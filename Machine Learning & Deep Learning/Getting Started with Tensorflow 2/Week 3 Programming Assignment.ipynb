{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation on the Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "In this notebook, you will build, compile and fit a neural network model to the Iris dataset. You will also implement validation, regularisation and callbacks to improve your model.\n",
    "\n",
    "Some code cells are provided you in the notebook. You should avoid editing provided code, and make sure to execute the cells in order to avoid unexpected errors. Some cells begin with the line: \n",
    "\n",
    "`#### GRADED CELL ####`\n",
    "\n",
    "Don't move or edit this first line - this is what the automatic grader looks for to recognise graded cells. These cells require you to write your own code to complete them, and are automatically graded when you submit the notebook. Don't edit the function name or signature provided in these cells, otherwise the automatic grader might not function properly. Inside these graded cells, you can use any functions or classes that are imported below, but make sure you don't use any variables that are outside the scope of the function.\n",
    "\n",
    "### How to submit\n",
    "\n",
    "Complete all the tasks you are asked for in the worksheet. When you have finished and are happy with your code, press the **Submit Assignment** button at the top of this notebook.\n",
    "\n",
    "### Let's get started!\n",
    "\n",
    "We'll start running some imports, and loading the dataset. Do not edit the existing imports in the following cell. If you would like to make further Tensorflow imports, you should add them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PACKAGE IMPORTS ####\n",
    "\n",
    "# Run this cell first to import all required packages. Do not make any imports elsewhere in the notebook\n",
    "from numpy.random import seed\n",
    "seed(8)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# If you would like to make further imports from tensorflow, add them here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td><img src=\"data/iris_setosa.jpg\" alt=\"Drawing\" style=\"height: 270px;\"/></td>\n",
    "<td><img src=\"data/iris_versicolor.jpg\" alt=\"Drawing\" style=\"height: 270px;\"/></td>\n",
    "<td><img src=\"data/iris_virginica.jpg\" alt=\"Drawing\" style=\"height: 270px;\"/></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Iris dataset\n",
    "\n",
    "In this assignment, you will use the [Iris dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html). It consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. For a reference, see the following papers:\n",
    "\n",
    "- R. A. Fisher. \"The use of multiple measurements in taxonomic problems\". Annals of Eugenics. 7 (2): 179â€“188, 1936.\n",
    "\n",
    "Your goal is to construct a neural network that classifies each sample into the correct class, as well as applying validation and regularisation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess the data\n",
    "\n",
    "First read in the Iris dataset using `datasets.load_iris()`, and split the dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': '/opt/conda/lib/python3.7/site-packages/sklearn/datasets/data/iris.csv'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = datasets.load_iris()\n",
    "iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def read_in_and_split_data(iris_data):\n",
    "    \"\"\"\n",
    "    This function takes the Iris dataset as loaded by sklearn.datasets.load_iris(), and then \n",
    "    splits so that the training set includes 90% of the full dataset, with the test set \n",
    "    making up the remaining 10%.\n",
    "    Your function should return a tuple (train_data, test_data, train_targets, test_targets) \n",
    "    of appropriately split training and test data and targets.\n",
    "    \n",
    "    If you would like to import any further packages to aid you in this task, please do so in the \n",
    "    Package Imports cell above.\n",
    "    \"\"\"\n",
    "    X = iris_data['data']\n",
    "    Y = iris_data['target']\n",
    "    x_train, y_train, x_test, y_test = train_test_split(X,Y, test_size=0.20, random_state=1)\n",
    "    \n",
    "    return (x_train, y_train, x_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to generate the test and training data.\n",
    "\n",
    "iris_data = datasets.load_iris()\n",
    "train_data, test_data, train_targets, test_targets = read_in_and_split_data(iris_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now convert the training and test targets using a one hot encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert targets to a one-hot encoding\n",
    "\n",
    "train_targets = tf.keras.utils.to_categorical(np.array(train_targets))\n",
    "test_targets = tf.keras.utils.to_categorical(np.array(test_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the neural network model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now construct a model to fit to the data. Using the Sequential API, build your model according to the following specifications:\n",
    "\n",
    "* The model should use the `input_shape` in the function argument to set the input size in the first layer.\n",
    "* The first layer should be a dense layer with 64 units.\n",
    "* The weights of the first layer should be initialised with the He uniform initializer.\n",
    "* The biases of the first layer should be all initially equal to one.\n",
    "* There should then be a further four dense layers, each with 128 units.\n",
    "* This should be followed with four dense layers, each with 64 units.\n",
    "* All of these Dense layers should use the ReLU activation function.\n",
    "* The output Dense layer should have 3 units and the softmax activation function.\n",
    "\n",
    "In total, the network should have 10 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def get_model(input_shape):\n",
    "    \"\"\"\n",
    "    This function should build a Sequential model according to the above specification. Ensure the \n",
    "    weights are initialised by providing the input_shape argument in the first layer, given by the\n",
    "    function argument.\n",
    "    Your function should return the model.\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Input\n",
    "    \n",
    "    model = Sequential([\n",
    "                        Input(shape=input_shape),\n",
    "                        Dense(64, kernel_initializer='he_uniform', bias_initializer='ones',\n",
    "                              activation='relu', input_shape = input_shape),\n",
    "                        Dense(128, activation='relu'),\n",
    "                        Dense(128, activation='relu'),\n",
    "                        Dense(128, activation='relu'),\n",
    "                        Dense(128, activation='relu'),\n",
    "                        Dense(64, activation='relu'),\n",
    "                        Dense(64, activation='relu'),\n",
    "                        Dense(64, activation='relu'),\n",
    "                        Dense(64, activation='relu'),\n",
    "                        Dense(3, activation='softmax')\n",
    "                        \n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to get the model\n",
    "\n",
    "model = get_model(train_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 79,107\n",
      "Trainable params: 79,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model\n",
    "\n",
    "You should now compile the model using the `compile` method. Remember that you need to specify an optimizer, a loss function and a metric to judge the performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def compile_model(model):\n",
    "    \"\"\"\n",
    "    This function takes in the model returned from your get_model function, and compiles it with an optimiser,\n",
    "    loss function and metric.\n",
    "    Compile the model using the Adam optimiser (with learning rate set to 0.0001), \n",
    "    the categorical crossentropy loss function and accuracy as the only metric. \n",
    "    Your function doesn't need to return anything; the model will be compiled in-place.\n",
    "    \"\"\"\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to compile the model\n",
    "\n",
    "compile_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model to the training data\n",
    "\n",
    "Now you should train the model on the Iris dataset, using the model's `fit` method. \n",
    "* Run the training for a fixed number of epochs, given by the function's `epochs` argument.\n",
    "* Return the training history to be used for plotting the learning curves.\n",
    "* Set the batch size to 40.\n",
    "* Set the validation set to be 15% of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def train_model(model, train_data, train_targets, epochs):\n",
    "    \"\"\"\n",
    "    This function should train the model for the given number of epochs on the \n",
    "    train_data and train_targets. \n",
    "    Your function should return the training history, as returned by model.fit.\n",
    "    \"\"\"\n",
    "    history = model.fit(train_data, train_targets, epochs=epochs, validation_split=0.15, batch_size=40)\n",
    "    return history\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to run the training for 800 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102 samples, validate on 18 samples\n",
      "Epoch 1/800\n",
      "102/102 [==============================] - 2s 18ms/sample - loss: 0.2483 - accuracy: 0.2843 - val_loss: 0.2267 - val_accuracy: 0.6667\n",
      "Epoch 2/800\n",
      "102/102 [==============================] - 0s 827us/sample - loss: 0.2357 - accuracy: 0.6176 - val_loss: 0.2189 - val_accuracy: 0.6667\n",
      "Epoch 3/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2252 - accuracy: 0.6275 - val_loss: 0.2131 - val_accuracy: 0.6667\n",
      "Epoch 4/800\n",
      "102/102 [==============================] - 0s 974us/sample - loss: 0.2156 - accuracy: 0.6275 - val_loss: 0.2074 - val_accuracy: 0.6667\n",
      "Epoch 5/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2075 - accuracy: 0.6275 - val_loss: 0.2027 - val_accuracy: 0.6667\n",
      "Epoch 6/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2012 - accuracy: 0.6275 - val_loss: 0.1987 - val_accuracy: 0.6667\n",
      "Epoch 7/800\n",
      "102/102 [==============================] - 0s 971us/sample - loss: 0.1961 - accuracy: 0.7059 - val_loss: 0.1956 - val_accuracy: 0.6111\n",
      "Epoch 8/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.1910 - accuracy: 0.7647 - val_loss: 0.1923 - val_accuracy: 0.5556\n",
      "Epoch 9/800\n",
      "102/102 [==============================] - 0s 983us/sample - loss: 0.1851 - accuracy: 0.7157 - val_loss: 0.1896 - val_accuracy: 0.5556\n",
      "Epoch 10/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.1798 - accuracy: 0.7157 - val_loss: 0.1872 - val_accuracy: 0.5556\n",
      "Epoch 11/800\n",
      "102/102 [==============================] - 0s 988us/sample - loss: 0.1740 - accuracy: 0.7157 - val_loss: 0.1830 - val_accuracy: 0.5556\n",
      "Epoch 12/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.1685 - accuracy: 0.7157 - val_loss: 0.1786 - val_accuracy: 0.5556\n",
      "Epoch 13/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.1626 - accuracy: 0.7157 - val_loss: 0.1746 - val_accuracy: 0.5556\n",
      "Epoch 14/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.1564 - accuracy: 0.7157 - val_loss: 0.1710 - val_accuracy: 0.5556\n",
      "Epoch 15/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.1501 - accuracy: 0.7157 - val_loss: 0.1660 - val_accuracy: 0.5556\n",
      "Epoch 16/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.1440 - accuracy: 0.7157 - val_loss: 0.1621 - val_accuracy: 0.5556\n",
      "Epoch 17/800\n",
      "102/102 [==============================] - 0s 982us/sample - loss: 0.1377 - accuracy: 0.7157 - val_loss: 0.1579 - val_accuracy: 0.5556\n",
      "Epoch 18/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.1310 - accuracy: 0.7157 - val_loss: 0.1537 - val_accuracy: 0.5556\n",
      "Epoch 19/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.1253 - accuracy: 0.7157 - val_loss: 0.1495 - val_accuracy: 0.5556\n",
      "Epoch 20/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.1196 - accuracy: 0.7157 - val_loss: 0.1451 - val_accuracy: 0.5556\n",
      "Epoch 21/800\n",
      "102/102 [==============================] - 0s 994us/sample - loss: 0.1150 - accuracy: 0.7157 - val_loss: 0.1427 - val_accuracy: 0.5556\n",
      "Epoch 22/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.1106 - accuracy: 0.7157 - val_loss: 0.1380 - val_accuracy: 0.5556\n",
      "Epoch 23/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.1074 - accuracy: 0.7157 - val_loss: 0.1334 - val_accuracy: 0.5556\n",
      "Epoch 24/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.1046 - accuracy: 0.7157 - val_loss: 0.1328 - val_accuracy: 0.5556\n",
      "Epoch 25/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.1015 - accuracy: 0.7157 - val_loss: 0.1289 - val_accuracy: 0.5556\n",
      "Epoch 26/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0991 - accuracy: 0.7157 - val_loss: 0.1279 - val_accuracy: 0.5556\n",
      "Epoch 27/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0970 - accuracy: 0.7157 - val_loss: 0.1257 - val_accuracy: 0.5556\n",
      "Epoch 28/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0959 - accuracy: 0.7255 - val_loss: 0.1214 - val_accuracy: 0.5556\n",
      "Epoch 29/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0930 - accuracy: 0.7157 - val_loss: 0.1219 - val_accuracy: 0.5556\n",
      "Epoch 30/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0911 - accuracy: 0.7157 - val_loss: 0.1196 - val_accuracy: 0.6111\n",
      "Epoch 31/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0892 - accuracy: 0.7255 - val_loss: 0.1161 - val_accuracy: 0.7222\n",
      "Epoch 32/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0877 - accuracy: 0.7941 - val_loss: 0.1129 - val_accuracy: 0.7222\n",
      "Epoch 33/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0857 - accuracy: 0.8627 - val_loss: 0.1116 - val_accuracy: 0.7222\n",
      "Epoch 34/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0836 - accuracy: 0.8235 - val_loss: 0.1125 - val_accuracy: 0.7222\n",
      "Epoch 35/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0821 - accuracy: 0.7843 - val_loss: 0.1086 - val_accuracy: 0.7222\n",
      "Epoch 36/800\n",
      "102/102 [==============================] - 0s 992us/sample - loss: 0.0786 - accuracy: 0.8529 - val_loss: 0.1004 - val_accuracy: 0.8889\n",
      "Epoch 37/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0771 - accuracy: 0.9510 - val_loss: 0.0962 - val_accuracy: 0.8889\n",
      "Epoch 38/800\n",
      "102/102 [==============================] - 0s 985us/sample - loss: 0.0768 - accuracy: 0.9706 - val_loss: 0.0940 - val_accuracy: 0.8889\n",
      "Epoch 39/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0718 - accuracy: 0.9608 - val_loss: 0.0977 - val_accuracy: 0.7778\n",
      "Epoch 40/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0726 - accuracy: 0.8725 - val_loss: 0.0965 - val_accuracy: 0.7778\n",
      "Epoch 41/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0685 - accuracy: 0.9314 - val_loss: 0.0869 - val_accuracy: 0.9444\n",
      "Epoch 42/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0697 - accuracy: 0.9804 - val_loss: 0.0834 - val_accuracy: 0.9444\n",
      "Epoch 43/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0657 - accuracy: 0.9510 - val_loss: 0.0897 - val_accuracy: 0.7778\n",
      "Epoch 44/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0633 - accuracy: 0.9216 - val_loss: 0.0818 - val_accuracy: 0.8889\n",
      "Epoch 45/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0596 - accuracy: 0.9608 - val_loss: 0.0746 - val_accuracy: 0.9444\n",
      "Epoch 46/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0578 - accuracy: 0.9804 - val_loss: 0.0740 - val_accuracy: 0.8889\n",
      "Epoch 47/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0556 - accuracy: 0.9608 - val_loss: 0.0774 - val_accuracy: 0.8333\n",
      "Epoch 48/800\n",
      "102/102 [==============================] - 0s 964us/sample - loss: 0.0541 - accuracy: 0.9510 - val_loss: 0.0670 - val_accuracy: 0.9444\n",
      "Epoch 49/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0502 - accuracy: 0.9706 - val_loss: 0.0655 - val_accuracy: 0.9444\n",
      "Epoch 50/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0477 - accuracy: 0.9706 - val_loss: 0.0630 - val_accuracy: 0.9444\n",
      "Epoch 51/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0452 - accuracy: 0.9706 - val_loss: 0.0615 - val_accuracy: 0.8889\n",
      "Epoch 52/800\n",
      "102/102 [==============================] - 0s 990us/sample - loss: 0.0431 - accuracy: 0.9706 - val_loss: 0.0565 - val_accuracy: 0.9444\n",
      "Epoch 53/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0429 - accuracy: 0.9608 - val_loss: 0.0526 - val_accuracy: 0.9444\n",
      "Epoch 54/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0390 - accuracy: 0.9706 - val_loss: 0.0567 - val_accuracy: 0.8889\n",
      "Epoch 55/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0390 - accuracy: 0.9706 - val_loss: 0.0511 - val_accuracy: 0.9444\n",
      "Epoch 56/800\n",
      "102/102 [==============================] - 0s 992us/sample - loss: 0.0358 - accuracy: 0.9804 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 57/800\n",
      "102/102 [==============================] - 0s 965us/sample - loss: 0.0358 - accuracy: 0.9706 - val_loss: 0.0484 - val_accuracy: 0.9444\n",
      "Epoch 58/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0327 - accuracy: 0.9706 - val_loss: 0.0486 - val_accuracy: 0.9444\n",
      "Epoch 59/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0313 - accuracy: 0.9706 - val_loss: 0.0423 - val_accuracy: 0.9444\n",
      "Epoch 60/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0300 - accuracy: 0.9804 - val_loss: 0.0411 - val_accuracy: 0.9444\n",
      "Epoch 61/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0288 - accuracy: 0.9804 - val_loss: 0.0441 - val_accuracy: 0.9444\n",
      "Epoch 62/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0282 - accuracy: 0.9706 - val_loss: 0.0433 - val_accuracy: 0.9444\n",
      "Epoch 63/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0267 - accuracy: 0.9804 - val_loss: 0.0358 - val_accuracy: 0.9444\n",
      "Epoch 64/800\n",
      "102/102 [==============================] - 0s 979us/sample - loss: 0.0269 - accuracy: 0.9804 - val_loss: 0.0362 - val_accuracy: 0.9444\n",
      "Epoch 65/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0246 - accuracy: 0.9804 - val_loss: 0.0365 - val_accuracy: 0.9444\n",
      "Epoch 66/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0237 - accuracy: 0.9804 - val_loss: 0.0376 - val_accuracy: 0.9444\n",
      "Epoch 67/800\n",
      "102/102 [==============================] - 0s 973us/sample - loss: 0.0238 - accuracy: 0.9804 - val_loss: 0.0330 - val_accuracy: 0.9444\n",
      "Epoch 68/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0225 - accuracy: 0.9804 - val_loss: 0.0408 - val_accuracy: 0.9444\n",
      "Epoch 69/800\n",
      "102/102 [==============================] - 0s 974us/sample - loss: 0.0223 - accuracy: 0.9706 - val_loss: 0.0394 - val_accuracy: 0.9444\n",
      "Epoch 70/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0231 - accuracy: 0.9706 - val_loss: 0.0303 - val_accuracy: 0.9444\n",
      "Epoch 71/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0203 - accuracy: 0.9804 - val_loss: 0.0389 - val_accuracy: 0.9444\n",
      "Epoch 72/800\n",
      "102/102 [==============================] - 0s 990us/sample - loss: 0.0215 - accuracy: 0.9706 - val_loss: 0.0377 - val_accuracy: 0.9444\n",
      "Epoch 73/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0198 - accuracy: 0.9804 - val_loss: 0.0264 - val_accuracy: 0.9444\n",
      "Epoch 74/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0215 - accuracy: 0.9804 - val_loss: 0.0300 - val_accuracy: 0.9444\n",
      "Epoch 75/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0193 - accuracy: 0.9804 - val_loss: 0.0318 - val_accuracy: 0.9444\n",
      "Epoch 76/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0185 - accuracy: 0.9804 - val_loss: 0.0385 - val_accuracy: 0.9444\n",
      "Epoch 77/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.0193 - accuracy: 0.9706 - val_loss: 0.0336 - val_accuracy: 0.9444\n",
      "Epoch 78/800\n",
      "102/102 [==============================] - 0s 969us/sample - loss: 0.0188 - accuracy: 0.9706 - val_loss: 0.0323 - val_accuracy: 0.9444\n",
      "Epoch 79/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0179 - accuracy: 0.9804 - val_loss: 0.0282 - val_accuracy: 0.9444\n",
      "Epoch 80/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0175 - accuracy: 0.9804 - val_loss: 0.0321 - val_accuracy: 0.9444\n",
      "Epoch 81/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0179 - accuracy: 0.9706 - val_loss: 0.0340 - val_accuracy: 0.9444\n",
      "Epoch 82/800\n",
      "102/102 [==============================] - 0s 983us/sample - loss: 0.0169 - accuracy: 0.9804 - val_loss: 0.0255 - val_accuracy: 0.9444\n",
      "Epoch 83/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0173 - accuracy: 0.9804 - val_loss: 0.0266 - val_accuracy: 0.9444\n",
      "Epoch 84/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0168 - accuracy: 0.9804 - val_loss: 0.0333 - val_accuracy: 0.9444\n",
      "Epoch 85/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.0167 - accuracy: 0.9804 - val_loss: 0.0338 - val_accuracy: 0.9444\n",
      "Epoch 86/800\n",
      "102/102 [==============================] - 0s 989us/sample - loss: 0.0162 - accuracy: 0.9804 - val_loss: 0.0289 - val_accuracy: 0.9444\n",
      "Epoch 87/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0163 - accuracy: 0.9804 - val_loss: 0.0246 - val_accuracy: 0.9444\n",
      "Epoch 88/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0169 - accuracy: 0.9804 - val_loss: 0.0294 - val_accuracy: 0.9444\n",
      "Epoch 89/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0157 - accuracy: 0.9804 - val_loss: 0.0448 - val_accuracy: 0.8333\n",
      "Epoch 90/800\n",
      "102/102 [==============================] - 0s 974us/sample - loss: 0.0172 - accuracy: 0.9706 - val_loss: 0.0335 - val_accuracy: 0.9444\n",
      "Epoch 91/800\n",
      "102/102 [==============================] - 0s 985us/sample - loss: 0.0163 - accuracy: 0.9804 - val_loss: 0.0255 - val_accuracy: 0.9444\n",
      "Epoch 92/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0159 - accuracy: 0.9804 - val_loss: 0.0328 - val_accuracy: 0.9444\n",
      "Epoch 93/800\n",
      "102/102 [==============================] - 0s 984us/sample - loss: 0.0155 - accuracy: 0.9804 - val_loss: 0.0299 - val_accuracy: 0.9444\n",
      "Epoch 94/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0151 - accuracy: 0.9804 - val_loss: 0.0293 - val_accuracy: 0.9444\n",
      "Epoch 95/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.0150 - accuracy: 0.9804 - val_loss: 0.0282 - val_accuracy: 0.9444\n",
      "Epoch 96/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0152 - accuracy: 0.9804 - val_loss: 0.0308 - val_accuracy: 0.9444\n",
      "Epoch 97/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0151 - accuracy: 0.9804 - val_loss: 0.0305 - val_accuracy: 0.9444\n",
      "Epoch 98/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0147 - accuracy: 0.9804 - val_loss: 0.0260 - val_accuracy: 0.9444\n",
      "Epoch 99/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.0150 - accuracy: 0.9804 - val_loss: 0.0288 - val_accuracy: 0.9444\n",
      "Epoch 100/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0151 - accuracy: 0.9804 - val_loss: 0.0309 - val_accuracy: 0.9444\n",
      "Epoch 101/800\n",
      "102/102 [==============================] - 0s 1000us/sample - loss: 0.0145 - accuracy: 0.9804 - val_loss: 0.0259 - val_accuracy: 0.9444\n",
      "Epoch 102/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0150 - accuracy: 0.9804 - val_loss: 0.0247 - val_accuracy: 0.9444\n",
      "Epoch 103/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0146 - accuracy: 0.9804 - val_loss: 0.0356 - val_accuracy: 0.9444\n",
      "Epoch 104/800\n",
      "102/102 [==============================] - 0s 985us/sample - loss: 0.0150 - accuracy: 0.9706 - val_loss: 0.0348 - val_accuracy: 0.9444\n",
      "Epoch 105/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.0176 - accuracy: 0.9706 - val_loss: 0.0237 - val_accuracy: 0.9444\n",
      "Epoch 106/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.0145 - accuracy: 0.9804 - val_loss: 0.0410 - val_accuracy: 0.9444\n",
      "Epoch 107/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0148 - accuracy: 0.9804 - val_loss: 0.0339 - val_accuracy: 0.9444\n",
      "Epoch 108/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0143 - accuracy: 0.9804 - val_loss: 0.0280 - val_accuracy: 0.9444\n",
      "Epoch 109/800\n",
      "102/102 [==============================] - 0s 984us/sample - loss: 0.0139 - accuracy: 0.9804 - val_loss: 0.0331 - val_accuracy: 0.9444\n",
      "Epoch 110/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0142 - accuracy: 0.9804 - val_loss: 0.0379 - val_accuracy: 0.9444\n",
      "Epoch 111/800\n",
      "102/102 [==============================] - 0s 985us/sample - loss: 0.0141 - accuracy: 0.9804 - val_loss: 0.0271 - val_accuracy: 0.9444\n",
      "Epoch 112/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0148 - accuracy: 0.9804 - val_loss: 0.0279 - val_accuracy: 0.9444\n",
      "Epoch 113/800\n",
      "102/102 [==============================] - 0s 981us/sample - loss: 0.0146 - accuracy: 0.9804 - val_loss: 0.0402 - val_accuracy: 0.9444\n",
      "Epoch 114/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0143 - accuracy: 0.9804 - val_loss: 0.0296 - val_accuracy: 0.9444\n",
      "Epoch 115/800\n",
      "102/102 [==============================] - 0s 982us/sample - loss: 0.0137 - accuracy: 0.9804 - val_loss: 0.0192 - val_accuracy: 0.9444\n",
      "Epoch 116/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0164 - accuracy: 0.9510 - val_loss: 0.0303 - val_accuracy: 0.9444\n",
      "Epoch 117/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0142 - accuracy: 0.9804 - val_loss: 0.0432 - val_accuracy: 0.8889\n",
      "Epoch 118/800\n",
      "102/102 [==============================] - 0s 992us/sample - loss: 0.0146 - accuracy: 0.9804 - val_loss: 0.0307 - val_accuracy: 0.9444\n",
      "Epoch 119/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0138 - accuracy: 0.9804 - val_loss: 0.0294 - val_accuracy: 0.9444\n",
      "Epoch 120/800\n",
      "102/102 [==============================] - 0s 965us/sample - loss: 0.0134 - accuracy: 0.9804 - val_loss: 0.0300 - val_accuracy: 0.9444\n",
      "Epoch 121/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0132 - accuracy: 0.9804 - val_loss: 0.0308 - val_accuracy: 0.9444\n",
      "Epoch 122/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0132 - accuracy: 0.9804 - val_loss: 0.0327 - val_accuracy: 0.9444\n",
      "Epoch 123/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0133 - accuracy: 0.9804 - val_loss: 0.0335 - val_accuracy: 0.9444\n",
      "Epoch 124/800\n",
      "102/102 [==============================] - 0s 963us/sample - loss: 0.0130 - accuracy: 0.9804 - val_loss: 0.0372 - val_accuracy: 0.9444\n",
      "Epoch 125/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0136 - accuracy: 0.9804 - val_loss: 0.0354 - val_accuracy: 0.9444\n",
      "Epoch 126/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0131 - accuracy: 0.9804 - val_loss: 0.0257 - val_accuracy: 0.9444\n",
      "Epoch 127/800\n",
      "102/102 [==============================] - 0s 983us/sample - loss: 0.0138 - accuracy: 0.9804 - val_loss: 0.0302 - val_accuracy: 0.9444\n",
      "Epoch 128/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.0132 - accuracy: 0.9804 - val_loss: 0.0449 - val_accuracy: 0.8889\n",
      "Epoch 129/800\n",
      "102/102 [==============================] - 0s 984us/sample - loss: 0.0136 - accuracy: 0.9804 - val_loss: 0.0348 - val_accuracy: 0.9444\n",
      "Epoch 130/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0126 - accuracy: 0.9804 - val_loss: 0.0256 - val_accuracy: 0.9444\n",
      "Epoch 131/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0136 - accuracy: 0.9804 - val_loss: 0.0290 - val_accuracy: 0.9444\n",
      "Epoch 132/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0128 - accuracy: 0.9804 - val_loss: 0.0311 - val_accuracy: 0.9444\n",
      "Epoch 133/800\n",
      "102/102 [==============================] - 0s 988us/sample - loss: 0.0126 - accuracy: 0.9804 - val_loss: 0.0358 - val_accuracy: 0.9444\n",
      "Epoch 134/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0129 - accuracy: 0.9804 - val_loss: 0.0349 - val_accuracy: 0.9444\n",
      "Epoch 135/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0126 - accuracy: 0.9804 - val_loss: 0.0308 - val_accuracy: 0.9444\n",
      "Epoch 136/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0128 - accuracy: 0.9804 - val_loss: 0.0300 - val_accuracy: 0.9444\n",
      "Epoch 137/800\n",
      "102/102 [==============================] - 0s 978us/sample - loss: 0.0128 - accuracy: 0.9804 - val_loss: 0.0350 - val_accuracy: 0.9444\n",
      "Epoch 138/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0125 - accuracy: 0.9804 - val_loss: 0.0319 - val_accuracy: 0.9444\n",
      "Epoch 139/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0126 - accuracy: 0.9804 - val_loss: 0.0315 - val_accuracy: 0.9444\n",
      "Epoch 140/800\n",
      "102/102 [==============================] - 0s 970us/sample - loss: 0.0132 - accuracy: 0.9804 - val_loss: 0.0368 - val_accuracy: 0.9444\n",
      "Epoch 141/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0124 - accuracy: 0.9804 - val_loss: 0.0280 - val_accuracy: 0.9444\n",
      "Epoch 142/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.0125 - accuracy: 0.9804 - val_loss: 0.0324 - val_accuracy: 0.9444\n",
      "Epoch 143/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0122 - accuracy: 0.9804 - val_loss: 0.0354 - val_accuracy: 0.9444\n",
      "Epoch 144/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0126 - accuracy: 0.9804 - val_loss: 0.0374 - val_accuracy: 0.9444\n",
      "Epoch 145/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0125 - accuracy: 0.9804 - val_loss: 0.0262 - val_accuracy: 0.9444\n",
      "Epoch 146/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0129 - accuracy: 0.9804 - val_loss: 0.0326 - val_accuracy: 0.9444\n",
      "Epoch 147/800\n",
      "102/102 [==============================] - 0s 984us/sample - loss: 0.0122 - accuracy: 0.9804 - val_loss: 0.0345 - val_accuracy: 0.9444\n",
      "Epoch 148/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0120 - accuracy: 0.9804 - val_loss: 0.0398 - val_accuracy: 0.8889\n",
      "Epoch 149/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0126 - accuracy: 0.9804 - val_loss: 0.0368 - val_accuracy: 0.9444\n",
      "Epoch 150/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0124 - accuracy: 0.9804 - val_loss: 0.0259 - val_accuracy: 0.9444\n",
      "Epoch 151/800\n",
      "102/102 [==============================] - 0s 978us/sample - loss: 0.0128 - accuracy: 0.9804 - val_loss: 0.0362 - val_accuracy: 0.9444\n",
      "Epoch 152/800\n",
      "102/102 [==============================] - 0s 981us/sample - loss: 0.0124 - accuracy: 0.9804 - val_loss: 0.0545 - val_accuracy: 0.8889\n",
      "Epoch 153/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0139 - accuracy: 0.9706 - val_loss: 0.0398 - val_accuracy: 0.8889\n",
      "Epoch 154/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0121 - accuracy: 0.9804 - val_loss: 0.0269 - val_accuracy: 0.9444\n",
      "Epoch 155/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0125 - accuracy: 0.9804 - val_loss: 0.0331 - val_accuracy: 0.9444\n",
      "Epoch 156/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0120 - accuracy: 0.9804 - val_loss: 0.0367 - val_accuracy: 0.9444\n",
      "Epoch 157/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0120 - accuracy: 0.9804 - val_loss: 0.0334 - val_accuracy: 0.9444\n",
      "Epoch 158/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.0118 - accuracy: 0.9804 - val_loss: 0.0344 - val_accuracy: 0.9444\n",
      "Epoch 159/800\n",
      "102/102 [==============================] - 0s 991us/sample - loss: 0.0122 - accuracy: 0.9804 - val_loss: 0.0411 - val_accuracy: 0.8889\n",
      "Epoch 160/800\n",
      "102/102 [==============================] - 0s 984us/sample - loss: 0.0118 - accuracy: 0.9804 - val_loss: 0.0342 - val_accuracy: 0.9444\n",
      "Epoch 161/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0122 - accuracy: 0.9804 - val_loss: 0.0325 - val_accuracy: 0.9444\n",
      "Epoch 162/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0122 - accuracy: 0.9804 - val_loss: 0.0420 - val_accuracy: 0.8889\n",
      "Epoch 163/800\n",
      "102/102 [==============================] - 0s 989us/sample - loss: 0.0123 - accuracy: 0.9804 - val_loss: 0.0350 - val_accuracy: 0.9444\n",
      "Epoch 164/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0115 - accuracy: 0.9804 - val_loss: 0.0414 - val_accuracy: 0.8889\n",
      "Epoch 165/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0118 - accuracy: 0.9804 - val_loss: 0.0383 - val_accuracy: 0.8889\n",
      "Epoch 166/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0115 - accuracy: 0.9804 - val_loss: 0.0324 - val_accuracy: 0.9444\n",
      "Epoch 167/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0116 - accuracy: 0.9804 - val_loss: 0.0340 - val_accuracy: 0.9444\n",
      "Epoch 168/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0124 - accuracy: 0.9804 - val_loss: 0.0442 - val_accuracy: 0.8889\n",
      "Epoch 169/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0120 - accuracy: 0.9804 - val_loss: 0.0375 - val_accuracy: 0.9444\n",
      "Epoch 170/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0107 - accuracy: 0.9804 - val_loss: 0.0240 - val_accuracy: 0.9444\n",
      "Epoch 171/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.0134 - accuracy: 0.9902 - val_loss: 0.0278 - val_accuracy: 0.9444\n",
      "Epoch 172/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0114 - accuracy: 0.9902 - val_loss: 0.0443 - val_accuracy: 0.8889\n",
      "Epoch 173/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0137 - accuracy: 0.9804 - val_loss: 0.0558 - val_accuracy: 0.8889\n",
      "Epoch 174/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0121 - accuracy: 0.9804 - val_loss: 0.0335 - val_accuracy: 0.9444\n",
      "Epoch 175/800\n",
      "102/102 [==============================] - 0s 989us/sample - loss: 0.0137 - accuracy: 0.9608 - val_loss: 0.0281 - val_accuracy: 0.9444\n",
      "Epoch 176/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0103 - accuracy: 0.9902 - val_loss: 0.0546 - val_accuracy: 0.8889\n",
      "Epoch 177/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0130 - accuracy: 0.9804 - val_loss: 0.0577 - val_accuracy: 0.8889\n",
      "Epoch 178/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0129 - accuracy: 0.9804 - val_loss: 0.0366 - val_accuracy: 0.9444\n",
      "Epoch 179/800\n",
      "102/102 [==============================] - 0s 988us/sample - loss: 0.0120 - accuracy: 0.9804 - val_loss: 0.0276 - val_accuracy: 0.9444\n",
      "Epoch 180/800\n",
      "102/102 [==============================] - 0s 991us/sample - loss: 0.0111 - accuracy: 0.9902 - val_loss: 0.0468 - val_accuracy: 0.8889\n",
      "Epoch 181/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0125 - accuracy: 0.9804 - val_loss: 0.0571 - val_accuracy: 0.8889\n",
      "Epoch 182/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0128 - accuracy: 0.9804 - val_loss: 0.0395 - val_accuracy: 0.8889\n",
      "Epoch 183/800\n",
      "102/102 [==============================] - 0s 992us/sample - loss: 0.0144 - accuracy: 0.9706 - val_loss: 0.0248 - val_accuracy: 0.9444\n",
      "Epoch 184/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0131 - accuracy: 0.9804 - val_loss: 0.0497 - val_accuracy: 0.8889\n",
      "Epoch 185/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0119 - accuracy: 0.9804 - val_loss: 0.0459 - val_accuracy: 0.8889\n",
      "Epoch 186/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0113 - accuracy: 0.9804 - val_loss: 0.0391 - val_accuracy: 0.8889\n",
      "Epoch 187/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0105 - accuracy: 0.9902 - val_loss: 0.0283 - val_accuracy: 0.9444\n",
      "Epoch 188/800\n",
      "102/102 [==============================] - 0s 981us/sample - loss: 0.0120 - accuracy: 0.9902 - val_loss: 0.0351 - val_accuracy: 0.9444\n",
      "Epoch 189/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0115 - accuracy: 0.9804 - val_loss: 0.0530 - val_accuracy: 0.8889\n",
      "Epoch 190/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0125 - accuracy: 0.9804 - val_loss: 0.0471 - val_accuracy: 0.8889\n",
      "Epoch 191/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0110 - accuracy: 0.9804 - val_loss: 0.0253 - val_accuracy: 0.9444\n",
      "Epoch 192/800\n",
      "102/102 [==============================] - 0s 961us/sample - loss: 0.0137 - accuracy: 0.9804 - val_loss: 0.0442 - val_accuracy: 0.8889\n",
      "Epoch 193/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0116 - accuracy: 0.9804 - val_loss: 0.0502 - val_accuracy: 0.8889\n",
      "Epoch 194/800\n",
      "102/102 [==============================] - 0s 976us/sample - loss: 0.0112 - accuracy: 0.9804 - val_loss: 0.0326 - val_accuracy: 0.9444\n",
      "Epoch 195/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0121 - accuracy: 0.9902 - val_loss: 0.0375 - val_accuracy: 0.8889\n",
      "Epoch 196/800\n",
      "102/102 [==============================] - 0s 978us/sample - loss: 0.0104 - accuracy: 0.9804 - val_loss: 0.0612 - val_accuracy: 0.8889\n",
      "Epoch 197/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0131 - accuracy: 0.9804 - val_loss: 0.0540 - val_accuracy: 0.8889\n",
      "Epoch 198/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0114 - accuracy: 0.9804 - val_loss: 0.0367 - val_accuracy: 0.9444\n",
      "Epoch 199/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.0106 - accuracy: 0.9902 - val_loss: 0.0325 - val_accuracy: 0.9444\n",
      "Epoch 200/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.0114 - accuracy: 0.9804 - val_loss: 0.0399 - val_accuracy: 0.8889\n",
      "Epoch 201/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0107 - accuracy: 0.9804 - val_loss: 0.0400 - val_accuracy: 0.8889\n",
      "Epoch 202/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0113 - accuracy: 0.9804 - val_loss: 0.0466 - val_accuracy: 0.8889\n",
      "Epoch 203/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0112 - accuracy: 0.9804 - val_loss: 0.0357 - val_accuracy: 0.9444\n",
      "Epoch 204/800\n",
      "102/102 [==============================] - 0s 970us/sample - loss: 0.0106 - accuracy: 0.9902 - val_loss: 0.0444 - val_accuracy: 0.8889\n",
      "Epoch 205/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0105 - accuracy: 0.9804 - val_loss: 0.0575 - val_accuracy: 0.8889\n",
      "Epoch 206/800\n",
      "102/102 [==============================] - 0s 991us/sample - loss: 0.0117 - accuracy: 0.9804 - val_loss: 0.0487 - val_accuracy: 0.8889\n",
      "Epoch 207/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0101 - accuracy: 0.9804 - val_loss: 0.0360 - val_accuracy: 0.9444\n",
      "Epoch 208/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0154 - accuracy: 0.9706 - val_loss: 0.0365 - val_accuracy: 0.9444\n",
      "Epoch 209/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0130 - accuracy: 0.9804 - val_loss: 0.0742 - val_accuracy: 0.8333\n",
      "Epoch 210/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0169 - accuracy: 0.9706 - val_loss: 0.0603 - val_accuracy: 0.8889\n",
      "Epoch 211/800\n",
      "102/102 [==============================] - 0s 989us/sample - loss: 0.0131 - accuracy: 0.9804 - val_loss: 0.0252 - val_accuracy: 0.9444\n",
      "Epoch 212/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0133 - accuracy: 0.9804 - val_loss: 0.0402 - val_accuracy: 0.8889\n",
      "Epoch 213/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0100 - accuracy: 0.9804 - val_loss: 0.0641 - val_accuracy: 0.8889\n",
      "Epoch 214/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0135 - accuracy: 0.9804 - val_loss: 0.0588 - val_accuracy: 0.8889\n",
      "Epoch 215/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0109 - accuracy: 0.9804 - val_loss: 0.0296 - val_accuracy: 0.9444\n",
      "Epoch 216/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0148 - accuracy: 0.9706 - val_loss: 0.0330 - val_accuracy: 0.9444\n",
      "Epoch 217/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0140 - accuracy: 0.9804 - val_loss: 0.0659 - val_accuracy: 0.8889\n",
      "Epoch 218/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.0135 - accuracy: 0.9804 - val_loss: 0.0480 - val_accuracy: 0.8889\n",
      "Epoch 219/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0098 - accuracy: 0.9804 - val_loss: 0.0349 - val_accuracy: 0.9444\n",
      "Epoch 220/800\n",
      "102/102 [==============================] - 0s 984us/sample - loss: 0.0124 - accuracy: 0.9902 - val_loss: 0.0370 - val_accuracy: 0.8889\n",
      "Epoch 221/800\n",
      "102/102 [==============================] - 0s 977us/sample - loss: 0.0099 - accuracy: 0.9902 - val_loss: 0.0591 - val_accuracy: 0.8889\n",
      "Epoch 222/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0120 - accuracy: 0.9804 - val_loss: 0.0556 - val_accuracy: 0.8889\n",
      "Epoch 223/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0108 - accuracy: 0.9804 - val_loss: 0.0394 - val_accuracy: 0.8889\n",
      "Epoch 224/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0099 - accuracy: 0.9902 - val_loss: 0.0327 - val_accuracy: 0.9444\n",
      "Epoch 225/800\n",
      "102/102 [==============================] - 0s 969us/sample - loss: 0.0113 - accuracy: 0.9902 - val_loss: 0.0370 - val_accuracy: 0.8889\n",
      "Epoch 226/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0098 - accuracy: 0.9902 - val_loss: 0.0544 - val_accuracy: 0.8889\n",
      "Epoch 227/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0113 - accuracy: 0.9804 - val_loss: 0.0558 - val_accuracy: 0.8889\n",
      "Epoch 228/800\n",
      "102/102 [==============================] - 0s 954us/sample - loss: 0.0112 - accuracy: 0.9804 - val_loss: 0.0401 - val_accuracy: 0.8889\n",
      "Epoch 229/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0099 - accuracy: 0.9902 - val_loss: 0.0401 - val_accuracy: 0.8889\n",
      "Epoch 230/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0099 - accuracy: 0.9902 - val_loss: 0.0442 - val_accuracy: 0.8889\n",
      "Epoch 231/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0110 - accuracy: 0.9804 - val_loss: 0.0498 - val_accuracy: 0.8889\n",
      "Epoch 232/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0103 - accuracy: 0.9804 - val_loss: 0.0388 - val_accuracy: 0.8889\n",
      "Epoch 233/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0101 - accuracy: 0.9804 - val_loss: 0.0445 - val_accuracy: 0.8889\n",
      "Epoch 234/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0097 - accuracy: 0.9804 - val_loss: 0.0443 - val_accuracy: 0.8889\n",
      "Epoch 235/800\n",
      "102/102 [==============================] - 0s 992us/sample - loss: 0.0102 - accuracy: 0.9804 - val_loss: 0.0446 - val_accuracy: 0.8889\n",
      "Epoch 236/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0095 - accuracy: 0.9902 - val_loss: 0.0378 - val_accuracy: 0.8889\n",
      "Epoch 237/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0107 - accuracy: 0.9902 - val_loss: 0.0377 - val_accuracy: 0.8889\n",
      "Epoch 238/800\n",
      "102/102 [==============================] - 0s 980us/sample - loss: 0.0101 - accuracy: 0.9902 - val_loss: 0.0494 - val_accuracy: 0.8889\n",
      "Epoch 239/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0107 - accuracy: 0.9804 - val_loss: 0.0614 - val_accuracy: 0.8889\n",
      "Epoch 240/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0114 - accuracy: 0.9804 - val_loss: 0.0509 - val_accuracy: 0.8889\n",
      "Epoch 241/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0098 - accuracy: 0.9804 - val_loss: 0.0423 - val_accuracy: 0.8889\n",
      "Epoch 242/800\n",
      "102/102 [==============================] - 0s 987us/sample - loss: 0.0101 - accuracy: 0.9902 - val_loss: 0.0467 - val_accuracy: 0.8889\n",
      "Epoch 243/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0106 - accuracy: 0.9804 - val_loss: 0.0600 - val_accuracy: 0.8889\n",
      "Epoch 244/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0110 - accuracy: 0.9804 - val_loss: 0.0527 - val_accuracy: 0.8889\n",
      "Epoch 245/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0095 - accuracy: 0.9902 - val_loss: 0.0358 - val_accuracy: 0.9444\n",
      "Epoch 246/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0107 - accuracy: 0.9902 - val_loss: 0.0450 - val_accuracy: 0.8889\n",
      "Epoch 247/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0098 - accuracy: 0.9804 - val_loss: 0.0534 - val_accuracy: 0.8889\n",
      "Epoch 248/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.0101 - accuracy: 0.9804 - val_loss: 0.0513 - val_accuracy: 0.8889\n",
      "Epoch 249/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0102 - accuracy: 0.9804 - val_loss: 0.0533 - val_accuracy: 0.8889\n",
      "Epoch 250/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0096 - accuracy: 0.9804 - val_loss: 0.0419 - val_accuracy: 0.8889\n",
      "Epoch 251/800\n",
      "102/102 [==============================] - 0s 980us/sample - loss: 0.0097 - accuracy: 0.9902 - val_loss: 0.0471 - val_accuracy: 0.8889\n",
      "Epoch 252/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0094 - accuracy: 0.9902 - val_loss: 0.0521 - val_accuracy: 0.8889\n",
      "Epoch 253/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.0096 - accuracy: 0.9804 - val_loss: 0.0507 - val_accuracy: 0.8889\n",
      "Epoch 254/800\n",
      "102/102 [==============================] - 0s 975us/sample - loss: 0.0100 - accuracy: 0.9804 - val_loss: 0.0535 - val_accuracy: 0.8889\n",
      "Epoch 255/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0094 - accuracy: 0.9804 - val_loss: 0.0469 - val_accuracy: 0.8889\n",
      "Epoch 256/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.0094 - accuracy: 0.9902 - val_loss: 0.0460 - val_accuracy: 0.8889\n",
      "Epoch 257/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0095 - accuracy: 0.9902 - val_loss: 0.0524 - val_accuracy: 0.8889\n",
      "Epoch 258/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0101 - accuracy: 0.9804 - val_loss: 0.0551 - val_accuracy: 0.8889\n",
      "Epoch 259/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0092 - accuracy: 0.9902 - val_loss: 0.0441 - val_accuracy: 0.8889\n",
      "Epoch 260/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0112 - accuracy: 0.9804 - val_loss: 0.0377 - val_accuracy: 0.8889\n",
      "Epoch 261/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0099 - accuracy: 0.9902 - val_loss: 0.0624 - val_accuracy: 0.8889\n",
      "Epoch 262/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.0123 - accuracy: 0.9804 - val_loss: 0.0654 - val_accuracy: 0.8889\n",
      "Epoch 263/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0112 - accuracy: 0.9804 - val_loss: 0.0468 - val_accuracy: 0.8889\n",
      "Epoch 264/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0100 - accuracy: 0.9902 - val_loss: 0.0370 - val_accuracy: 0.8889\n",
      "Epoch 265/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0103 - accuracy: 0.9902 - val_loss: 0.0515 - val_accuracy: 0.8889\n",
      "Epoch 266/800\n",
      "102/102 [==============================] - 0s 994us/sample - loss: 0.0108 - accuracy: 0.9804 - val_loss: 0.0589 - val_accuracy: 0.8889\n",
      "Epoch 267/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0094 - accuracy: 0.9804 - val_loss: 0.0427 - val_accuracy: 0.8889\n",
      "Epoch 268/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0109 - accuracy: 0.9804 - val_loss: 0.0419 - val_accuracy: 0.8889\n",
      "Epoch 269/800\n",
      "102/102 [==============================] - 0s 973us/sample - loss: 0.0098 - accuracy: 0.9902 - val_loss: 0.0609 - val_accuracy: 0.8889\n",
      "Epoch 270/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0113 - accuracy: 0.9804 - val_loss: 0.0617 - val_accuracy: 0.8889\n",
      "Epoch 271/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.0094 - accuracy: 0.9804 - val_loss: 0.0460 - val_accuracy: 0.8889\n",
      "Epoch 272/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0108 - accuracy: 0.9902 - val_loss: 0.0405 - val_accuracy: 0.8889\n",
      "Epoch 273/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0096 - accuracy: 0.9902 - val_loss: 0.0623 - val_accuracy: 0.8889\n",
      "Epoch 274/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0116 - accuracy: 0.9804 - val_loss: 0.0631 - val_accuracy: 0.8889\n",
      "Epoch 275/800\n",
      "102/102 [==============================] - 0s 977us/sample - loss: 0.0105 - accuracy: 0.9804 - val_loss: 0.0494 - val_accuracy: 0.8889\n",
      "Epoch 276/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0097 - accuracy: 0.9902 - val_loss: 0.0474 - val_accuracy: 0.8889\n",
      "Epoch 277/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0088 - accuracy: 0.9902 - val_loss: 0.0574 - val_accuracy: 0.8889\n",
      "Epoch 278/800\n",
      "102/102 [==============================] - 0s 1000us/sample - loss: 0.0094 - accuracy: 0.9804 - val_loss: 0.0573 - val_accuracy: 0.8889\n",
      "Epoch 279/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0095 - accuracy: 0.9804 - val_loss: 0.0535 - val_accuracy: 0.8889\n",
      "Epoch 280/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0091 - accuracy: 0.9902 - val_loss: 0.0515 - val_accuracy: 0.8889\n",
      "Epoch 281/800\n",
      "102/102 [==============================] - 0s 985us/sample - loss: 0.0091 - accuracy: 0.9902 - val_loss: 0.0547 - val_accuracy: 0.8889\n",
      "Epoch 282/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0092 - accuracy: 0.9804 - val_loss: 0.0520 - val_accuracy: 0.8889\n",
      "Epoch 283/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0085 - accuracy: 0.9902 - val_loss: 0.0433 - val_accuracy: 0.8889\n",
      "Epoch 284/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0104 - accuracy: 0.9902 - val_loss: 0.0457 - val_accuracy: 0.8889\n",
      "Epoch 285/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0085 - accuracy: 0.9902 - val_loss: 0.0592 - val_accuracy: 0.8889\n",
      "Epoch 286/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0106 - accuracy: 0.9804 - val_loss: 0.0628 - val_accuracy: 0.8889\n",
      "Epoch 287/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0098 - accuracy: 0.9804 - val_loss: 0.0509 - val_accuracy: 0.8889\n",
      "Epoch 288/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0092 - accuracy: 0.9902 - val_loss: 0.0427 - val_accuracy: 0.8889\n",
      "Epoch 289/800\n",
      "102/102 [==============================] - 0s 989us/sample - loss: 0.0097 - accuracy: 0.9902 - val_loss: 0.0558 - val_accuracy: 0.8889\n",
      "Epoch 290/800\n",
      "102/102 [==============================] - 0s 960us/sample - loss: 0.0090 - accuracy: 0.9902 - val_loss: 0.0656 - val_accuracy: 0.8889\n",
      "Epoch 291/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0112 - accuracy: 0.9804 - val_loss: 0.0589 - val_accuracy: 0.8889\n",
      "Epoch 292/800\n",
      "102/102 [==============================] - 0s 962us/sample - loss: 0.0086 - accuracy: 0.9902 - val_loss: 0.0463 - val_accuracy: 0.8889\n",
      "Epoch 293/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0106 - accuracy: 0.9902 - val_loss: 0.0503 - val_accuracy: 0.8889\n",
      "Epoch 294/800\n",
      "102/102 [==============================] - 0s 1000us/sample - loss: 0.0088 - accuracy: 0.9902 - val_loss: 0.0598 - val_accuracy: 0.8889\n",
      "Epoch 295/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0094 - accuracy: 0.9804 - val_loss: 0.0604 - val_accuracy: 0.8889\n",
      "Epoch 296/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0093 - accuracy: 0.9804 - val_loss: 0.0544 - val_accuracy: 0.8889\n",
      "Epoch 297/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0085 - accuracy: 0.9902 - val_loss: 0.0489 - val_accuracy: 0.8889\n",
      "Epoch 298/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0096 - accuracy: 0.9902 - val_loss: 0.0539 - val_accuracy: 0.8889\n",
      "Epoch 299/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0091 - accuracy: 0.9804 - val_loss: 0.0633 - val_accuracy: 0.8889\n",
      "Epoch 300/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0097 - accuracy: 0.9804 - val_loss: 0.0556 - val_accuracy: 0.8889\n",
      "Epoch 301/800\n",
      "102/102 [==============================] - 0s 990us/sample - loss: 0.0085 - accuracy: 0.9902 - val_loss: 0.0508 - val_accuracy: 0.8889\n",
      "Epoch 302/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0089 - accuracy: 0.9902 - val_loss: 0.0526 - val_accuracy: 0.8889\n",
      "Epoch 303/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0087 - accuracy: 0.9902 - val_loss: 0.0522 - val_accuracy: 0.8889\n",
      "Epoch 304/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0089 - accuracy: 0.9902 - val_loss: 0.0530 - val_accuracy: 0.8889\n",
      "Epoch 305/800\n",
      "102/102 [==============================] - 0s 961us/sample - loss: 0.0085 - accuracy: 0.9902 - val_loss: 0.0587 - val_accuracy: 0.8889\n",
      "Epoch 306/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0086 - accuracy: 0.9902 - val_loss: 0.0588 - val_accuracy: 0.8889\n",
      "Epoch 307/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0093 - accuracy: 0.9902 - val_loss: 0.0574 - val_accuracy: 0.8889\n",
      "Epoch 308/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0097 - accuracy: 0.9804 - val_loss: 0.0619 - val_accuracy: 0.8889\n",
      "Epoch 309/800\n",
      "102/102 [==============================] - 0s 980us/sample - loss: 0.0085 - accuracy: 0.9902 - val_loss: 0.0516 - val_accuracy: 0.8889\n",
      "Epoch 310/800\n",
      "102/102 [==============================] - 0s 990us/sample - loss: 0.0088 - accuracy: 0.9902 - val_loss: 0.0540 - val_accuracy: 0.8889\n",
      "Epoch 311/800\n",
      "102/102 [==============================] - 0s 987us/sample - loss: 0.0083 - accuracy: 0.9902 - val_loss: 0.0612 - val_accuracy: 0.8889\n",
      "Epoch 312/800\n",
      "102/102 [==============================] - 0s 987us/sample - loss: 0.0088 - accuracy: 0.9902 - val_loss: 0.0588 - val_accuracy: 0.8889\n",
      "Epoch 313/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0087 - accuracy: 0.9902 - val_loss: 0.0550 - val_accuracy: 0.8889\n",
      "Epoch 314/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0085 - accuracy: 0.9902 - val_loss: 0.0569 - val_accuracy: 0.8889\n",
      "Epoch 315/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0083 - accuracy: 0.9902 - val_loss: 0.0546 - val_accuracy: 0.8889\n",
      "Epoch 316/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0084 - accuracy: 0.9902 - val_loss: 0.0568 - val_accuracy: 0.8889\n",
      "Epoch 317/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0083 - accuracy: 0.9902 - val_loss: 0.0598 - val_accuracy: 0.8889\n",
      "Epoch 318/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0084 - accuracy: 0.9902 - val_loss: 0.0622 - val_accuracy: 0.8889\n",
      "Epoch 319/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0087 - accuracy: 0.9902 - val_loss: 0.0570 - val_accuracy: 0.8889\n",
      "Epoch 320/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0084 - accuracy: 0.9902 - val_loss: 0.0554 - val_accuracy: 0.8889\n",
      "Epoch 321/800\n",
      "102/102 [==============================] - 0s 980us/sample - loss: 0.0083 - accuracy: 0.9902 - val_loss: 0.0533 - val_accuracy: 0.8889\n",
      "Epoch 322/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0094 - accuracy: 0.9902 - val_loss: 0.0602 - val_accuracy: 0.8889\n",
      "Epoch 323/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0087 - accuracy: 0.9902 - val_loss: 0.0536 - val_accuracy: 0.8889\n",
      "Epoch 324/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0085 - accuracy: 0.9902 - val_loss: 0.0590 - val_accuracy: 0.8889\n",
      "Epoch 325/800\n",
      "102/102 [==============================] - 0s 987us/sample - loss: 0.0084 - accuracy: 0.9902 - val_loss: 0.0591 - val_accuracy: 0.8889\n",
      "Epoch 326/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0081 - accuracy: 0.9902 - val_loss: 0.0568 - val_accuracy: 0.8889\n",
      "Epoch 327/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0084 - accuracy: 0.9902 - val_loss: 0.0546 - val_accuracy: 0.8889\n",
      "Epoch 328/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0085 - accuracy: 0.9902 - val_loss: 0.0576 - val_accuracy: 0.8889\n",
      "Epoch 329/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0082 - accuracy: 0.9902 - val_loss: 0.0597 - val_accuracy: 0.8889\n",
      "Epoch 330/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0082 - accuracy: 0.9902 - val_loss: 0.0611 - val_accuracy: 0.8889\n",
      "Epoch 331/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0084 - accuracy: 0.9902 - val_loss: 0.0575 - val_accuracy: 0.8889\n",
      "Epoch 332/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0081 - accuracy: 0.9902 - val_loss: 0.0595 - val_accuracy: 0.8889\n",
      "Epoch 333/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0080 - accuracy: 0.9902 - val_loss: 0.0620 - val_accuracy: 0.8889\n",
      "Epoch 334/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0081 - accuracy: 0.9902 - val_loss: 0.0602 - val_accuracy: 0.8889\n",
      "Epoch 335/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0084 - accuracy: 0.9902 - val_loss: 0.0551 - val_accuracy: 0.8889\n",
      "Epoch 336/800\n",
      "102/102 [==============================] - 0s 989us/sample - loss: 0.0082 - accuracy: 0.9902 - val_loss: 0.0616 - val_accuracy: 0.8889\n",
      "Epoch 337/800\n",
      "102/102 [==============================] - 0s 994us/sample - loss: 0.0091 - accuracy: 0.9804 - val_loss: 0.0631 - val_accuracy: 0.8889\n",
      "Epoch 338/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0082 - accuracy: 0.9902 - val_loss: 0.0543 - val_accuracy: 0.8889\n",
      "Epoch 339/800\n",
      "102/102 [==============================] - 0s 969us/sample - loss: 0.0084 - accuracy: 0.9902 - val_loss: 0.0612 - val_accuracy: 0.8889\n",
      "Epoch 340/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0099 - accuracy: 0.9804 - val_loss: 0.0653 - val_accuracy: 0.8889\n",
      "Epoch 341/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.0082 - accuracy: 0.9902 - val_loss: 0.0522 - val_accuracy: 0.8889\n",
      "Epoch 342/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0095 - accuracy: 0.9902 - val_loss: 0.0587 - val_accuracy: 0.8889\n",
      "Epoch 343/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0077 - accuracy: 0.9902 - val_loss: 0.0646 - val_accuracy: 0.8889\n",
      "Epoch 344/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0098 - accuracy: 0.9804 - val_loss: 0.0637 - val_accuracy: 0.8889\n",
      "Epoch 345/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0076 - accuracy: 0.9902 - val_loss: 0.0493 - val_accuracy: 0.8889\n",
      "Epoch 346/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.0106 - accuracy: 0.9804 - val_loss: 0.0594 - val_accuracy: 0.8889\n",
      "Epoch 347/800\n",
      "102/102 [==============================] - 0s 957us/sample - loss: 0.0085 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.8889\n",
      "Epoch 348/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0098 - accuracy: 0.9804 - val_loss: 0.0640 - val_accuracy: 0.8889\n",
      "Epoch 349/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0083 - accuracy: 0.9902 - val_loss: 0.0567 - val_accuracy: 0.8889\n",
      "Epoch 350/800\n",
      "102/102 [==============================] - 0s 983us/sample - loss: 0.0083 - accuracy: 0.9902 - val_loss: 0.0608 - val_accuracy: 0.8889\n",
      "Epoch 351/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0079 - accuracy: 0.9902 - val_loss: 0.0638 - val_accuracy: 0.8889\n",
      "Epoch 352/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0079 - accuracy: 0.9902 - val_loss: 0.0616 - val_accuracy: 0.8889\n",
      "Epoch 353/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0079 - accuracy: 0.9902 - val_loss: 0.0611 - val_accuracy: 0.8889\n",
      "Epoch 354/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0078 - accuracy: 0.9902 - val_loss: 0.0605 - val_accuracy: 0.8889\n",
      "Epoch 355/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0079 - accuracy: 0.9902 - val_loss: 0.0602 - val_accuracy: 0.8889\n",
      "Epoch 356/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.0080 - accuracy: 0.9902 - val_loss: 0.0632 - val_accuracy: 0.8889\n",
      "Epoch 357/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0080 - accuracy: 0.9902 - val_loss: 0.0637 - val_accuracy: 0.8889\n",
      "Epoch 358/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0078 - accuracy: 0.9902 - val_loss: 0.0603 - val_accuracy: 0.8889\n",
      "Epoch 359/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0080 - accuracy: 0.9902 - val_loss: 0.0610 - val_accuracy: 0.8889\n",
      "Epoch 360/800\n",
      "102/102 [==============================] - 0s 982us/sample - loss: 0.0081 - accuracy: 0.9902 - val_loss: 0.0620 - val_accuracy: 0.8889\n",
      "Epoch 361/800\n",
      "102/102 [==============================] - 0s 987us/sample - loss: 0.0085 - accuracy: 0.9902 - val_loss: 0.0666 - val_accuracy: 0.8889\n",
      "Epoch 362/800\n",
      "102/102 [==============================] - 0s 994us/sample - loss: 0.0088 - accuracy: 0.9804 - val_loss: 0.0629 - val_accuracy: 0.8889\n",
      "Epoch 363/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0077 - accuracy: 0.9902 - val_loss: 0.0577 - val_accuracy: 0.8889\n",
      "Epoch 364/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0082 - accuracy: 0.9902 - val_loss: 0.0622 - val_accuracy: 0.8889\n",
      "Epoch 365/800\n",
      "102/102 [==============================] - 0s 987us/sample - loss: 0.0079 - accuracy: 0.9902 - val_loss: 0.0638 - val_accuracy: 0.8889\n",
      "Epoch 366/800\n",
      "102/102 [==============================] - 0s 973us/sample - loss: 0.0078 - accuracy: 0.9902 - val_loss: 0.0615 - val_accuracy: 0.8889\n",
      "Epoch 367/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0078 - accuracy: 0.9902 - val_loss: 0.0626 - val_accuracy: 0.8889\n",
      "Epoch 368/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0085 - accuracy: 0.9902 - val_loss: 0.0642 - val_accuracy: 0.8889\n",
      "Epoch 369/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0088 - accuracy: 0.9902 - val_loss: 0.0586 - val_accuracy: 0.8889\n",
      "Epoch 370/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0077 - accuracy: 0.9902 - val_loss: 0.0655 - val_accuracy: 0.8889\n",
      "Epoch 371/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0086 - accuracy: 0.9804 - val_loss: 0.0661 - val_accuracy: 0.8889\n",
      "Epoch 372/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0084 - accuracy: 0.9902 - val_loss: 0.0606 - val_accuracy: 0.8889\n",
      "Epoch 373/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0077 - accuracy: 0.9902 - val_loss: 0.0630 - val_accuracy: 0.8889\n",
      "Epoch 374/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0076 - accuracy: 0.9902 - val_loss: 0.0649 - val_accuracy: 0.8889\n",
      "Epoch 375/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0079 - accuracy: 0.9902 - val_loss: 0.0634 - val_accuracy: 0.8889\n",
      "Epoch 376/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0645 - val_accuracy: 0.8889\n",
      "Epoch 377/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.0076 - accuracy: 0.9902 - val_loss: 0.0635 - val_accuracy: 0.8889\n",
      "Epoch 378/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0079 - accuracy: 0.9902 - val_loss: 0.0639 - val_accuracy: 0.8889\n",
      "Epoch 379/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0078 - accuracy: 0.9902 - val_loss: 0.0666 - val_accuracy: 0.8889\n",
      "Epoch 380/800\n",
      "102/102 [==============================] - 0s 971us/sample - loss: 0.0081 - accuracy: 0.9902 - val_loss: 0.0639 - val_accuracy: 0.8889\n",
      "Epoch 381/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0077 - accuracy: 0.9902 - val_loss: 0.0617 - val_accuracy: 0.8889\n",
      "Epoch 382/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0076 - accuracy: 0.9902 - val_loss: 0.0649 - val_accuracy: 0.8889\n",
      "Epoch 383/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0078 - accuracy: 0.9902 - val_loss: 0.0658 - val_accuracy: 0.8889\n",
      "Epoch 384/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.0078 - accuracy: 0.9902 - val_loss: 0.0633 - val_accuracy: 0.8889\n",
      "Epoch 385/800\n",
      "102/102 [==============================] - 0s 989us/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0640 - val_accuracy: 0.8889\n",
      "Epoch 386/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0076 - accuracy: 0.9902 - val_loss: 0.0641 - val_accuracy: 0.8889\n",
      "Epoch 387/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0076 - accuracy: 0.9902 - val_loss: 0.0650 - val_accuracy: 0.8889\n",
      "Epoch 388/800\n",
      "102/102 [==============================] - 0s 983us/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0649 - val_accuracy: 0.8889\n",
      "Epoch 389/800\n",
      "102/102 [==============================] - 0s 980us/sample - loss: 0.0076 - accuracy: 0.9902 - val_loss: 0.0645 - val_accuracy: 0.8889\n",
      "Epoch 390/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0076 - accuracy: 0.9902 - val_loss: 0.0642 - val_accuracy: 0.8889\n",
      "Epoch 391/800\n",
      "102/102 [==============================] - 0s 975us/sample - loss: 0.0074 - accuracy: 0.9902 - val_loss: 0.0619 - val_accuracy: 0.8889\n",
      "Epoch 392/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0077 - accuracy: 0.9902 - val_loss: 0.0638 - val_accuracy: 0.8889\n",
      "Epoch 393/800\n",
      "102/102 [==============================] - 0s 979us/sample - loss: 0.0074 - accuracy: 0.9902 - val_loss: 0.0658 - val_accuracy: 0.8889\n",
      "Epoch 394/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0078 - accuracy: 0.9902 - val_loss: 0.0655 - val_accuracy: 0.8889\n",
      "Epoch 395/800\n",
      "102/102 [==============================] - 0s 992us/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0631 - val_accuracy: 0.8889\n",
      "Epoch 396/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0076 - accuracy: 0.9902 - val_loss: 0.0632 - val_accuracy: 0.8889\n",
      "Epoch 397/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0076 - accuracy: 0.9902 - val_loss: 0.0660 - val_accuracy: 0.8889\n",
      "Epoch 398/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0655 - val_accuracy: 0.8889\n",
      "Epoch 399/800\n",
      "102/102 [==============================] - 0s 988us/sample - loss: 0.0074 - accuracy: 0.9902 - val_loss: 0.0636 - val_accuracy: 0.8889\n",
      "Epoch 400/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0636 - val_accuracy: 0.8889\n",
      "Epoch 401/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0074 - accuracy: 0.9902 - val_loss: 0.0661 - val_accuracy: 0.8889\n",
      "Epoch 402/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.0074 - accuracy: 0.9902 - val_loss: 0.0666 - val_accuracy: 0.8889\n",
      "Epoch 403/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0650 - val_accuracy: 0.8889\n",
      "Epoch 404/800\n",
      "102/102 [==============================] - 0s 983us/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0629 - val_accuracy: 0.8889\n",
      "Epoch 405/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0662 - val_accuracy: 0.8889\n",
      "Epoch 406/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0074 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 407/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0080 - accuracy: 0.9902 - val_loss: 0.0656 - val_accuracy: 0.8889\n",
      "Epoch 408/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0079 - accuracy: 0.9902 - val_loss: 0.0541 - val_accuracy: 0.8889\n",
      "Epoch 409/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0106 - accuracy: 0.9804 - val_loss: 0.0661 - val_accuracy: 0.8889\n",
      "Epoch 410/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0089 - accuracy: 0.9804 - val_loss: 0.0711 - val_accuracy: 0.8889\n",
      "Epoch 411/800\n",
      "102/102 [==============================] - 0s 984us/sample - loss: 0.0092 - accuracy: 0.9804 - val_loss: 0.0643 - val_accuracy: 0.8889\n",
      "Epoch 412/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0079 - accuracy: 0.9902 - val_loss: 0.0578 - val_accuracy: 0.8889\n",
      "Epoch 413/800\n",
      "102/102 [==============================] - 0s 987us/sample - loss: 0.0091 - accuracy: 0.9804 - val_loss: 0.0661 - val_accuracy: 0.8889\n",
      "Epoch 414/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0103 - accuracy: 0.9804 - val_loss: 0.0711 - val_accuracy: 0.8889\n",
      "Epoch 415/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0096 - accuracy: 0.9804 - val_loss: 0.0620 - val_accuracy: 0.8889\n",
      "Epoch 416/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0081 - accuracy: 0.9902 - val_loss: 0.0636 - val_accuracy: 0.8889\n",
      "Epoch 417/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0077 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 418/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0666 - val_accuracy: 0.8889\n",
      "Epoch 419/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0651 - val_accuracy: 0.8889\n",
      "Epoch 420/800\n",
      "102/102 [==============================] - 0s 978us/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0630 - val_accuracy: 0.8889\n",
      "Epoch 421/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0077 - accuracy: 0.9902 - val_loss: 0.0668 - val_accuracy: 0.8889\n",
      "Epoch 422/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 423/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0074 - accuracy: 0.9902 - val_loss: 0.0660 - val_accuracy: 0.8889\n",
      "Epoch 424/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0655 - val_accuracy: 0.8889\n",
      "Epoch 425/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0658 - val_accuracy: 0.8889\n",
      "Epoch 426/800\n",
      "102/102 [==============================] - 0s 988us/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0659 - val_accuracy: 0.8889\n",
      "Epoch 427/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0078 - accuracy: 0.9902 - val_loss: 0.0656 - val_accuracy: 0.8889\n",
      "Epoch 428/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0085 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.8889\n",
      "Epoch 429/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0074 - accuracy: 0.9902 - val_loss: 0.0638 - val_accuracy: 0.8889\n",
      "Epoch 430/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0648 - val_accuracy: 0.8889\n",
      "Epoch 431/800\n",
      "102/102 [==============================] - 0s 989us/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0664 - val_accuracy: 0.8889\n",
      "Epoch 432/800\n",
      "102/102 [==============================] - 0s 989us/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 433/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0666 - val_accuracy: 0.8889\n",
      "Epoch 434/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0659 - val_accuracy: 0.8889\n",
      "Epoch 435/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0651 - val_accuracy: 0.8889\n",
      "Epoch 436/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0660 - val_accuracy: 0.8889\n",
      "Epoch 437/800\n",
      "102/102 [==============================] - 0s 983us/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0665 - val_accuracy: 0.8889\n",
      "Epoch 438/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0675 - val_accuracy: 0.8889\n",
      "Epoch 439/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0074 - accuracy: 0.9902 - val_loss: 0.0668 - val_accuracy: 0.8889\n",
      "Epoch 440/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.0080 - accuracy: 0.9902 - val_loss: 0.0652 - val_accuracy: 0.8889\n",
      "Epoch 441/800\n",
      "102/102 [==============================] - 0s 967us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0689 - val_accuracy: 0.8889\n",
      "Epoch 442/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0077 - accuracy: 0.9902 - val_loss: 0.0678 - val_accuracy: 0.8889\n",
      "Epoch 443/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0645 - val_accuracy: 0.8889\n",
      "Epoch 444/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0654 - val_accuracy: 0.8889\n",
      "Epoch 445/800\n",
      "102/102 [==============================] - 0s 988us/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 446/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 447/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 448/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0667 - val_accuracy: 0.8889\n",
      "Epoch 449/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0667 - val_accuracy: 0.8889\n",
      "Epoch 450/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 451/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0680 - val_accuracy: 0.8889\n",
      "Epoch 452/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0675 - val_accuracy: 0.8889\n",
      "Epoch 453/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0663 - val_accuracy: 0.8889\n",
      "Epoch 454/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0662 - val_accuracy: 0.8889\n",
      "Epoch 455/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0677 - val_accuracy: 0.8889\n",
      "Epoch 456/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0676 - val_accuracy: 0.8889\n",
      "Epoch 457/800\n",
      "102/102 [==============================] - 0s 972us/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0667 - val_accuracy: 0.8889\n",
      "Epoch 458/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0651 - val_accuracy: 0.8889\n",
      "Epoch 459/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0675 - val_accuracy: 0.8889\n",
      "Epoch 460/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 461/800\n",
      "102/102 [==============================] - 0s 988us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 462/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0677 - val_accuracy: 0.8889\n",
      "Epoch 463/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0658 - val_accuracy: 0.8889\n",
      "Epoch 464/800\n",
      "102/102 [==============================] - 0s 1000us/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0658 - val_accuracy: 0.8889\n",
      "Epoch 465/800\n",
      "102/102 [==============================] - 0s 985us/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0678 - val_accuracy: 0.8889\n",
      "Epoch 466/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0676 - val_accuracy: 0.8889\n",
      "Epoch 467/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0676 - val_accuracy: 0.8889\n",
      "Epoch 468/800\n",
      "102/102 [==============================] - 0s 975us/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 469/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0684 - val_accuracy: 0.8889\n",
      "Epoch 470/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.8889\n",
      "Epoch 471/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0678 - val_accuracy: 0.8889\n",
      "Epoch 472/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0677 - val_accuracy: 0.8889\n",
      "Epoch 473/800\n",
      "102/102 [==============================] - 0s 973us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0679 - val_accuracy: 0.8889\n",
      "Epoch 474/800\n",
      "102/102 [==============================] - 0s 994us/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 475/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0680 - val_accuracy: 0.8889\n",
      "Epoch 476/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0678 - val_accuracy: 0.8889\n",
      "Epoch 477/800\n",
      "102/102 [==============================] - 0s 987us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0666 - val_accuracy: 0.8889\n",
      "Epoch 478/800\n",
      "102/102 [==============================] - 0s 972us/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0675 - val_accuracy: 0.8889\n",
      "Epoch 479/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0679 - val_accuracy: 0.8889\n",
      "Epoch 480/800\n",
      "102/102 [==============================] - 0s 980us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0676 - val_accuracy: 0.8889\n",
      "Epoch 481/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0661 - val_accuracy: 0.8889\n",
      "Epoch 482/800\n",
      "102/102 [==============================] - 0s 972us/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0685 - val_accuracy: 0.8889\n",
      "Epoch 483/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0687 - val_accuracy: 0.8889\n",
      "Epoch 484/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 485/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 486/800\n",
      "102/102 [==============================] - 0s 984us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0679 - val_accuracy: 0.8889\n",
      "Epoch 487/800\n",
      "102/102 [==============================] - 0s 988us/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0679 - val_accuracy: 0.8889\n",
      "Epoch 488/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0676 - val_accuracy: 0.8889\n",
      "Epoch 489/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0677 - val_accuracy: 0.8889\n",
      "Epoch 490/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0676 - val_accuracy: 0.8889\n",
      "Epoch 491/800\n",
      "102/102 [==============================] - 0s 966us/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 492/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0680 - val_accuracy: 0.8889\n",
      "Epoch 493/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0689 - val_accuracy: 0.8889\n",
      "Epoch 494/800\n",
      "102/102 [==============================] - 0s 970us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0683 - val_accuracy: 0.8889\n",
      "Epoch 495/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 496/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0680 - val_accuracy: 0.8889\n",
      "Epoch 497/800\n",
      "102/102 [==============================] - 0s 994us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0701 - val_accuracy: 0.8889\n",
      "Epoch 498/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0082 - accuracy: 0.9902 - val_loss: 0.0683 - val_accuracy: 0.8889\n",
      "Epoch 499/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0074 - accuracy: 0.9902 - val_loss: 0.0668 - val_accuracy: 0.8889\n",
      "Epoch 500/800\n",
      "102/102 [==============================] - 0s 948us/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0700 - val_accuracy: 0.8889\n",
      "Epoch 501/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0077 - accuracy: 0.9902 - val_loss: 0.0688 - val_accuracy: 0.8889\n",
      "Epoch 502/800\n",
      "102/102 [==============================] - 0s 974us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 503/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 504/800\n",
      "102/102 [==============================] - 0s 958us/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0683 - val_accuracy: 0.8889\n",
      "Epoch 505/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0687 - val_accuracy: 0.8889\n",
      "Epoch 506/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 507/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0685 - val_accuracy: 0.8889\n",
      "Epoch 508/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0694 - val_accuracy: 0.8889\n",
      "Epoch 509/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0687 - val_accuracy: 0.8889\n",
      "Epoch 510/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 511/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0675 - val_accuracy: 0.8889\n",
      "Epoch 512/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0685 - val_accuracy: 0.8889\n",
      "Epoch 513/800\n",
      "102/102 [==============================] - 0s 994us/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0687 - val_accuracy: 0.8889\n",
      "Epoch 514/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0686 - val_accuracy: 0.8889\n",
      "Epoch 515/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0683 - val_accuracy: 0.8889\n",
      "Epoch 516/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0683 - val_accuracy: 0.8889\n",
      "Epoch 517/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0681 - val_accuracy: 0.8889\n",
      "Epoch 518/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0681 - val_accuracy: 0.8889\n",
      "Epoch 519/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0684 - val_accuracy: 0.8889\n",
      "Epoch 520/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0680 - val_accuracy: 0.8889\n",
      "Epoch 521/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.8889\n",
      "Epoch 522/800\n",
      "102/102 [==============================] - 0s 953us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0680 - val_accuracy: 0.8889\n",
      "Epoch 523/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.8889\n",
      "Epoch 524/800\n",
      "102/102 [==============================] - 0s 965us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0684 - val_accuracy: 0.8889\n",
      "Epoch 525/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0681 - val_accuracy: 0.8889\n",
      "Epoch 526/800\n",
      "102/102 [==============================] - 0s 991us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.8889\n",
      "Epoch 527/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0686 - val_accuracy: 0.8889\n",
      "Epoch 528/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0683 - val_accuracy: 0.8889\n",
      "Epoch 529/800\n",
      "102/102 [==============================] - 0s 978us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0683 - val_accuracy: 0.8889\n",
      "Epoch 530/800\n",
      "102/102 [==============================] - 0s 978us/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0681 - val_accuracy: 0.8889\n",
      "Epoch 531/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0685 - val_accuracy: 0.8889\n",
      "Epoch 532/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.8889\n",
      "Epoch 533/800\n",
      "102/102 [==============================] - 0s 994us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.8889\n",
      "Epoch 534/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.8889\n",
      "Epoch 535/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0683 - val_accuracy: 0.8889\n",
      "Epoch 536/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.8889\n",
      "Epoch 537/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0680 - val_accuracy: 0.8889\n",
      "Epoch 538/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0681 - val_accuracy: 0.8889\n",
      "Epoch 539/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.8889\n",
      "Epoch 540/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0683 - val_accuracy: 0.8889\n",
      "Epoch 541/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0679 - val_accuracy: 0.8889\n",
      "Epoch 542/800\n",
      "102/102 [==============================] - 0s 976us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0679 - val_accuracy: 0.8889\n",
      "Epoch 543/800\n",
      "102/102 [==============================] - 0s 981us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.8889\n",
      "Epoch 544/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0689 - val_accuracy: 0.8889\n",
      "Epoch 545/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0683 - val_accuracy: 0.8889\n",
      "Epoch 546/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0677 - val_accuracy: 0.8889\n",
      "Epoch 547/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0689 - val_accuracy: 0.8889\n",
      "Epoch 548/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.8889\n",
      "Epoch 549/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0651 - val_accuracy: 0.8889\n",
      "Epoch 550/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0081 - accuracy: 0.9902 - val_loss: 0.0686 - val_accuracy: 0.8889\n",
      "Epoch 551/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0715 - val_accuracy: 0.8889\n",
      "Epoch 552/800\n",
      "102/102 [==============================] - 0s 979us/sample - loss: 0.0099 - accuracy: 0.9804 - val_loss: 0.0667 - val_accuracy: 0.8889\n",
      "Epoch 553/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0081 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 554/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0690 - val_accuracy: 0.8889\n",
      "Epoch 555/800\n",
      "102/102 [==============================] - 0s 1000us/sample - loss: 0.0076 - accuracy: 0.9902 - val_loss: 0.0682 - val_accuracy: 0.8889\n",
      "Epoch 556/800\n",
      "102/102 [==============================] - 0s 955us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0605 - val_accuracy: 0.8889\n",
      "Epoch 557/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0129 - accuracy: 0.9804 - val_loss: 0.0692 - val_accuracy: 0.8889\n",
      "Epoch 558/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0173 - accuracy: 0.9706 - val_loss: 0.0905 - val_accuracy: 0.8333\n",
      "Epoch 559/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0164 - accuracy: 0.9608 - val_loss: 0.0394 - val_accuracy: 0.9444\n",
      "Epoch 560/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0322 - accuracy: 0.9510 - val_loss: 0.0340 - val_accuracy: 0.9444\n",
      "Epoch 561/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0290 - accuracy: 0.9608 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 562/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0149 - accuracy: 0.9706 - val_loss: 0.0996 - val_accuracy: 0.8333\n",
      "Epoch 563/800\n",
      "102/102 [==============================] - 0s 962us/sample - loss: 0.0236 - accuracy: 0.9608 - val_loss: 0.0701 - val_accuracy: 0.8889\n",
      "Epoch 564/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0081 - accuracy: 0.9902 - val_loss: 0.0377 - val_accuracy: 0.9444\n",
      "Epoch 565/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0216 - accuracy: 0.9510 - val_loss: 0.0582 - val_accuracy: 0.8889\n",
      "Epoch 566/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0850 - val_accuracy: 0.8333\n",
      "Epoch 567/800\n",
      "102/102 [==============================] - 0s 981us/sample - loss: 0.0243 - accuracy: 0.9510 - val_loss: 0.0755 - val_accuracy: 0.8889\n",
      "Epoch 568/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0148 - accuracy: 0.9804 - val_loss: 0.0375 - val_accuracy: 0.8889\n",
      "Epoch 569/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0147 - accuracy: 0.9706 - val_loss: 0.0574 - val_accuracy: 0.8889\n",
      "Epoch 570/800\n",
      "102/102 [==============================] - 0s 991us/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0657 - val_accuracy: 0.8889\n",
      "Epoch 571/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0106 - accuracy: 0.9804 - val_loss: 0.0649 - val_accuracy: 0.8889\n",
      "Epoch 572/800\n",
      "102/102 [==============================] - 0s 976us/sample - loss: 0.0103 - accuracy: 0.9804 - val_loss: 0.0563 - val_accuracy: 0.8889\n",
      "Epoch 573/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0494 - val_accuracy: 0.8889\n",
      "Epoch 574/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0081 - accuracy: 0.9902 - val_loss: 0.0569 - val_accuracy: 0.8889\n",
      "Epoch 575/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0609 - val_accuracy: 0.8889\n",
      "Epoch 576/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0620 - val_accuracy: 0.8889\n",
      "Epoch 577/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0598 - val_accuracy: 0.8889\n",
      "Epoch 578/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0599 - val_accuracy: 0.8889\n",
      "Epoch 579/800\n",
      "102/102 [==============================] - 0s 979us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0620 - val_accuracy: 0.8889\n",
      "Epoch 580/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0074 - accuracy: 0.9902 - val_loss: 0.0632 - val_accuracy: 0.8889\n",
      "Epoch 581/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0594 - val_accuracy: 0.8889\n",
      "Epoch 582/800\n",
      "102/102 [==============================] - 0s 968us/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0612 - val_accuracy: 0.8889\n",
      "Epoch 583/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0645 - val_accuracy: 0.8889\n",
      "Epoch 584/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0648 - val_accuracy: 0.8889\n",
      "Epoch 585/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0627 - val_accuracy: 0.8889\n",
      "Epoch 586/800\n",
      "102/102 [==============================] - 0s 969us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0631 - val_accuracy: 0.8889\n",
      "Epoch 587/800\n",
      "102/102 [==============================] - 0s 994us/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0654 - val_accuracy: 0.8889\n",
      "Epoch 588/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0654 - val_accuracy: 0.8889\n",
      "Epoch 589/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0640 - val_accuracy: 0.8889\n",
      "Epoch 590/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0635 - val_accuracy: 0.8889\n",
      "Epoch 591/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0662 - val_accuracy: 0.8889\n",
      "Epoch 592/800\n",
      "102/102 [==============================] - 0s 960us/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0659 - val_accuracy: 0.8889\n",
      "Epoch 593/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0649 - val_accuracy: 0.8889\n",
      "Epoch 594/800\n",
      "102/102 [==============================] - 0s 977us/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0631 - val_accuracy: 0.8889\n",
      "Epoch 595/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0641 - val_accuracy: 0.8889\n",
      "Epoch 596/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0655 - val_accuracy: 0.8889\n",
      "Epoch 597/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0641 - val_accuracy: 0.8889\n",
      "Epoch 598/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0646 - val_accuracy: 0.8889\n",
      "Epoch 599/800\n",
      "102/102 [==============================] - 0s 984us/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0653 - val_accuracy: 0.8889\n",
      "Epoch 600/800\n",
      "102/102 [==============================] - 0s 985us/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0653 - val_accuracy: 0.8889\n",
      "Epoch 601/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0629 - val_accuracy: 0.8889\n",
      "Epoch 602/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0646 - val_accuracy: 0.8889\n",
      "Epoch 603/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0666 - val_accuracy: 0.8889\n",
      "Epoch 604/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0662 - val_accuracy: 0.8889\n",
      "Epoch 605/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0654 - val_accuracy: 0.8889\n",
      "Epoch 606/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0647 - val_accuracy: 0.8889\n",
      "Epoch 607/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0069 - accuracy: 0.9902 - val_loss: 0.0647 - val_accuracy: 0.8889\n",
      "Epoch 608/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0658 - val_accuracy: 0.8889\n",
      "Epoch 609/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0660 - val_accuracy: 0.8889\n",
      "Epoch 610/800\n",
      "102/102 [==============================] - 0s 982us/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0654 - val_accuracy: 0.8889\n",
      "Epoch 611/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0652 - val_accuracy: 0.8889\n",
      "Epoch 612/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0649 - val_accuracy: 0.8889\n",
      "Epoch 613/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0652 - val_accuracy: 0.8889\n",
      "Epoch 614/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0656 - val_accuracy: 0.8889\n",
      "Epoch 615/800\n",
      "102/102 [==============================] - 0s 975us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0655 - val_accuracy: 0.8889\n",
      "Epoch 616/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0653 - val_accuracy: 0.8889\n",
      "Epoch 617/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0071 - accuracy: 0.9902 - val_loss: 0.0648 - val_accuracy: 0.8889\n",
      "Epoch 618/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 619/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0079 - accuracy: 0.9902 - val_loss: 0.0668 - val_accuracy: 0.8889\n",
      "Epoch 620/800\n",
      "102/102 [==============================] - 0s 992us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0648 - val_accuracy: 0.8889\n",
      "Epoch 621/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0645 - val_accuracy: 0.8889\n",
      "Epoch 622/800\n",
      "102/102 [==============================] - 0s 979us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0666 - val_accuracy: 0.8889\n",
      "Epoch 623/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0666 - val_accuracy: 0.8889\n",
      "Epoch 624/800\n",
      "102/102 [==============================] - 0s 991us/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0612 - val_accuracy: 0.8889\n",
      "Epoch 625/800\n",
      "102/102 [==============================] - 0s 968us/sample - loss: 0.0079 - accuracy: 0.9902 - val_loss: 0.0656 - val_accuracy: 0.8889\n",
      "Epoch 626/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0704 - val_accuracy: 0.8889\n",
      "Epoch 627/800\n",
      "102/102 [==============================] - 0s 966us/sample - loss: 0.0103 - accuracy: 0.9804 - val_loss: 0.0684 - val_accuracy: 0.8889\n",
      "Epoch 628/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0644 - val_accuracy: 0.8889\n",
      "Epoch 629/800\n",
      "102/102 [==============================] - 0s 975us/sample - loss: 0.0074 - accuracy: 0.9902 - val_loss: 0.0608 - val_accuracy: 0.8889\n",
      "Epoch 630/800\n",
      "102/102 [==============================] - 0s 982us/sample - loss: 0.0076 - accuracy: 0.9902 - val_loss: 0.0659 - val_accuracy: 0.8889\n",
      "Epoch 631/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0700 - val_accuracy: 0.8889\n",
      "Epoch 632/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0099 - accuracy: 0.9804 - val_loss: 0.0677 - val_accuracy: 0.8889\n",
      "Epoch 633/800\n",
      "102/102 [==============================] - 0s 983us/sample - loss: 0.0074 - accuracy: 0.9902 - val_loss: 0.0615 - val_accuracy: 0.8889\n",
      "Epoch 634/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0095 - accuracy: 0.9804 - val_loss: 0.0656 - val_accuracy: 0.8889\n",
      "Epoch 635/800\n",
      "102/102 [==============================] - 0s 970us/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0681 - val_accuracy: 0.8889\n",
      "Epoch 636/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0085 - accuracy: 0.9804 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 637/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0630 - val_accuracy: 0.8889\n",
      "Epoch 638/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0647 - val_accuracy: 0.8889\n",
      "Epoch 639/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0663 - val_accuracy: 0.8889\n",
      "Epoch 640/800\n",
      "102/102 [==============================] - 0s 970us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 641/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0666 - val_accuracy: 0.8889\n",
      "Epoch 642/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0637 - val_accuracy: 0.8889\n",
      "Epoch 643/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0649 - val_accuracy: 0.8889\n",
      "Epoch 644/800\n",
      "102/102 [==============================] - 0s 989us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 645/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0082 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 646/800\n",
      "102/102 [==============================] - 0s 971us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0567 - val_accuracy: 0.8889\n",
      "Epoch 647/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0134 - accuracy: 0.9706 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 648/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0075 - accuracy: 0.9902 - val_loss: 0.0714 - val_accuracy: 0.8889\n",
      "Epoch 649/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0105 - accuracy: 0.9804 - val_loss: 0.0664 - val_accuracy: 0.8889\n",
      "Epoch 650/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0617 - val_accuracy: 0.8889\n",
      "Epoch 651/800\n",
      "102/102 [==============================] - 0s 979us/sample - loss: 0.0084 - accuracy: 0.9902 - val_loss: 0.0657 - val_accuracy: 0.8889\n",
      "Epoch 652/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0677 - val_accuracy: 0.8889\n",
      "Epoch 653/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0083 - accuracy: 0.9804 - val_loss: 0.0667 - val_accuracy: 0.8889\n",
      "Epoch 654/800\n",
      "102/102 [==============================] - 0s 976us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0566 - val_accuracy: 0.8889\n",
      "Epoch 655/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0092 - accuracy: 0.9804 - val_loss: 0.0647 - val_accuracy: 0.8889\n",
      "Epoch 656/800\n",
      "102/102 [==============================] - 0s 980us/sample - loss: 0.0074 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 657/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0658 - val_accuracy: 0.8889\n",
      "Epoch 658/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0638 - val_accuracy: 0.8889\n",
      "Epoch 659/800\n",
      "102/102 [==============================] - 0s 974us/sample - loss: 0.0073 - accuracy: 0.9902 - val_loss: 0.0652 - val_accuracy: 0.8889\n",
      "Epoch 660/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 661/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0668 - val_accuracy: 0.8889\n",
      "Epoch 662/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0628 - val_accuracy: 0.8889\n",
      "Epoch 663/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0081 - accuracy: 0.9902 - val_loss: 0.0651 - val_accuracy: 0.8889\n",
      "Epoch 664/800\n",
      "102/102 [==============================] - 0s 975us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0696 - val_accuracy: 0.8889\n",
      "Epoch 665/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0095 - accuracy: 0.9804 - val_loss: 0.0677 - val_accuracy: 0.8889\n",
      "Epoch 666/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0658 - val_accuracy: 0.8889\n",
      "Epoch 667/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0626 - val_accuracy: 0.8889\n",
      "Epoch 668/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0082 - accuracy: 0.9902 - val_loss: 0.0654 - val_accuracy: 0.8889\n",
      "Epoch 669/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0676 - val_accuracy: 0.8889\n",
      "Epoch 670/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0072 - accuracy: 0.9902 - val_loss: 0.0675 - val_accuracy: 0.8889\n",
      "Epoch 671/800\n",
      "102/102 [==============================] - 0s 981us/sample - loss: 0.0070 - accuracy: 0.9902 - val_loss: 0.0661 - val_accuracy: 0.8889\n",
      "Epoch 672/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0650 - val_accuracy: 0.8889\n",
      "Epoch 673/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0653 - val_accuracy: 0.8889\n",
      "Epoch 674/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0659 - val_accuracy: 0.8889\n",
      "Epoch 675/800\n",
      "102/102 [==============================] - 0s 990us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 676/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 677/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0667 - val_accuracy: 0.8889\n",
      "Epoch 678/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0661 - val_accuracy: 0.8889\n",
      "Epoch 679/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0659 - val_accuracy: 0.8889\n",
      "Epoch 680/800\n",
      "102/102 [==============================] - 0s 958us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0662 - val_accuracy: 0.8889\n",
      "Epoch 681/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0666 - val_accuracy: 0.8889\n",
      "Epoch 682/800\n",
      "102/102 [==============================] - 0s 960us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0667 - val_accuracy: 0.8889\n",
      "Epoch 683/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0667 - val_accuracy: 0.8889\n",
      "Epoch 684/800\n",
      "102/102 [==============================] - 0s 984us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0666 - val_accuracy: 0.8889\n",
      "Epoch 685/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0663 - val_accuracy: 0.8889\n",
      "Epoch 686/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0660 - val_accuracy: 0.8889\n",
      "Epoch 687/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0663 - val_accuracy: 0.8889\n",
      "Epoch 688/800\n",
      "102/102 [==============================] - 0s 987us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0664 - val_accuracy: 0.8889\n",
      "Epoch 689/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0668 - val_accuracy: 0.8889\n",
      "Epoch 690/800\n",
      "102/102 [==============================] - 0s 969us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0667 - val_accuracy: 0.8889\n",
      "Epoch 691/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0659 - val_accuracy: 0.8889\n",
      "Epoch 692/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0657 - val_accuracy: 0.8889\n",
      "Epoch 693/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0663 - val_accuracy: 0.8889\n",
      "Epoch 694/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0668 - val_accuracy: 0.8889\n",
      "Epoch 695/800\n",
      "102/102 [==============================] - 0s 984us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0667 - val_accuracy: 0.8889\n",
      "Epoch 696/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0662 - val_accuracy: 0.8889\n",
      "Epoch 697/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0663 - val_accuracy: 0.8889\n",
      "Epoch 698/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 699/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 700/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0662 - val_accuracy: 0.8889\n",
      "Epoch 701/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0661 - val_accuracy: 0.8889\n",
      "Epoch 702/800\n",
      "102/102 [==============================] - 0s 1000us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 703/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 704/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0664 - val_accuracy: 0.8889\n",
      "Epoch 705/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0661 - val_accuracy: 0.8889\n",
      "Epoch 706/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 707/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0677 - val_accuracy: 0.8889\n",
      "Epoch 708/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 709/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0665 - val_accuracy: 0.8889\n",
      "Epoch 710/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0661 - val_accuracy: 0.8889\n",
      "Epoch 711/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0067 - accuracy: 0.9902 - val_loss: 0.0666 - val_accuracy: 0.8889\n",
      "Epoch 712/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 713/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 714/800\n",
      "102/102 [==============================] - 0s 965us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0668 - val_accuracy: 0.8889\n",
      "Epoch 715/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 716/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 717/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 718/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 719/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 720/800\n",
      "102/102 [==============================] - 0s 981us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 721/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 722/800\n",
      "102/102 [==============================] - 0s 983us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 723/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 724/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 725/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 726/800\n",
      "102/102 [==============================] - 0s 990us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0668 - val_accuracy: 0.8889\n",
      "Epoch 727/800\n",
      "102/102 [==============================] - 0s 975us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 728/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 729/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0675 - val_accuracy: 0.8889\n",
      "Epoch 730/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0675 - val_accuracy: 0.8889\n",
      "Epoch 731/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 732/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 733/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 734/800\n",
      "102/102 [==============================] - 0s 980us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 735/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 736/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 737/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 738/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 739/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0677 - val_accuracy: 0.8889\n",
      "Epoch 740/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 741/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 742/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0668 - val_accuracy: 0.8889\n",
      "Epoch 743/800\n",
      "102/102 [==============================] - 0s 953us/sample - loss: 0.0066 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 744/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 745/800\n",
      "102/102 [==============================] - 0s 990us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 746/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 747/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 748/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 749/800\n",
      "102/102 [==============================] - 0s 988us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0675 - val_accuracy: 0.8889\n",
      "Epoch 750/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 751/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 752/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 753/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 754/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 755/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 756/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 757/800\n",
      "102/102 [==============================] - 0s 988us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 758/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 759/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 760/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 761/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 762/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 763/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 764/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 765/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 766/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 767/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 768/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0675 - val_accuracy: 0.8889\n",
      "Epoch 769/800\n",
      "102/102 [==============================] - 0s 984us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0677 - val_accuracy: 0.8889\n",
      "Epoch 770/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 771/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 772/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 773/800\n",
      "102/102 [==============================] - 0s 994us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 774/800\n",
      "102/102 [==============================] - 0s 970us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n",
      "Epoch 775/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0674 - val_accuracy: 0.8889\n",
      "Epoch 776/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0676 - val_accuracy: 0.8889\n",
      "Epoch 777/800\n",
      "102/102 [==============================] - 0s 992us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 778/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0672 - val_accuracy: 0.8889\n",
      "Epoch 779/800\n",
      "102/102 [==============================] - 0s 971us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 780/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 781/800\n",
      "102/102 [==============================] - 0s 979us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 782/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 783/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 784/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0668 - val_accuracy: 0.8889\n",
      "Epoch 785/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0665 - val_accuracy: 0.8889\n",
      "Epoch 786/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0666 - val_accuracy: 0.8889\n",
      "Epoch 787/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 788/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 789/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0668 - val_accuracy: 0.8889\n",
      "Epoch 790/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0667 - val_accuracy: 0.8889\n",
      "Epoch 791/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 792/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 793/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0669 - val_accuracy: 0.8889\n",
      "Epoch 794/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0667 - val_accuracy: 0.8889\n",
      "Epoch 795/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0667 - val_accuracy: 0.8889\n",
      "Epoch 796/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 797/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 798/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0673 - val_accuracy: 0.8889\n",
      "Epoch 799/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0671 - val_accuracy: 0.8889\n",
      "Epoch 800/800\n",
      "102/102 [==============================] - 0s 978us/sample - loss: 0.0065 - accuracy: 0.9902 - val_loss: 0.0670 - val_accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "# Run your function to train the model\n",
    "\n",
    "history = train_model(model, train_data, train_targets, epochs=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves\n",
    "\n",
    "We will now plot two graphs:\n",
    "* Epoch vs accuracy\n",
    "* Epoch vs loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to plot the epoch vs accuracy graph\n",
    "\n",
    "try:\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "except KeyError:\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "plt.title('Accuracy vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Run this cell to plot the epoch vs loss graph\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no! We have overfit our dataset. You should now try to now try to mitigate this overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing overfitting in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now define a new regularised model.\n",
    "The specs for the regularised model are the same as our original model, with the addition of two dropout layers, weight decay, and a batch normalisation layer. \n",
    "\n",
    "In particular:\n",
    "\n",
    "* Add a dropout layer after the 3rd Dense layer\n",
    "* Then there should be two more Dense layers with 128 units before a batch normalisation layer\n",
    "* Following this, two more Dense layers with 64 units and then another Dropout layer\n",
    "* Two more Dense layers with 64 units and then the final 3-way softmax layer\n",
    "* Add weight decay (l2 kernel regularisation) in all Dense layers except the final softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def get_regularised_model(input_shape, dropout_rate, weight_decay):\n",
    "    \"\"\"\n",
    "    This function should build a regularised Sequential model according to the above specification. \n",
    "    The dropout_rate argument in the function should be used to set the Dropout rate for all Dropout layers.\n",
    "    L2 kernel regularisation (weight decay) should be added using the weight_decay argument to \n",
    "    set the weight decay coefficient in all Dense layers that use L2 regularisation.\n",
    "    Ensure the weights are initialised by providing the input_shape argument in the first layer, given by the\n",
    "    function argument input_shape.\n",
    "    Your function should return the model.\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import BatchNormalization, Dropout, Input, Dense\n",
    "    from tensorflow.keras import regularizers\n",
    "\n",
    "    model = Sequential([\n",
    "                        Input(shape=input_shape),\n",
    "                        Dense(64,kernel_regularizer=regularizers.l2(weight_decay),\n",
    "                              kernel_initializer='he_uniform', bias_initializer='ones',\n",
    "                              input_shape = input_shape, activation='relu'),\n",
    "                        Dense(128, kernel_regularizer=regularizers.l2(weight_decay),activation='relu'),\n",
    "                        Dense(128,kernel_regularizer=regularizers.l2(weight_decay), activation='relu'),\n",
    "                        Dropout(dropout_rate),\n",
    "                        BatchNormalization(),\n",
    "                        Dense(128, kernel_regularizer=regularizers.l2(weight_decay),activation='relu'),\n",
    "                        Dense(128,kernel_regularizer=regularizers.l2(weight_decay), activation='relu'),\n",
    "                        Dense(64, kernel_regularizer=regularizers.l2(weight_decay),activation='relu'),\n",
    "                        Dense(64, kernel_regularizer=regularizers.l2(weight_decay),activation='relu'),\n",
    "                        Dropout(dropout_rate),\n",
    "                        Dense(64, kernel_regularizer=regularizers.l2(weight_decay),activation='relu'),\n",
    "                        Dense(64,kernel_regularizer=regularizers.l2(weight_decay), activation='relu'),\n",
    "                        Dense(3, activation='softmax')\n",
    "                        \n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate, compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, using a dropout rate of 0.3 and weight decay coefficient of 0.001\n",
    "\n",
    "reg_model = get_regularised_model(train_data[0].shape, 0.3, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "compile_model(reg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102 samples, validate on 18 samples\n",
      "Epoch 1/800\n",
      "102/102 [==============================] - 3s 27ms/sample - loss: 1.0955 - accuracy: 0.4510 - val_loss: 1.0838 - val_accuracy: 0.3333\n",
      "Epoch 2/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 1.0933 - accuracy: 0.3725 - val_loss: 1.0806 - val_accuracy: 0.3333\n",
      "Epoch 3/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 1.0850 - accuracy: 0.4412 - val_loss: 1.0776 - val_accuracy: 0.3333\n",
      "Epoch 4/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 1.0829 - accuracy: 0.4412 - val_loss: 1.0757 - val_accuracy: 0.3333\n",
      "Epoch 5/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 1.0783 - accuracy: 0.4804 - val_loss: 1.0736 - val_accuracy: 0.3333\n",
      "Epoch 6/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 1.0722 - accuracy: 0.5098 - val_loss: 1.0716 - val_accuracy: 0.3333\n",
      "Epoch 7/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 1.0670 - accuracy: 0.5588 - val_loss: 1.0698 - val_accuracy: 0.3333\n",
      "Epoch 8/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 1.0630 - accuracy: 0.5294 - val_loss: 1.0676 - val_accuracy: 0.3333\n",
      "Epoch 9/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 1.0485 - accuracy: 0.5686 - val_loss: 1.0656 - val_accuracy: 0.3333\n",
      "Epoch 10/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 1.0496 - accuracy: 0.6176 - val_loss: 1.0634 - val_accuracy: 0.3333\n",
      "Epoch 11/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 1.0437 - accuracy: 0.5882 - val_loss: 1.0612 - val_accuracy: 0.3333\n",
      "Epoch 12/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 1.0419 - accuracy: 0.6275 - val_loss: 1.0589 - val_accuracy: 0.3333\n",
      "Epoch 13/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 1.0336 - accuracy: 0.6667 - val_loss: 1.0561 - val_accuracy: 0.3333\n",
      "Epoch 14/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 1.0292 - accuracy: 0.6471 - val_loss: 1.0531 - val_accuracy: 0.3333\n",
      "Epoch 15/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 1.0174 - accuracy: 0.6961 - val_loss: 1.0505 - val_accuracy: 0.3333\n",
      "Epoch 16/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 1.0125 - accuracy: 0.6275 - val_loss: 1.0476 - val_accuracy: 0.3333\n",
      "Epoch 17/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 1.0069 - accuracy: 0.6863 - val_loss: 1.0441 - val_accuracy: 0.3889\n",
      "Epoch 18/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 1.0091 - accuracy: 0.6569 - val_loss: 1.0400 - val_accuracy: 0.5000\n",
      "Epoch 19/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.9953 - accuracy: 0.7255 - val_loss: 1.0354 - val_accuracy: 0.5556\n",
      "Epoch 20/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.9859 - accuracy: 0.7157 - val_loss: 1.0308 - val_accuracy: 0.5556\n",
      "Epoch 21/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.9870 - accuracy: 0.6863 - val_loss: 1.0262 - val_accuracy: 0.5556\n",
      "Epoch 22/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.9753 - accuracy: 0.7157 - val_loss: 1.0210 - val_accuracy: 0.5556\n",
      "Epoch 23/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.9767 - accuracy: 0.6961 - val_loss: 1.0158 - val_accuracy: 0.5556\n",
      "Epoch 24/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.9642 - accuracy: 0.7255 - val_loss: 1.0099 - val_accuracy: 0.5556\n",
      "Epoch 25/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.9522 - accuracy: 0.7255 - val_loss: 1.0047 - val_accuracy: 0.5556\n",
      "Epoch 26/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.9553 - accuracy: 0.7157 - val_loss: 1.0000 - val_accuracy: 0.5556\n",
      "Epoch 27/800\n",
      "102/102 [==============================] - 0s 976us/sample - loss: 0.9494 - accuracy: 0.7255 - val_loss: 0.9950 - val_accuracy: 0.5556\n",
      "Epoch 28/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.9349 - accuracy: 0.7255 - val_loss: 0.9899 - val_accuracy: 0.5556\n",
      "Epoch 29/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.9348 - accuracy: 0.7157 - val_loss: 0.9850 - val_accuracy: 0.5556\n",
      "Epoch 30/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.9374 - accuracy: 0.7157 - val_loss: 0.9804 - val_accuracy: 0.5556\n",
      "Epoch 31/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.9243 - accuracy: 0.7157 - val_loss: 0.9757 - val_accuracy: 0.5556\n",
      "Epoch 32/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.9195 - accuracy: 0.7451 - val_loss: 0.9714 - val_accuracy: 0.5556\n",
      "Epoch 33/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.9180 - accuracy: 0.7059 - val_loss: 0.9671 - val_accuracy: 0.5556\n",
      "Epoch 34/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.9124 - accuracy: 0.7745 - val_loss: 0.9624 - val_accuracy: 0.5556\n",
      "Epoch 35/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.9067 - accuracy: 0.7353 - val_loss: 0.9580 - val_accuracy: 0.5556\n",
      "Epoch 36/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.9062 - accuracy: 0.7745 - val_loss: 0.9532 - val_accuracy: 0.5556\n",
      "Epoch 37/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.8917 - accuracy: 0.7549 - val_loss: 0.9487 - val_accuracy: 0.5556\n",
      "Epoch 38/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8937 - accuracy: 0.7549 - val_loss: 0.9446 - val_accuracy: 0.5556\n",
      "Epoch 39/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.8906 - accuracy: 0.7451 - val_loss: 0.9410 - val_accuracy: 0.6111\n",
      "Epoch 40/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8855 - accuracy: 0.7647 - val_loss: 0.9373 - val_accuracy: 0.6111\n",
      "Epoch 41/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8816 - accuracy: 0.7549 - val_loss: 0.9331 - val_accuracy: 0.6111\n",
      "Epoch 42/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.8783 - accuracy: 0.8137 - val_loss: 0.9286 - val_accuracy: 0.6111\n",
      "Epoch 43/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8782 - accuracy: 0.7745 - val_loss: 0.9243 - val_accuracy: 0.6111\n",
      "Epoch 44/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8714 - accuracy: 0.8235 - val_loss: 0.9199 - val_accuracy: 0.6667\n",
      "Epoch 45/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8662 - accuracy: 0.8431 - val_loss: 0.9158 - val_accuracy: 0.6667\n",
      "Epoch 46/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8697 - accuracy: 0.8627 - val_loss: 0.9120 - val_accuracy: 0.7222\n",
      "Epoch 47/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.8631 - accuracy: 0.8431 - val_loss: 0.9081 - val_accuracy: 0.7222\n",
      "Epoch 48/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8593 - accuracy: 0.8529 - val_loss: 0.9036 - val_accuracy: 0.7778\n",
      "Epoch 49/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8595 - accuracy: 0.8529 - val_loss: 0.8996 - val_accuracy: 0.8333\n",
      "Epoch 50/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8530 - accuracy: 0.9118 - val_loss: 0.8955 - val_accuracy: 0.8333\n",
      "Epoch 51/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8549 - accuracy: 0.8529 - val_loss: 0.8917 - val_accuracy: 0.8889\n",
      "Epoch 52/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8438 - accuracy: 0.9314 - val_loss: 0.8876 - val_accuracy: 0.8889\n",
      "Epoch 53/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8372 - accuracy: 0.9314 - val_loss: 0.8829 - val_accuracy: 0.8889\n",
      "Epoch 54/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8398 - accuracy: 0.8922 - val_loss: 0.8787 - val_accuracy: 0.9444\n",
      "Epoch 55/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8375 - accuracy: 0.9020 - val_loss: 0.8740 - val_accuracy: 0.9444\n",
      "Epoch 56/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8359 - accuracy: 0.9412 - val_loss: 0.8700 - val_accuracy: 0.9444\n",
      "Epoch 57/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.8324 - accuracy: 0.9510 - val_loss: 0.8668 - val_accuracy: 0.9444\n",
      "Epoch 58/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8326 - accuracy: 0.9510 - val_loss: 0.8643 - val_accuracy: 1.0000\n",
      "Epoch 59/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.8248 - accuracy: 0.9608 - val_loss: 0.8609 - val_accuracy: 0.9444\n",
      "Epoch 60/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8262 - accuracy: 0.9412 - val_loss: 0.8573 - val_accuracy: 1.0000\n",
      "Epoch 61/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8257 - accuracy: 0.8824 - val_loss: 0.8531 - val_accuracy: 1.0000\n",
      "Epoch 62/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.8160 - accuracy: 0.9608 - val_loss: 0.8478 - val_accuracy: 0.9444\n",
      "Epoch 63/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8062 - accuracy: 0.9608 - val_loss: 0.8454 - val_accuracy: 0.9444\n",
      "Epoch 64/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8163 - accuracy: 0.9510 - val_loss: 0.8414 - val_accuracy: 0.9444\n",
      "Epoch 65/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7968 - accuracy: 0.9804 - val_loss: 0.8364 - val_accuracy: 0.9444\n",
      "Epoch 66/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.8044 - accuracy: 0.9412 - val_loss: 0.8316 - val_accuracy: 0.9444\n",
      "Epoch 67/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.7990 - accuracy: 0.9706 - val_loss: 0.8290 - val_accuracy: 0.9444\n",
      "Epoch 68/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7851 - accuracy: 0.9804 - val_loss: 0.8271 - val_accuracy: 0.9444\n",
      "Epoch 69/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7856 - accuracy: 0.9804 - val_loss: 0.8280 - val_accuracy: 0.8889\n",
      "Epoch 70/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.7824 - accuracy: 0.9706 - val_loss: 0.8278 - val_accuracy: 0.8889\n",
      "Epoch 71/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7740 - accuracy: 0.9706 - val_loss: 0.8251 - val_accuracy: 0.8889\n",
      "Epoch 72/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7775 - accuracy: 0.9706 - val_loss: 0.8205 - val_accuracy: 0.8889\n",
      "Epoch 73/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7744 - accuracy: 0.9706 - val_loss: 0.8149 - val_accuracy: 0.8889\n",
      "Epoch 74/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7764 - accuracy: 0.9608 - val_loss: 0.8118 - val_accuracy: 0.8889\n",
      "Epoch 75/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.7664 - accuracy: 0.9804 - val_loss: 0.8038 - val_accuracy: 0.8889\n",
      "Epoch 76/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7678 - accuracy: 0.9804 - val_loss: 0.7972 - val_accuracy: 0.8889\n",
      "Epoch 77/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7583 - accuracy: 0.9902 - val_loss: 0.7894 - val_accuracy: 0.9444\n",
      "Epoch 78/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7557 - accuracy: 0.9804 - val_loss: 0.7848 - val_accuracy: 0.9444\n",
      "Epoch 79/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7605 - accuracy: 0.9608 - val_loss: 0.7810 - val_accuracy: 0.9444\n",
      "Epoch 80/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7495 - accuracy: 0.9804 - val_loss: 0.7783 - val_accuracy: 1.0000\n",
      "Epoch 81/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7512 - accuracy: 0.9804 - val_loss: 0.7774 - val_accuracy: 0.9444\n",
      "Epoch 82/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7496 - accuracy: 0.9706 - val_loss: 0.7753 - val_accuracy: 0.9444\n",
      "Epoch 83/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.7485 - accuracy: 0.9804 - val_loss: 0.7728 - val_accuracy: 0.9444\n",
      "Epoch 84/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7500 - accuracy: 0.9706 - val_loss: 0.7724 - val_accuracy: 0.8889\n",
      "Epoch 85/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7405 - accuracy: 0.9804 - val_loss: 0.7764 - val_accuracy: 0.8889\n",
      "Epoch 86/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.7451 - accuracy: 0.9706 - val_loss: 0.7747 - val_accuracy: 0.8889\n",
      "Epoch 87/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7403 - accuracy: 0.9608 - val_loss: 0.7666 - val_accuracy: 0.8889\n",
      "Epoch 88/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7371 - accuracy: 0.9706 - val_loss: 0.7603 - val_accuracy: 0.9444\n",
      "Epoch 89/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.7340 - accuracy: 0.9804 - val_loss: 0.7577 - val_accuracy: 0.9444\n",
      "Epoch 90/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7339 - accuracy: 0.9706 - val_loss: 0.7558 - val_accuracy: 0.9444\n",
      "Epoch 91/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7278 - accuracy: 0.9804 - val_loss: 0.7618 - val_accuracy: 0.8889\n",
      "Epoch 92/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7256 - accuracy: 0.9804 - val_loss: 0.7692 - val_accuracy: 0.8889\n",
      "Epoch 93/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7301 - accuracy: 0.9706 - val_loss: 0.7691 - val_accuracy: 0.8889\n",
      "Epoch 94/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.7204 - accuracy: 0.9902 - val_loss: 0.7661 - val_accuracy: 0.8889\n",
      "Epoch 95/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7301 - accuracy: 0.9412 - val_loss: 0.7513 - val_accuracy: 0.8889\n",
      "Epoch 96/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7290 - accuracy: 0.9510 - val_loss: 0.7460 - val_accuracy: 0.8889\n",
      "Epoch 97/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.7164 - accuracy: 0.9706 - val_loss: 0.7422 - val_accuracy: 0.8889\n",
      "Epoch 98/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7151 - accuracy: 0.9706 - val_loss: 0.7402 - val_accuracy: 0.8889\n",
      "Epoch 99/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7164 - accuracy: 0.9804 - val_loss: 0.7406 - val_accuracy: 0.8889\n",
      "Epoch 100/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.7179 - accuracy: 0.9804 - val_loss: 0.7371 - val_accuracy: 0.8889\n",
      "Epoch 101/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7110 - accuracy: 0.9706 - val_loss: 0.7305 - val_accuracy: 0.9444\n",
      "Epoch 102/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.7167 - accuracy: 0.9706 - val_loss: 0.7267 - val_accuracy: 0.9444\n",
      "Epoch 103/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7095 - accuracy: 0.9706 - val_loss: 0.7284 - val_accuracy: 0.8889\n",
      "Epoch 104/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7056 - accuracy: 0.9804 - val_loss: 0.7311 - val_accuracy: 0.8889\n",
      "Epoch 105/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.7092 - accuracy: 0.9706 - val_loss: 0.7321 - val_accuracy: 0.8889\n",
      "Epoch 106/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.7014 - accuracy: 0.9804 - val_loss: 0.7313 - val_accuracy: 0.8889\n",
      "Epoch 107/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.7061 - accuracy: 0.9608 - val_loss: 0.7372 - val_accuracy: 0.8889\n",
      "Epoch 108/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6964 - accuracy: 0.9902 - val_loss: 0.7461 - val_accuracy: 0.8889\n",
      "Epoch 109/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6996 - accuracy: 0.9804 - val_loss: 0.7384 - val_accuracy: 0.8889\n",
      "Epoch 110/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.7034 - accuracy: 0.9706 - val_loss: 0.7308 - val_accuracy: 0.8889\n",
      "Epoch 111/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6952 - accuracy: 0.9706 - val_loss: 0.7212 - val_accuracy: 0.8889\n",
      "Epoch 112/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6943 - accuracy: 0.9804 - val_loss: 0.7148 - val_accuracy: 0.9444\n",
      "Epoch 113/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6939 - accuracy: 0.9804 - val_loss: 0.7123 - val_accuracy: 0.9444\n",
      "Epoch 114/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6901 - accuracy: 0.9804 - val_loss: 0.7116 - val_accuracy: 0.9444\n",
      "Epoch 115/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6872 - accuracy: 0.9804 - val_loss: 0.7118 - val_accuracy: 0.8889\n",
      "Epoch 116/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6902 - accuracy: 0.9706 - val_loss: 0.7153 - val_accuracy: 0.8889\n",
      "Epoch 117/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6832 - accuracy: 0.9804 - val_loss: 0.7179 - val_accuracy: 0.8889\n",
      "Epoch 118/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6857 - accuracy: 0.9804 - val_loss: 0.7192 - val_accuracy: 0.8889\n",
      "Epoch 119/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6769 - accuracy: 0.9902 - val_loss: 0.7215 - val_accuracy: 0.8889\n",
      "Epoch 120/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6778 - accuracy: 0.9902 - val_loss: 0.7229 - val_accuracy: 0.8889\n",
      "Epoch 121/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6791 - accuracy: 0.9804 - val_loss: 0.7156 - val_accuracy: 0.8889\n",
      "Epoch 122/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6760 - accuracy: 0.9804 - val_loss: 0.7076 - val_accuracy: 0.8889\n",
      "Epoch 123/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6753 - accuracy: 0.9804 - val_loss: 0.7036 - val_accuracy: 0.8889\n",
      "Epoch 124/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6787 - accuracy: 0.9608 - val_loss: 0.6969 - val_accuracy: 0.8889\n",
      "Epoch 125/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6789 - accuracy: 0.9706 - val_loss: 0.6929 - val_accuracy: 0.9444\n",
      "Epoch 126/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6723 - accuracy: 0.9706 - val_loss: 0.6917 - val_accuracy: 0.9444\n",
      "Epoch 127/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6726 - accuracy: 0.9608 - val_loss: 0.6894 - val_accuracy: 0.9444\n",
      "Epoch 128/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6734 - accuracy: 0.9706 - val_loss: 0.6876 - val_accuracy: 0.9444\n",
      "Epoch 129/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6661 - accuracy: 0.9804 - val_loss: 0.6830 - val_accuracy: 0.9444\n",
      "Epoch 130/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6678 - accuracy: 0.9804 - val_loss: 0.6835 - val_accuracy: 0.9444\n",
      "Epoch 131/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6687 - accuracy: 0.9706 - val_loss: 0.6849 - val_accuracy: 0.8889\n",
      "Epoch 132/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6635 - accuracy: 0.9804 - val_loss: 0.6920 - val_accuracy: 0.8889\n",
      "Epoch 133/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6610 - accuracy: 0.9804 - val_loss: 0.6987 - val_accuracy: 0.8889\n",
      "Epoch 134/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6614 - accuracy: 0.9706 - val_loss: 0.7070 - val_accuracy: 0.8889\n",
      "Epoch 135/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6580 - accuracy: 0.9706 - val_loss: 0.7077 - val_accuracy: 0.8889\n",
      "Epoch 136/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6588 - accuracy: 0.9706 - val_loss: 0.6999 - val_accuracy: 0.8889\n",
      "Epoch 137/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6563 - accuracy: 0.9804 - val_loss: 0.6872 - val_accuracy: 0.8889\n",
      "Epoch 138/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6549 - accuracy: 0.9706 - val_loss: 0.6823 - val_accuracy: 0.8889\n",
      "Epoch 139/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6541 - accuracy: 0.9706 - val_loss: 0.6826 - val_accuracy: 0.8889\n",
      "Epoch 140/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6511 - accuracy: 0.9706 - val_loss: 0.6856 - val_accuracy: 0.8889\n",
      "Epoch 141/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6490 - accuracy: 0.9804 - val_loss: 0.6858 - val_accuracy: 0.8889\n",
      "Epoch 142/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6455 - accuracy: 0.9804 - val_loss: 0.6811 - val_accuracy: 0.8889\n",
      "Epoch 143/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6417 - accuracy: 0.9902 - val_loss: 0.6829 - val_accuracy: 0.8889\n",
      "Epoch 144/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6409 - accuracy: 0.9902 - val_loss: 0.6829 - val_accuracy: 0.8889\n",
      "Epoch 145/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6402 - accuracy: 0.9804 - val_loss: 0.6818 - val_accuracy: 0.8889\n",
      "Epoch 146/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6429 - accuracy: 0.9804 - val_loss: 0.6802 - val_accuracy: 0.8889\n",
      "Epoch 147/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6448 - accuracy: 0.9608 - val_loss: 0.6700 - val_accuracy: 0.8889\n",
      "Epoch 148/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6387 - accuracy: 0.9804 - val_loss: 0.6644 - val_accuracy: 0.8889\n",
      "Epoch 149/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6319 - accuracy: 0.9902 - val_loss: 0.6675 - val_accuracy: 0.8889\n",
      "Epoch 150/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6365 - accuracy: 0.9804 - val_loss: 0.6710 - val_accuracy: 0.8889\n",
      "Epoch 151/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6304 - accuracy: 0.9902 - val_loss: 0.6774 - val_accuracy: 0.8889\n",
      "Epoch 152/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6406 - accuracy: 0.9608 - val_loss: 0.6737 - val_accuracy: 0.8889\n",
      "Epoch 153/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6354 - accuracy: 0.9608 - val_loss: 0.6585 - val_accuracy: 0.8889\n",
      "Epoch 154/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6292 - accuracy: 0.9804 - val_loss: 0.6512 - val_accuracy: 0.9444\n",
      "Epoch 155/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6303 - accuracy: 0.9706 - val_loss: 0.6527 - val_accuracy: 0.8889\n",
      "Epoch 156/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6298 - accuracy: 0.9608 - val_loss: 0.6659 - val_accuracy: 0.8889\n",
      "Epoch 157/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6218 - accuracy: 0.9804 - val_loss: 0.6710 - val_accuracy: 0.8889\n",
      "Epoch 158/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6269 - accuracy: 0.9804 - val_loss: 0.6722 - val_accuracy: 0.8889\n",
      "Epoch 159/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6185 - accuracy: 0.9902 - val_loss: 0.6722 - val_accuracy: 0.8889\n",
      "Epoch 160/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6225 - accuracy: 0.9706 - val_loss: 0.6671 - val_accuracy: 0.8889\n",
      "Epoch 161/800\n",
      "102/102 [==============================] - 0s 962us/sample - loss: 0.6194 - accuracy: 0.9804 - val_loss: 0.6591 - val_accuracy: 0.8889\n",
      "Epoch 162/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6210 - accuracy: 0.9706 - val_loss: 0.6438 - val_accuracy: 0.8889\n",
      "Epoch 163/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6226 - accuracy: 0.9706 - val_loss: 0.6393 - val_accuracy: 0.8889\n",
      "Epoch 164/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6157 - accuracy: 0.9804 - val_loss: 0.6361 - val_accuracy: 0.8889\n",
      "Epoch 165/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6188 - accuracy: 0.9706 - val_loss: 0.6342 - val_accuracy: 0.9444\n",
      "Epoch 166/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6148 - accuracy: 0.9804 - val_loss: 0.6353 - val_accuracy: 0.9444\n",
      "Epoch 167/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6107 - accuracy: 0.9804 - val_loss: 0.6413 - val_accuracy: 0.8889\n",
      "Epoch 168/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6090 - accuracy: 0.9804 - val_loss: 0.6487 - val_accuracy: 0.8889\n",
      "Epoch 169/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.6069 - accuracy: 0.9804 - val_loss: 0.6543 - val_accuracy: 0.8889\n",
      "Epoch 170/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6052 - accuracy: 0.9804 - val_loss: 0.6540 - val_accuracy: 0.8889\n",
      "Epoch 171/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6065 - accuracy: 0.9804 - val_loss: 0.6459 - val_accuracy: 0.8889\n",
      "Epoch 172/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6037 - accuracy: 0.9804 - val_loss: 0.6434 - val_accuracy: 0.8889\n",
      "Epoch 173/800\n",
      "102/102 [==============================] - 0s 988us/sample - loss: 0.6026 - accuracy: 0.9804 - val_loss: 0.6423 - val_accuracy: 0.8889\n",
      "Epoch 174/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6017 - accuracy: 0.9706 - val_loss: 0.6442 - val_accuracy: 0.8889\n",
      "Epoch 175/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5994 - accuracy: 0.9804 - val_loss: 0.6405 - val_accuracy: 0.8889\n",
      "Epoch 176/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.6009 - accuracy: 0.9804 - val_loss: 0.6368 - val_accuracy: 0.8889\n",
      "Epoch 177/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5956 - accuracy: 0.9706 - val_loss: 0.6341 - val_accuracy: 0.8889\n",
      "Epoch 178/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5971 - accuracy: 0.9804 - val_loss: 0.6399 - val_accuracy: 0.8889\n",
      "Epoch 179/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.5916 - accuracy: 0.9902 - val_loss: 0.6444 - val_accuracy: 0.8889\n",
      "Epoch 180/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5893 - accuracy: 0.9902 - val_loss: 0.6476 - val_accuracy: 0.8889\n",
      "Epoch 181/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5897 - accuracy: 0.9902 - val_loss: 0.6402 - val_accuracy: 0.8889\n",
      "Epoch 182/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5840 - accuracy: 1.0000 - val_loss: 0.6393 - val_accuracy: 0.8889\n",
      "Epoch 183/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5902 - accuracy: 0.9706 - val_loss: 0.6348 - val_accuracy: 0.8889\n",
      "Epoch 184/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5895 - accuracy: 0.9804 - val_loss: 0.6200 - val_accuracy: 0.8889\n",
      "Epoch 185/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5843 - accuracy: 0.9804 - val_loss: 0.6120 - val_accuracy: 0.8889\n",
      "Epoch 186/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5852 - accuracy: 0.9902 - val_loss: 0.6080 - val_accuracy: 0.9444\n",
      "Epoch 187/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5811 - accuracy: 0.9804 - val_loss: 0.6105 - val_accuracy: 0.8889\n",
      "Epoch 188/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5860 - accuracy: 0.9608 - val_loss: 0.6061 - val_accuracy: 0.8889\n",
      "Epoch 189/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5872 - accuracy: 0.9706 - val_loss: 0.6038 - val_accuracy: 0.8889\n",
      "Epoch 190/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5815 - accuracy: 0.9706 - val_loss: 0.6121 - val_accuracy: 0.8889\n",
      "Epoch 191/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5841 - accuracy: 0.9608 - val_loss: 0.6322 - val_accuracy: 0.8889\n",
      "Epoch 192/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5927 - accuracy: 0.9510 - val_loss: 0.6437 - val_accuracy: 0.8333\n",
      "Epoch 193/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5751 - accuracy: 0.9902 - val_loss: 0.6427 - val_accuracy: 0.8889\n",
      "Epoch 194/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5905 - accuracy: 0.9510 - val_loss: 0.6297 - val_accuracy: 0.8889\n",
      "Epoch 195/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5733 - accuracy: 0.9902 - val_loss: 0.6179 - val_accuracy: 0.8889\n",
      "Epoch 196/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5700 - accuracy: 0.9902 - val_loss: 0.6121 - val_accuracy: 0.8889\n",
      "Epoch 197/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5782 - accuracy: 0.9706 - val_loss: 0.6026 - val_accuracy: 0.8889\n",
      "Epoch 198/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5758 - accuracy: 0.9804 - val_loss: 0.5983 - val_accuracy: 0.8889\n",
      "Epoch 199/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5710 - accuracy: 0.9804 - val_loss: 0.6028 - val_accuracy: 0.8889\n",
      "Epoch 200/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5702 - accuracy: 0.9706 - val_loss: 0.6109 - val_accuracy: 0.8889\n",
      "Epoch 201/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5678 - accuracy: 0.9804 - val_loss: 0.6257 - val_accuracy: 0.8889\n",
      "Epoch 202/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5742 - accuracy: 0.9608 - val_loss: 0.6287 - val_accuracy: 0.8333\n",
      "Epoch 203/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5719 - accuracy: 0.9706 - val_loss: 0.6143 - val_accuracy: 0.8889\n",
      "Epoch 204/800\n",
      "102/102 [==============================] - 0s 985us/sample - loss: 0.5637 - accuracy: 0.9902 - val_loss: 0.6142 - val_accuracy: 0.8889\n",
      "Epoch 205/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5784 - accuracy: 0.9510 - val_loss: 0.6043 - val_accuracy: 0.8889\n",
      "Epoch 206/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5572 - accuracy: 0.9902 - val_loss: 0.6079 - val_accuracy: 0.8889\n",
      "Epoch 207/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5649 - accuracy: 0.9608 - val_loss: 0.6348 - val_accuracy: 0.8333\n",
      "Epoch 208/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5648 - accuracy: 0.9706 - val_loss: 0.6552 - val_accuracy: 0.7778\n",
      "Epoch 209/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5565 - accuracy: 0.9902 - val_loss: 0.6493 - val_accuracy: 0.7778\n",
      "Epoch 210/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5635 - accuracy: 0.9608 - val_loss: 0.6376 - val_accuracy: 0.7778\n",
      "Epoch 211/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5616 - accuracy: 0.9706 - val_loss: 0.6331 - val_accuracy: 0.8333\n",
      "Epoch 212/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.5517 - accuracy: 0.9902 - val_loss: 0.6416 - val_accuracy: 0.7778\n",
      "Epoch 213/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5563 - accuracy: 0.9706 - val_loss: 0.6515 - val_accuracy: 0.7778\n",
      "Epoch 214/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5559 - accuracy: 0.9804 - val_loss: 0.6506 - val_accuracy: 0.7778\n",
      "Epoch 215/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5472 - accuracy: 0.9804 - val_loss: 0.6488 - val_accuracy: 0.7778\n",
      "Epoch 216/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5592 - accuracy: 0.9608 - val_loss: 0.6405 - val_accuracy: 0.7778\n",
      "Epoch 217/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5451 - accuracy: 0.9902 - val_loss: 0.6257 - val_accuracy: 0.7778\n",
      "Epoch 218/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5434 - accuracy: 0.9804 - val_loss: 0.6148 - val_accuracy: 0.8889\n",
      "Epoch 219/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5502 - accuracy: 0.9706 - val_loss: 0.6051 - val_accuracy: 0.8889\n",
      "Epoch 220/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5477 - accuracy: 0.9804 - val_loss: 0.5959 - val_accuracy: 0.8889\n",
      "Epoch 221/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5456 - accuracy: 0.9706 - val_loss: 0.5908 - val_accuracy: 0.8889\n",
      "Epoch 222/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5467 - accuracy: 0.9706 - val_loss: 0.5853 - val_accuracy: 0.8889\n",
      "Epoch 223/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5449 - accuracy: 0.9706 - val_loss: 0.5811 - val_accuracy: 0.8889\n",
      "Epoch 224/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5407 - accuracy: 0.9804 - val_loss: 0.5799 - val_accuracy: 0.8889\n",
      "Epoch 225/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5389 - accuracy: 0.9804 - val_loss: 0.5833 - val_accuracy: 0.8889\n",
      "Epoch 226/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5403 - accuracy: 0.9706 - val_loss: 0.5822 - val_accuracy: 0.8889\n",
      "Epoch 227/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5386 - accuracy: 0.9804 - val_loss: 0.5826 - val_accuracy: 0.8889\n",
      "Epoch 228/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5379 - accuracy: 0.9804 - val_loss: 0.5860 - val_accuracy: 0.8889\n",
      "Epoch 229/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5395 - accuracy: 0.9804 - val_loss: 0.5745 - val_accuracy: 0.8889\n",
      "Epoch 230/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5355 - accuracy: 0.9804 - val_loss: 0.5671 - val_accuracy: 0.8889\n",
      "Epoch 231/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5319 - accuracy: 0.9804 - val_loss: 0.5755 - val_accuracy: 0.8889\n",
      "Epoch 232/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5324 - accuracy: 0.9902 - val_loss: 0.5804 - val_accuracy: 0.8889\n",
      "Epoch 233/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5292 - accuracy: 0.9902 - val_loss: 0.5775 - val_accuracy: 0.8889\n",
      "Epoch 234/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5396 - accuracy: 0.9510 - val_loss: 0.5801 - val_accuracy: 0.8889\n",
      "Epoch 235/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5292 - accuracy: 0.9804 - val_loss: 0.5894 - val_accuracy: 0.8889\n",
      "Epoch 236/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5265 - accuracy: 0.9804 - val_loss: 0.5941 - val_accuracy: 0.8889\n",
      "Epoch 237/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5265 - accuracy: 0.9804 - val_loss: 0.5876 - val_accuracy: 0.8889\n",
      "Epoch 238/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5218 - accuracy: 0.9902 - val_loss: 0.5844 - val_accuracy: 0.8889\n",
      "Epoch 239/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5231 - accuracy: 0.9804 - val_loss: 0.5780 - val_accuracy: 0.8889\n",
      "Epoch 240/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5223 - accuracy: 0.9804 - val_loss: 0.5742 - val_accuracy: 0.8889\n",
      "Epoch 241/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5192 - accuracy: 0.9902 - val_loss: 0.5723 - val_accuracy: 0.8889\n",
      "Epoch 242/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5233 - accuracy: 0.9804 - val_loss: 0.5705 - val_accuracy: 0.8889\n",
      "Epoch 243/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5207 - accuracy: 0.9804 - val_loss: 0.5623 - val_accuracy: 0.8889\n",
      "Epoch 244/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5231 - accuracy: 0.9706 - val_loss: 0.5602 - val_accuracy: 0.8889\n",
      "Epoch 245/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5146 - accuracy: 0.9902 - val_loss: 0.5559 - val_accuracy: 0.8889\n",
      "Epoch 246/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5171 - accuracy: 0.9804 - val_loss: 0.5568 - val_accuracy: 0.8889\n",
      "Epoch 247/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5153 - accuracy: 0.9804 - val_loss: 0.5624 - val_accuracy: 0.8889\n",
      "Epoch 248/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5158 - accuracy: 0.9706 - val_loss: 0.5667 - val_accuracy: 0.8889\n",
      "Epoch 249/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5142 - accuracy: 0.9804 - val_loss: 0.5621 - val_accuracy: 0.8889\n",
      "Epoch 250/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5094 - accuracy: 0.9902 - val_loss: 0.5584 - val_accuracy: 0.8889\n",
      "Epoch 251/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5156 - accuracy: 0.9706 - val_loss: 0.5566 - val_accuracy: 0.8889\n",
      "Epoch 252/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5125 - accuracy: 0.9902 - val_loss: 0.5534 - val_accuracy: 0.8333\n",
      "Epoch 253/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.9804 - val_loss: 0.5506 - val_accuracy: 0.7778\n",
      "Epoch 254/800\n",
      "102/102 [==============================] - 0s 989us/sample - loss: 0.5120 - accuracy: 0.9706 - val_loss: 0.5482 - val_accuracy: 0.8889\n",
      "Epoch 255/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5141 - accuracy: 0.9706 - val_loss: 0.5472 - val_accuracy: 0.8889\n",
      "Epoch 256/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5117 - accuracy: 0.9706 - val_loss: 0.5558 - val_accuracy: 0.8889\n",
      "Epoch 257/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5054 - accuracy: 0.9804 - val_loss: 0.5590 - val_accuracy: 0.8889\n",
      "Epoch 258/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.5013 - accuracy: 0.9902 - val_loss: 0.5553 - val_accuracy: 0.8889\n",
      "Epoch 259/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5069 - accuracy: 0.9706 - val_loss: 0.5436 - val_accuracy: 0.8889\n",
      "Epoch 260/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5027 - accuracy: 0.9804 - val_loss: 0.5357 - val_accuracy: 0.8889\n",
      "Epoch 261/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5027 - accuracy: 0.9608 - val_loss: 0.5276 - val_accuracy: 0.8889\n",
      "Epoch 262/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5039 - accuracy: 0.9706 - val_loss: 0.5225 - val_accuracy: 0.8889\n",
      "Epoch 263/800\n",
      "102/102 [==============================] - 0s 994us/sample - loss: 0.4977 - accuracy: 0.9804 - val_loss: 0.5214 - val_accuracy: 0.8889\n",
      "Epoch 264/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4953 - accuracy: 0.9804 - val_loss: 0.5337 - val_accuracy: 0.8889\n",
      "Epoch 265/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4967 - accuracy: 0.9804 - val_loss: 0.5465 - val_accuracy: 0.8889\n",
      "Epoch 266/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5002 - accuracy: 0.9706 - val_loss: 0.5539 - val_accuracy: 0.8333\n",
      "Epoch 267/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.5026 - accuracy: 0.9804 - val_loss: 0.5368 - val_accuracy: 0.8889\n",
      "Epoch 268/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4929 - accuracy: 0.9804 - val_loss: 0.5252 - val_accuracy: 0.8889\n",
      "Epoch 269/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4914 - accuracy: 0.9804 - val_loss: 0.5296 - val_accuracy: 0.8889\n",
      "Epoch 270/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.5011 - accuracy: 0.9706 - val_loss: 0.5256 - val_accuracy: 0.8333\n",
      "Epoch 271/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4899 - accuracy: 0.9804 - val_loss: 0.5255 - val_accuracy: 0.8333\n",
      "Epoch 272/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4917 - accuracy: 0.9804 - val_loss: 0.5231 - val_accuracy: 0.8333\n",
      "Epoch 273/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4859 - accuracy: 0.9902 - val_loss: 0.5247 - val_accuracy: 0.8889\n",
      "Epoch 274/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.4868 - accuracy: 0.9804 - val_loss: 0.5283 - val_accuracy: 0.8889\n",
      "Epoch 275/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4835 - accuracy: 0.9902 - val_loss: 0.5296 - val_accuracy: 0.8889\n",
      "Epoch 276/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4882 - accuracy: 0.9804 - val_loss: 0.5303 - val_accuracy: 0.8889\n",
      "Epoch 277/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4910 - accuracy: 0.9706 - val_loss: 0.5230 - val_accuracy: 0.8889\n",
      "Epoch 278/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4898 - accuracy: 0.9706 - val_loss: 0.5188 - val_accuracy: 0.8889\n",
      "Epoch 279/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4859 - accuracy: 0.9804 - val_loss: 0.5216 - val_accuracy: 0.8889\n",
      "Epoch 280/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4806 - accuracy: 0.9902 - val_loss: 0.5220 - val_accuracy: 0.8889\n",
      "Epoch 281/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4904 - accuracy: 0.9608 - val_loss: 0.5116 - val_accuracy: 0.8333\n",
      "Epoch 282/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4814 - accuracy: 0.9804 - val_loss: 0.5037 - val_accuracy: 0.8889\n",
      "Epoch 283/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4801 - accuracy: 0.9804 - val_loss: 0.5063 - val_accuracy: 0.8889\n",
      "Epoch 284/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4799 - accuracy: 0.9804 - val_loss: 0.5091 - val_accuracy: 0.8889\n",
      "Epoch 285/800\n",
      "102/102 [==============================] - 0s 1000us/sample - loss: 0.4784 - accuracy: 0.9804 - val_loss: 0.5185 - val_accuracy: 0.8889\n",
      "Epoch 286/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4755 - accuracy: 0.9902 - val_loss: 0.5243 - val_accuracy: 0.8889\n",
      "Epoch 287/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4721 - accuracy: 0.9902 - val_loss: 0.5281 - val_accuracy: 0.8889\n",
      "Epoch 288/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4811 - accuracy: 0.9608 - val_loss: 0.5287 - val_accuracy: 0.8889\n",
      "Epoch 289/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4731 - accuracy: 0.9804 - val_loss: 0.5196 - val_accuracy: 0.8889\n",
      "Epoch 290/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4670 - accuracy: 0.9902 - val_loss: 0.5174 - val_accuracy: 0.8889\n",
      "Epoch 291/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4746 - accuracy: 0.9804 - val_loss: 0.5211 - val_accuracy: 0.8889\n",
      "Epoch 292/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4754 - accuracy: 0.9804 - val_loss: 0.5175 - val_accuracy: 0.8889\n",
      "Epoch 293/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.4688 - accuracy: 0.9804 - val_loss: 0.5040 - val_accuracy: 0.8889\n",
      "Epoch 294/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4698 - accuracy: 0.9804 - val_loss: 0.5018 - val_accuracy: 0.8889\n",
      "Epoch 295/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4622 - accuracy: 0.9902 - val_loss: 0.5223 - val_accuracy: 0.8889\n",
      "Epoch 296/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4709 - accuracy: 0.9706 - val_loss: 0.5312 - val_accuracy: 0.8889\n",
      "Epoch 297/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4684 - accuracy: 0.9804 - val_loss: 0.5276 - val_accuracy: 0.8889\n",
      "Epoch 298/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4652 - accuracy: 0.9804 - val_loss: 0.5222 - val_accuracy: 0.8889\n",
      "Epoch 299/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4678 - accuracy: 0.9510 - val_loss: 0.5319 - val_accuracy: 0.8889\n",
      "Epoch 300/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4632 - accuracy: 0.9804 - val_loss: 0.5498 - val_accuracy: 0.7778\n",
      "Epoch 301/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4659 - accuracy: 0.9804 - val_loss: 0.5398 - val_accuracy: 0.7778\n",
      "Epoch 302/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4643 - accuracy: 0.9706 - val_loss: 0.5074 - val_accuracy: 0.8889\n",
      "Epoch 303/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4631 - accuracy: 0.9706 - val_loss: 0.4887 - val_accuracy: 0.8889\n",
      "Epoch 304/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.4626 - accuracy: 0.9804 - val_loss: 0.4803 - val_accuracy: 0.9444\n",
      "Epoch 305/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4643 - accuracy: 0.9804 - val_loss: 0.4759 - val_accuracy: 0.9444\n",
      "Epoch 306/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4614 - accuracy: 0.9804 - val_loss: 0.4730 - val_accuracy: 0.9444\n",
      "Epoch 307/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4568 - accuracy: 0.9804 - val_loss: 0.4718 - val_accuracy: 0.9444\n",
      "Epoch 308/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4589 - accuracy: 0.9804 - val_loss: 0.4733 - val_accuracy: 0.9444\n",
      "Epoch 309/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4578 - accuracy: 0.9706 - val_loss: 0.4766 - val_accuracy: 0.8889\n",
      "Epoch 310/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4551 - accuracy: 0.9706 - val_loss: 0.4953 - val_accuracy: 0.8889\n",
      "Epoch 311/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4538 - accuracy: 0.9804 - val_loss: 0.5241 - val_accuracy: 0.8889\n",
      "Epoch 312/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.4564 - accuracy: 0.9608 - val_loss: 0.5183 - val_accuracy: 0.8889\n",
      "Epoch 313/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4546 - accuracy: 0.9804 - val_loss: 0.5121 - val_accuracy: 0.8889\n",
      "Epoch 314/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4558 - accuracy: 0.9706 - val_loss: 0.5103 - val_accuracy: 0.8889\n",
      "Epoch 315/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4556 - accuracy: 0.9706 - val_loss: 0.5073 - val_accuracy: 0.8889\n",
      "Epoch 316/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4588 - accuracy: 0.9608 - val_loss: 0.4969 - val_accuracy: 0.8889\n",
      "Epoch 317/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4494 - accuracy: 0.9804 - val_loss: 0.4789 - val_accuracy: 0.8889\n",
      "Epoch 318/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4512 - accuracy: 0.9804 - val_loss: 0.4681 - val_accuracy: 0.8889\n",
      "Epoch 319/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4512 - accuracy: 0.9804 - val_loss: 0.4670 - val_accuracy: 0.9444\n",
      "Epoch 320/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4511 - accuracy: 0.9804 - val_loss: 0.4698 - val_accuracy: 0.9444\n",
      "Epoch 321/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4527 - accuracy: 0.9706 - val_loss: 0.4703 - val_accuracy: 0.8889\n",
      "Epoch 322/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4479 - accuracy: 0.9804 - val_loss: 0.4657 - val_accuracy: 0.9444\n",
      "Epoch 323/800\n",
      "102/102 [==============================] - 0s 980us/sample - loss: 0.4395 - accuracy: 0.9902 - val_loss: 0.4666 - val_accuracy: 0.9444\n",
      "Epoch 324/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4594 - accuracy: 0.9510 - val_loss: 0.4725 - val_accuracy: 0.8889\n",
      "Epoch 325/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4414 - accuracy: 0.9804 - val_loss: 0.4805 - val_accuracy: 0.8889\n",
      "Epoch 326/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4407 - accuracy: 0.9706 - val_loss: 0.4968 - val_accuracy: 0.8889\n",
      "Epoch 327/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4407 - accuracy: 0.9804 - val_loss: 0.5139 - val_accuracy: 0.8333\n",
      "Epoch 328/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4466 - accuracy: 0.9706 - val_loss: 0.5139 - val_accuracy: 0.8333\n",
      "Epoch 329/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.4365 - accuracy: 0.9804 - val_loss: 0.4954 - val_accuracy: 0.8889\n",
      "Epoch 330/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4429 - accuracy: 0.9804 - val_loss: 0.4803 - val_accuracy: 0.8889\n",
      "Epoch 331/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4435 - accuracy: 0.9706 - val_loss: 0.4798 - val_accuracy: 0.8889\n",
      "Epoch 332/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4394 - accuracy: 0.9804 - val_loss: 0.4807 - val_accuracy: 0.8889\n",
      "Epoch 333/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4355 - accuracy: 0.9804 - val_loss: 0.4820 - val_accuracy: 0.8889\n",
      "Epoch 334/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4354 - accuracy: 0.9804 - val_loss: 0.4873 - val_accuracy: 0.8889\n",
      "Epoch 335/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4389 - accuracy: 0.9706 - val_loss: 0.4949 - val_accuracy: 0.8889\n",
      "Epoch 336/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4318 - accuracy: 0.9902 - val_loss: 0.5034 - val_accuracy: 0.8889\n",
      "Epoch 337/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4321 - accuracy: 0.9804 - val_loss: 0.5031 - val_accuracy: 0.8889\n",
      "Epoch 338/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4280 - accuracy: 0.9902 - val_loss: 0.4993 - val_accuracy: 0.8889\n",
      "Epoch 339/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4337 - accuracy: 0.9706 - val_loss: 0.5032 - val_accuracy: 0.8333\n",
      "Epoch 340/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4355 - accuracy: 0.9706 - val_loss: 0.4871 - val_accuracy: 0.8889\n",
      "Epoch 341/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4297 - accuracy: 0.9804 - val_loss: 0.4718 - val_accuracy: 0.8889\n",
      "Epoch 342/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4305 - accuracy: 0.9804 - val_loss: 0.4552 - val_accuracy: 0.8333\n",
      "Epoch 343/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4258 - accuracy: 0.9804 - val_loss: 0.4529 - val_accuracy: 0.8889\n",
      "Epoch 344/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4304 - accuracy: 0.9706 - val_loss: 0.4521 - val_accuracy: 0.9444\n",
      "Epoch 345/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4282 - accuracy: 0.9804 - val_loss: 0.4534 - val_accuracy: 0.8889\n",
      "Epoch 346/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4243 - accuracy: 0.9902 - val_loss: 0.4553 - val_accuracy: 0.8889\n",
      "Epoch 347/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4243 - accuracy: 0.9804 - val_loss: 0.4516 - val_accuracy: 0.8889\n",
      "Epoch 348/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4276 - accuracy: 0.9804 - val_loss: 0.4500 - val_accuracy: 0.9444\n",
      "Epoch 349/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4228 - accuracy: 0.9804 - val_loss: 0.4595 - val_accuracy: 0.8889\n",
      "Epoch 350/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4272 - accuracy: 0.9706 - val_loss: 0.4637 - val_accuracy: 0.8889\n",
      "Epoch 351/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4228 - accuracy: 0.9902 - val_loss: 0.4695 - val_accuracy: 0.8889\n",
      "Epoch 352/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4190 - accuracy: 0.9902 - val_loss: 0.4808 - val_accuracy: 0.8889\n",
      "Epoch 353/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4201 - accuracy: 0.9804 - val_loss: 0.4805 - val_accuracy: 0.8889\n",
      "Epoch 354/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4222 - accuracy: 0.9706 - val_loss: 0.4711 - val_accuracy: 0.8889\n",
      "Epoch 355/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4159 - accuracy: 0.9902 - val_loss: 0.4661 - val_accuracy: 0.8889\n",
      "Epoch 356/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4160 - accuracy: 0.9902 - val_loss: 0.4655 - val_accuracy: 0.8889\n",
      "Epoch 357/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4129 - accuracy: 0.9902 - val_loss: 0.4716 - val_accuracy: 0.8889\n",
      "Epoch 358/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4166 - accuracy: 0.9804 - val_loss: 0.4733 - val_accuracy: 0.8889\n",
      "Epoch 359/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4200 - accuracy: 0.9804 - val_loss: 0.4756 - val_accuracy: 0.8889\n",
      "Epoch 360/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4204 - accuracy: 0.9706 - val_loss: 0.4658 - val_accuracy: 0.8889\n",
      "Epoch 361/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4168 - accuracy: 0.9804 - val_loss: 0.4621 - val_accuracy: 0.8889\n",
      "Epoch 362/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4131 - accuracy: 0.9804 - val_loss: 0.4675 - val_accuracy: 0.8889\n",
      "Epoch 363/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4121 - accuracy: 0.9902 - val_loss: 0.4702 - val_accuracy: 0.8889\n",
      "Epoch 364/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.4085 - accuracy: 0.9902 - val_loss: 0.4750 - val_accuracy: 0.8889\n",
      "Epoch 365/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4022 - accuracy: 1.0000 - val_loss: 0.4871 - val_accuracy: 0.7778\n",
      "Epoch 366/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4113 - accuracy: 0.9902 - val_loss: 0.4950 - val_accuracy: 0.7778\n",
      "Epoch 367/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4146 - accuracy: 0.9706 - val_loss: 0.4950 - val_accuracy: 0.7778\n",
      "Epoch 368/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4111 - accuracy: 0.9804 - val_loss: 0.4767 - val_accuracy: 0.8889\n",
      "Epoch 369/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4059 - accuracy: 0.9902 - val_loss: 0.4613 - val_accuracy: 0.8889\n",
      "Epoch 370/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4078 - accuracy: 0.9902 - val_loss: 0.4523 - val_accuracy: 0.8889\n",
      "Epoch 371/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4002 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.8889\n",
      "Epoch 372/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4050 - accuracy: 0.9804 - val_loss: 0.4471 - val_accuracy: 0.8333\n",
      "Epoch 373/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4082 - accuracy: 0.9706 - val_loss: 0.4462 - val_accuracy: 0.8333\n",
      "Epoch 374/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4039 - accuracy: 0.9902 - val_loss: 0.4431 - val_accuracy: 0.8333\n",
      "Epoch 375/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4056 - accuracy: 0.9804 - val_loss: 0.4438 - val_accuracy: 0.8889\n",
      "Epoch 376/800\n",
      "102/102 [==============================] - 0s 983us/sample - loss: 0.4020 - accuracy: 0.9902 - val_loss: 0.4480 - val_accuracy: 0.8889\n",
      "Epoch 377/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3983 - accuracy: 0.9902 - val_loss: 0.4531 - val_accuracy: 0.8889\n",
      "Epoch 378/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4010 - accuracy: 0.9804 - val_loss: 0.4495 - val_accuracy: 0.8889\n",
      "Epoch 379/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4000 - accuracy: 0.9804 - val_loss: 0.4400 - val_accuracy: 0.8889\n",
      "Epoch 380/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3997 - accuracy: 0.9902 - val_loss: 0.4291 - val_accuracy: 0.8889\n",
      "Epoch 381/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4022 - accuracy: 0.9804 - val_loss: 0.4256 - val_accuracy: 0.9444\n",
      "Epoch 382/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3953 - accuracy: 0.9804 - val_loss: 0.4340 - val_accuracy: 0.8889\n",
      "Epoch 383/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3978 - accuracy: 0.9804 - val_loss: 0.4406 - val_accuracy: 0.8889\n",
      "Epoch 384/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.4059 - accuracy: 0.9608 - val_loss: 0.4285 - val_accuracy: 0.8889\n",
      "Epoch 385/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3951 - accuracy: 0.9902 - val_loss: 0.4250 - val_accuracy: 0.8889\n",
      "Epoch 386/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3907 - accuracy: 0.9902 - val_loss: 0.4326 - val_accuracy: 0.8889\n",
      "Epoch 387/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3955 - accuracy: 0.9804 - val_loss: 0.4416 - val_accuracy: 0.8889\n",
      "Epoch 388/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3995 - accuracy: 0.9608 - val_loss: 0.4364 - val_accuracy: 0.8889\n",
      "Epoch 389/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.3950 - accuracy: 0.9804 - val_loss: 0.4319 - val_accuracy: 0.8889\n",
      "Epoch 390/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3910 - accuracy: 0.9804 - val_loss: 0.4331 - val_accuracy: 0.8889\n",
      "Epoch 391/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3985 - accuracy: 0.9804 - val_loss: 0.4361 - val_accuracy: 0.8889\n",
      "Epoch 392/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3935 - accuracy: 0.9804 - val_loss: 0.4446 - val_accuracy: 0.8889\n",
      "Epoch 393/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.4009 - accuracy: 0.9412 - val_loss: 0.4454 - val_accuracy: 0.8889\n",
      "Epoch 394/800\n",
      "102/102 [==============================] - 0s 992us/sample - loss: 0.3899 - accuracy: 0.9902 - val_loss: 0.4562 - val_accuracy: 0.8889\n",
      "Epoch 395/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3866 - accuracy: 0.9804 - val_loss: 0.4643 - val_accuracy: 0.8333\n",
      "Epoch 396/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3906 - accuracy: 0.9706 - val_loss: 0.4690 - val_accuracy: 0.8333\n",
      "Epoch 397/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3904 - accuracy: 0.9706 - val_loss: 0.4846 - val_accuracy: 0.7778\n",
      "Epoch 398/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3902 - accuracy: 0.9902 - val_loss: 0.4865 - val_accuracy: 0.7778\n",
      "Epoch 399/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3867 - accuracy: 0.9902 - val_loss: 0.4694 - val_accuracy: 0.8333\n",
      "Epoch 400/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3904 - accuracy: 0.9804 - val_loss: 0.4450 - val_accuracy: 0.8889\n",
      "Epoch 401/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3864 - accuracy: 0.9804 - val_loss: 0.4397 - val_accuracy: 0.8889\n",
      "Epoch 402/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3881 - accuracy: 0.9804 - val_loss: 0.4348 - val_accuracy: 0.8889\n",
      "Epoch 403/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3852 - accuracy: 0.9706 - val_loss: 0.4304 - val_accuracy: 0.8889\n",
      "Epoch 404/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3839 - accuracy: 0.9706 - val_loss: 0.4319 - val_accuracy: 0.8889\n",
      "Epoch 405/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3857 - accuracy: 0.9706 - val_loss: 0.4323 - val_accuracy: 0.8889\n",
      "Epoch 406/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.3833 - accuracy: 0.9902 - val_loss: 0.4377 - val_accuracy: 0.7778\n",
      "Epoch 407/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3827 - accuracy: 0.9804 - val_loss: 0.4378 - val_accuracy: 0.7778\n",
      "Epoch 408/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.3801 - accuracy: 0.9804 - val_loss: 0.4363 - val_accuracy: 0.7778\n",
      "Epoch 409/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3856 - accuracy: 0.9706 - val_loss: 0.4333 - val_accuracy: 0.8889\n",
      "Epoch 410/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3879 - accuracy: 0.9706 - val_loss: 0.4290 - val_accuracy: 0.8889\n",
      "Epoch 411/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3801 - accuracy: 0.9804 - val_loss: 0.4172 - val_accuracy: 0.8889\n",
      "Epoch 412/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3797 - accuracy: 0.9804 - val_loss: 0.4071 - val_accuracy: 0.8889\n",
      "Epoch 413/800\n",
      "102/102 [==============================] - 0s 985us/sample - loss: 0.3781 - accuracy: 0.9902 - val_loss: 0.4255 - val_accuracy: 0.8333\n",
      "Epoch 414/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3763 - accuracy: 0.9902 - val_loss: 0.4304 - val_accuracy: 0.8333\n",
      "Epoch 415/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3834 - accuracy: 0.9804 - val_loss: 0.4273 - val_accuracy: 0.8333\n",
      "Epoch 416/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3811 - accuracy: 0.9804 - val_loss: 0.4246 - val_accuracy: 0.8333\n",
      "Epoch 417/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3817 - accuracy: 0.9804 - val_loss: 0.4234 - val_accuracy: 0.8333\n",
      "Epoch 418/800\n",
      "102/102 [==============================] - 0s 959us/sample - loss: 0.3744 - accuracy: 0.9902 - val_loss: 0.4211 - val_accuracy: 0.8333\n",
      "Epoch 419/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3740 - accuracy: 0.9804 - val_loss: 0.4142 - val_accuracy: 0.8333\n",
      "Epoch 420/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3762 - accuracy: 0.9804 - val_loss: 0.4155 - val_accuracy: 0.8889\n",
      "Epoch 421/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3664 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.8889\n",
      "Epoch 422/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3698 - accuracy: 0.9902 - val_loss: 0.4309 - val_accuracy: 0.8889\n",
      "Epoch 423/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3712 - accuracy: 0.9804 - val_loss: 0.4360 - val_accuracy: 0.8889\n",
      "Epoch 424/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3723 - accuracy: 0.9804 - val_loss: 0.4428 - val_accuracy: 0.8889\n",
      "Epoch 425/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.3712 - accuracy: 0.9804 - val_loss: 0.4688 - val_accuracy: 0.7778\n",
      "Epoch 426/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3716 - accuracy: 0.9902 - val_loss: 0.4608 - val_accuracy: 0.7778\n",
      "Epoch 427/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3690 - accuracy: 0.9902 - val_loss: 0.4339 - val_accuracy: 0.8889\n",
      "Epoch 428/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3681 - accuracy: 0.9804 - val_loss: 0.4229 - val_accuracy: 0.8889\n",
      "Epoch 429/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3689 - accuracy: 0.9902 - val_loss: 0.4158 - val_accuracy: 0.7778\n",
      "Epoch 430/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3699 - accuracy: 0.9804 - val_loss: 0.4142 - val_accuracy: 0.8333\n",
      "Epoch 431/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3661 - accuracy: 0.9902 - val_loss: 0.4155 - val_accuracy: 0.8889\n",
      "Epoch 432/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3689 - accuracy: 0.9804 - val_loss: 0.4148 - val_accuracy: 0.8889\n",
      "Epoch 433/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3707 - accuracy: 0.9804 - val_loss: 0.4114 - val_accuracy: 0.8889\n",
      "Epoch 434/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3640 - accuracy: 0.9804 - val_loss: 0.4083 - val_accuracy: 0.8889\n",
      "Epoch 435/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3682 - accuracy: 0.9706 - val_loss: 0.4010 - val_accuracy: 0.8333\n",
      "Epoch 436/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3645 - accuracy: 0.9804 - val_loss: 0.3954 - val_accuracy: 0.8889\n",
      "Epoch 437/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3621 - accuracy: 0.9804 - val_loss: 0.4023 - val_accuracy: 0.8889\n",
      "Epoch 438/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3622 - accuracy: 0.9902 - val_loss: 0.4137 - val_accuracy: 0.8889\n",
      "Epoch 439/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3621 - accuracy: 0.9902 - val_loss: 0.4233 - val_accuracy: 0.8889\n",
      "Epoch 440/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3611 - accuracy: 0.9902 - val_loss: 0.4332 - val_accuracy: 0.8333\n",
      "Epoch 441/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.3667 - accuracy: 0.9706 - val_loss: 0.4386 - val_accuracy: 0.8333\n",
      "Epoch 442/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3610 - accuracy: 0.9902 - val_loss: 0.4382 - val_accuracy: 0.8333\n",
      "Epoch 443/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3593 - accuracy: 0.9804 - val_loss: 0.4250 - val_accuracy: 0.8889\n",
      "Epoch 444/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3591 - accuracy: 0.9804 - val_loss: 0.4051 - val_accuracy: 0.8889\n",
      "Epoch 445/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3582 - accuracy: 0.9804 - val_loss: 0.4040 - val_accuracy: 0.8333\n",
      "Epoch 446/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3606 - accuracy: 0.9902 - val_loss: 0.4075 - val_accuracy: 0.8889\n",
      "Epoch 447/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3609 - accuracy: 0.9804 - val_loss: 0.4085 - val_accuracy: 0.8889\n",
      "Epoch 448/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3565 - accuracy: 0.9804 - val_loss: 0.4014 - val_accuracy: 0.8889\n",
      "Epoch 449/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.3552 - accuracy: 0.9902 - val_loss: 0.3881 - val_accuracy: 0.8889\n",
      "Epoch 450/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3581 - accuracy: 0.9902 - val_loss: 0.3873 - val_accuracy: 0.8889\n",
      "Epoch 451/800\n",
      "102/102 [==============================] - 0s 996us/sample - loss: 0.3556 - accuracy: 0.9804 - val_loss: 0.3838 - val_accuracy: 0.8889\n",
      "Epoch 452/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3561 - accuracy: 0.9902 - val_loss: 0.3769 - val_accuracy: 0.9444\n",
      "Epoch 453/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3615 - accuracy: 0.9706 - val_loss: 0.3708 - val_accuracy: 0.9444\n",
      "Epoch 454/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3592 - accuracy: 0.9706 - val_loss: 0.3688 - val_accuracy: 0.9444\n",
      "Epoch 455/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3544 - accuracy: 0.9706 - val_loss: 0.3719 - val_accuracy: 0.9444\n",
      "Epoch 456/800\n",
      "102/102 [==============================] - 0s 992us/sample - loss: 0.3552 - accuracy: 0.9804 - val_loss: 0.3767 - val_accuracy: 0.8889\n",
      "Epoch 457/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3521 - accuracy: 0.9902 - val_loss: 0.3756 - val_accuracy: 0.8889\n",
      "Epoch 458/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3540 - accuracy: 0.9804 - val_loss: 0.3869 - val_accuracy: 0.8889\n",
      "Epoch 459/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3537 - accuracy: 0.9804 - val_loss: 0.3977 - val_accuracy: 0.8889\n",
      "Epoch 460/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3521 - accuracy: 0.9804 - val_loss: 0.4014 - val_accuracy: 0.8889\n",
      "Epoch 461/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3507 - accuracy: 0.9804 - val_loss: 0.4035 - val_accuracy: 0.8889\n",
      "Epoch 462/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.3490 - accuracy: 0.9902 - val_loss: 0.4054 - val_accuracy: 0.8889\n",
      "Epoch 463/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3530 - accuracy: 0.9804 - val_loss: 0.4043 - val_accuracy: 0.8889\n",
      "Epoch 464/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3490 - accuracy: 0.9804 - val_loss: 0.3975 - val_accuracy: 0.8889\n",
      "Epoch 465/800\n",
      "102/102 [==============================] - 0s 981us/sample - loss: 0.3420 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.8889\n",
      "Epoch 466/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3454 - accuracy: 0.9902 - val_loss: 0.3818 - val_accuracy: 0.8889\n",
      "Epoch 467/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3503 - accuracy: 0.9804 - val_loss: 0.3809 - val_accuracy: 0.8889\n",
      "Epoch 468/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3508 - accuracy: 0.9804 - val_loss: 0.3844 - val_accuracy: 0.8889\n",
      "Epoch 469/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3449 - accuracy: 0.9902 - val_loss: 0.3861 - val_accuracy: 0.8889\n",
      "Epoch 470/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3445 - accuracy: 0.9804 - val_loss: 0.3909 - val_accuracy: 0.8889\n",
      "Epoch 471/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3490 - accuracy: 0.9804 - val_loss: 0.3943 - val_accuracy: 0.8889\n",
      "Epoch 472/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3457 - accuracy: 0.9804 - val_loss: 0.3919 - val_accuracy: 0.8889\n",
      "Epoch 473/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3451 - accuracy: 0.9902 - val_loss: 0.3864 - val_accuracy: 0.8889\n",
      "Epoch 474/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3453 - accuracy: 0.9804 - val_loss: 0.3976 - val_accuracy: 0.8889\n",
      "Epoch 475/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3407 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.8333\n",
      "Epoch 476/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3432 - accuracy: 0.9804 - val_loss: 0.4101 - val_accuracy: 0.8333\n",
      "Epoch 477/800\n",
      "102/102 [==============================] - 0s 990us/sample - loss: 0.3481 - accuracy: 0.9804 - val_loss: 0.3821 - val_accuracy: 0.8889\n",
      "Epoch 478/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3436 - accuracy: 0.9804 - val_loss: 0.3638 - val_accuracy: 0.8889\n",
      "Epoch 479/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3405 - accuracy: 0.9804 - val_loss: 0.3646 - val_accuracy: 0.8889\n",
      "Epoch 480/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3427 - accuracy: 0.9804 - val_loss: 0.3667 - val_accuracy: 0.9444\n",
      "Epoch 481/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3447 - accuracy: 0.9706 - val_loss: 0.3720 - val_accuracy: 0.8889\n",
      "Epoch 482/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.3386 - accuracy: 0.9902 - val_loss: 0.3632 - val_accuracy: 0.9444\n",
      "Epoch 483/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3394 - accuracy: 0.9804 - val_loss: 0.3588 - val_accuracy: 0.9444\n",
      "Epoch 484/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3426 - accuracy: 0.9706 - val_loss: 0.3632 - val_accuracy: 0.8889\n",
      "Epoch 485/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3414 - accuracy: 0.9804 - val_loss: 0.3656 - val_accuracy: 0.8889\n",
      "Epoch 486/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3389 - accuracy: 0.9804 - val_loss: 0.3712 - val_accuracy: 0.8889\n",
      "Epoch 487/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3370 - accuracy: 0.9804 - val_loss: 0.3829 - val_accuracy: 0.8889\n",
      "Epoch 488/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3346 - accuracy: 0.9902 - val_loss: 0.3940 - val_accuracy: 0.8889\n",
      "Epoch 489/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3386 - accuracy: 0.9804 - val_loss: 0.4035 - val_accuracy: 0.8889\n",
      "Epoch 490/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3441 - accuracy: 0.9608 - val_loss: 0.4066 - val_accuracy: 0.8889\n",
      "Epoch 491/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3345 - accuracy: 0.9804 - val_loss: 0.4048 - val_accuracy: 0.8889\n",
      "Epoch 492/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3356 - accuracy: 0.9804 - val_loss: 0.3915 - val_accuracy: 0.8889\n",
      "Epoch 493/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3362 - accuracy: 0.9902 - val_loss: 0.3710 - val_accuracy: 0.8889\n",
      "Epoch 494/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3310 - accuracy: 0.9902 - val_loss: 0.3662 - val_accuracy: 0.8333\n",
      "Epoch 495/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3309 - accuracy: 0.9902 - val_loss: 0.3660 - val_accuracy: 0.8333\n",
      "Epoch 496/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3346 - accuracy: 0.9804 - val_loss: 0.3676 - val_accuracy: 0.8889\n",
      "Epoch 497/800\n",
      "102/102 [==============================] - 0s 968us/sample - loss: 0.3313 - accuracy: 0.9902 - val_loss: 0.3734 - val_accuracy: 0.8889\n",
      "Epoch 498/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3300 - accuracy: 0.9902 - val_loss: 0.3786 - val_accuracy: 0.8889\n",
      "Epoch 499/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.3356 - accuracy: 0.9804 - val_loss: 0.3725 - val_accuracy: 0.8889\n",
      "Epoch 500/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3281 - accuracy: 0.9804 - val_loss: 0.3589 - val_accuracy: 0.8889\n",
      "Epoch 501/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3330 - accuracy: 0.9804 - val_loss: 0.3781 - val_accuracy: 0.8889\n",
      "Epoch 502/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3348 - accuracy: 0.9706 - val_loss: 0.3809 - val_accuracy: 0.8889\n",
      "Epoch 503/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3339 - accuracy: 0.9804 - val_loss: 0.3795 - val_accuracy: 0.8889\n",
      "Epoch 504/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3300 - accuracy: 0.9804 - val_loss: 0.3765 - val_accuracy: 0.8889\n",
      "Epoch 505/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3297 - accuracy: 0.9804 - val_loss: 0.3658 - val_accuracy: 0.8889\n",
      "Epoch 506/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3266 - accuracy: 0.9902 - val_loss: 0.3591 - val_accuracy: 0.8889\n",
      "Epoch 507/800\n",
      "102/102 [==============================] - 0s 971us/sample - loss: 0.3279 - accuracy: 0.9902 - val_loss: 0.3692 - val_accuracy: 0.8889\n",
      "Epoch 508/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3275 - accuracy: 0.9804 - val_loss: 0.3806 - val_accuracy: 0.8889\n",
      "Epoch 509/800\n",
      "102/102 [==============================] - 0s 965us/sample - loss: 0.3323 - accuracy: 0.9706 - val_loss: 0.3896 - val_accuracy: 0.8889\n",
      "Epoch 510/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3239 - accuracy: 0.9804 - val_loss: 0.4021 - val_accuracy: 0.8333\n",
      "Epoch 511/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3235 - accuracy: 0.9804 - val_loss: 0.4203 - val_accuracy: 0.7778\n",
      "Epoch 512/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3353 - accuracy: 0.9804 - val_loss: 0.4056 - val_accuracy: 0.8333\n",
      "Epoch 513/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3230 - accuracy: 0.9902 - val_loss: 0.3863 - val_accuracy: 0.8889\n",
      "Epoch 514/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3281 - accuracy: 0.9706 - val_loss: 0.3673 - val_accuracy: 0.8889\n",
      "Epoch 515/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3300 - accuracy: 0.9706 - val_loss: 0.3610 - val_accuracy: 0.8889\n",
      "Epoch 516/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3208 - accuracy: 0.9902 - val_loss: 0.3579 - val_accuracy: 0.8889\n",
      "Epoch 517/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3250 - accuracy: 0.9706 - val_loss: 0.3652 - val_accuracy: 0.8889\n",
      "Epoch 518/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3189 - accuracy: 0.9902 - val_loss: 0.3721 - val_accuracy: 0.8889\n",
      "Epoch 519/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3211 - accuracy: 0.9902 - val_loss: 0.3850 - val_accuracy: 0.8889\n",
      "Epoch 520/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3238 - accuracy: 0.9706 - val_loss: 0.4179 - val_accuracy: 0.7778\n",
      "Epoch 521/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3251 - accuracy: 0.9804 - val_loss: 0.4206 - val_accuracy: 0.7778\n",
      "Epoch 522/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3260 - accuracy: 0.9608 - val_loss: 0.4000 - val_accuracy: 0.8333\n",
      "Epoch 523/800\n",
      "102/102 [==============================] - 0s 990us/sample - loss: 0.3264 - accuracy: 0.9706 - val_loss: 0.3735 - val_accuracy: 0.8889\n",
      "Epoch 524/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3179 - accuracy: 0.9902 - val_loss: 0.3617 - val_accuracy: 0.8889\n",
      "Epoch 525/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3168 - accuracy: 0.9804 - val_loss: 0.3553 - val_accuracy: 0.8889\n",
      "Epoch 526/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3185 - accuracy: 0.9804 - val_loss: 0.3551 - val_accuracy: 0.8889\n",
      "Epoch 527/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3181 - accuracy: 0.9902 - val_loss: 0.3601 - val_accuracy: 0.8889\n",
      "Epoch 528/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3178 - accuracy: 0.9804 - val_loss: 0.3624 - val_accuracy: 0.8889\n",
      "Epoch 529/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3215 - accuracy: 0.9706 - val_loss: 0.3658 - val_accuracy: 0.8889\n",
      "Epoch 530/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3178 - accuracy: 0.9902 - val_loss: 0.3576 - val_accuracy: 0.8333\n",
      "Epoch 531/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3176 - accuracy: 0.9804 - val_loss: 0.3662 - val_accuracy: 0.8889\n",
      "Epoch 532/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3248 - accuracy: 0.9706 - val_loss: 0.3691 - val_accuracy: 0.8889\n",
      "Epoch 533/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3186 - accuracy: 0.9804 - val_loss: 0.3699 - val_accuracy: 0.8889\n",
      "Epoch 534/800\n",
      "102/102 [==============================] - 0s 985us/sample - loss: 0.3175 - accuracy: 0.9804 - val_loss: 0.3692 - val_accuracy: 0.8889\n",
      "Epoch 535/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3206 - accuracy: 0.9608 - val_loss: 0.3677 - val_accuracy: 0.8889\n",
      "Epoch 536/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.3171 - accuracy: 0.9804 - val_loss: 0.3682 - val_accuracy: 0.8889\n",
      "Epoch 537/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3156 - accuracy: 0.9804 - val_loss: 0.3667 - val_accuracy: 0.8889\n",
      "Epoch 538/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3106 - accuracy: 0.9902 - val_loss: 0.3626 - val_accuracy: 0.8889\n",
      "Epoch 539/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3158 - accuracy: 0.9804 - val_loss: 0.3565 - val_accuracy: 0.8333\n",
      "Epoch 540/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3158 - accuracy: 0.9804 - val_loss: 0.3541 - val_accuracy: 0.8333\n",
      "Epoch 541/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.3137 - accuracy: 0.9804 - val_loss: 0.3594 - val_accuracy: 0.8889\n",
      "Epoch 542/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3112 - accuracy: 0.9902 - val_loss: 0.3659 - val_accuracy: 0.8889\n",
      "Epoch 543/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3139 - accuracy: 0.9804 - val_loss: 0.3672 - val_accuracy: 0.8889\n",
      "Epoch 544/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3188 - accuracy: 0.9608 - val_loss: 0.3661 - val_accuracy: 0.8889\n",
      "Epoch 545/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3150 - accuracy: 0.9706 - val_loss: 0.3588 - val_accuracy: 0.8889\n",
      "Epoch 546/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3071 - accuracy: 0.9902 - val_loss: 0.3574 - val_accuracy: 0.8333\n",
      "Epoch 547/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3127 - accuracy: 0.9706 - val_loss: 0.3579 - val_accuracy: 0.7778\n",
      "Epoch 548/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3089 - accuracy: 0.9804 - val_loss: 0.3593 - val_accuracy: 0.8889\n",
      "Epoch 549/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3129 - accuracy: 0.9804 - val_loss: 0.3582 - val_accuracy: 0.8889\n",
      "Epoch 550/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3046 - accuracy: 0.9902 - val_loss: 0.3553 - val_accuracy: 0.8889\n",
      "Epoch 551/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3183 - accuracy: 0.9706 - val_loss: 0.3555 - val_accuracy: 0.8889\n",
      "Epoch 552/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3077 - accuracy: 0.9902 - val_loss: 0.3561 - val_accuracy: 0.8889\n",
      "Epoch 553/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3118 - accuracy: 0.9706 - val_loss: 0.3539 - val_accuracy: 0.8889\n",
      "Epoch 554/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3075 - accuracy: 0.9706 - val_loss: 0.3608 - val_accuracy: 0.8889\n",
      "Epoch 555/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3113 - accuracy: 0.9706 - val_loss: 0.3691 - val_accuracy: 0.8889\n",
      "Epoch 556/800\n",
      "102/102 [==============================] - 0s 991us/sample - loss: 0.3036 - accuracy: 0.9804 - val_loss: 0.3714 - val_accuracy: 0.8889\n",
      "Epoch 557/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3149 - accuracy: 0.9608 - val_loss: 0.3669 - val_accuracy: 0.8889\n",
      "Epoch 558/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3038 - accuracy: 0.9804 - val_loss: 0.3808 - val_accuracy: 0.8889\n",
      "Epoch 559/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3058 - accuracy: 0.9804 - val_loss: 0.3831 - val_accuracy: 0.7778\n",
      "Epoch 560/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3067 - accuracy: 0.9706 - val_loss: 0.3694 - val_accuracy: 0.8889\n",
      "Epoch 561/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3071 - accuracy: 0.9706 - val_loss: 0.3611 - val_accuracy: 0.8889\n",
      "Epoch 562/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3022 - accuracy: 0.9902 - val_loss: 0.3506 - val_accuracy: 0.8889\n",
      "Epoch 563/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2981 - accuracy: 0.9902 - val_loss: 0.3444 - val_accuracy: 0.7778\n",
      "Epoch 564/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3030 - accuracy: 0.9902 - val_loss: 0.3523 - val_accuracy: 0.8333\n",
      "Epoch 565/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2993 - accuracy: 0.9902 - val_loss: 0.3556 - val_accuracy: 0.8889\n",
      "Epoch 566/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3062 - accuracy: 0.9706 - val_loss: 0.3556 - val_accuracy: 0.8889\n",
      "Epoch 567/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3008 - accuracy: 0.9804 - val_loss: 0.3554 - val_accuracy: 0.8333\n",
      "Epoch 568/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2995 - accuracy: 0.9902 - val_loss: 0.3531 - val_accuracy: 0.7778\n",
      "Epoch 569/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3067 - accuracy: 0.9706 - val_loss: 0.3531 - val_accuracy: 0.8889\n",
      "Epoch 570/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2986 - accuracy: 0.9804 - val_loss: 0.3550 - val_accuracy: 0.8889\n",
      "Epoch 571/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.2970 - accuracy: 0.9902 - val_loss: 0.3577 - val_accuracy: 0.8889\n",
      "Epoch 572/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3043 - accuracy: 0.9608 - val_loss: 0.3630 - val_accuracy: 0.8889\n",
      "Epoch 573/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2981 - accuracy: 0.9804 - val_loss: 0.3568 - val_accuracy: 0.8889\n",
      "Epoch 574/800\n",
      "102/102 [==============================] - 0s 977us/sample - loss: 0.2969 - accuracy: 0.9902 - val_loss: 0.3506 - val_accuracy: 0.8889\n",
      "Epoch 575/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2933 - accuracy: 0.9902 - val_loss: 0.3512 - val_accuracy: 0.8889\n",
      "Epoch 576/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2989 - accuracy: 0.9804 - val_loss: 0.3587 - val_accuracy: 0.8889\n",
      "Epoch 577/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2908 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.8889\n",
      "Epoch 578/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2986 - accuracy: 0.9804 - val_loss: 0.3571 - val_accuracy: 0.8889\n",
      "Epoch 579/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2976 - accuracy: 0.9804 - val_loss: 0.3525 - val_accuracy: 0.8333\n",
      "Epoch 580/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2982 - accuracy: 0.9804 - val_loss: 0.3532 - val_accuracy: 0.7778\n",
      "Epoch 581/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2993 - accuracy: 0.9804 - val_loss: 0.3528 - val_accuracy: 0.7778\n",
      "Epoch 582/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.2966 - accuracy: 0.9804 - val_loss: 0.3534 - val_accuracy: 0.8889\n",
      "Epoch 583/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2941 - accuracy: 0.9902 - val_loss: 0.3555 - val_accuracy: 0.8889\n",
      "Epoch 584/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2947 - accuracy: 0.9804 - val_loss: 0.3774 - val_accuracy: 0.8333\n",
      "Epoch 585/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2999 - accuracy: 0.9608 - val_loss: 0.3784 - val_accuracy: 0.7778\n",
      "Epoch 586/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2989 - accuracy: 0.9804 - val_loss: 0.3506 - val_accuracy: 0.8889\n",
      "Epoch 587/800\n",
      "102/102 [==============================] - 0s 991us/sample - loss: 0.2918 - accuracy: 0.9804 - val_loss: 0.3459 - val_accuracy: 0.8333\n",
      "Epoch 588/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2979 - accuracy: 0.9608 - val_loss: 0.3455 - val_accuracy: 0.7778\n",
      "Epoch 589/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2969 - accuracy: 0.9804 - val_loss: 0.3499 - val_accuracy: 0.8889\n",
      "Epoch 590/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2933 - accuracy: 0.9804 - val_loss: 0.3479 - val_accuracy: 0.8333\n",
      "Epoch 591/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2974 - accuracy: 0.9706 - val_loss: 0.3453 - val_accuracy: 0.7778\n",
      "Epoch 592/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3011 - accuracy: 0.9608 - val_loss: 0.3490 - val_accuracy: 0.8333\n",
      "Epoch 593/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.3002 - accuracy: 0.9706 - val_loss: 0.3494 - val_accuracy: 0.7778\n",
      "Epoch 594/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2920 - accuracy: 0.9804 - val_loss: 0.3453 - val_accuracy: 0.8889\n",
      "Epoch 595/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.3029 - accuracy: 0.9608 - val_loss: 0.3451 - val_accuracy: 0.8889\n",
      "Epoch 596/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2921 - accuracy: 0.9902 - val_loss: 0.3453 - val_accuracy: 0.8889\n",
      "Epoch 597/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2999 - accuracy: 0.9706 - val_loss: 0.3448 - val_accuracy: 0.8889\n",
      "Epoch 598/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2985 - accuracy: 0.9706 - val_loss: 0.3462 - val_accuracy: 0.8889\n",
      "Epoch 599/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2849 - accuracy: 0.9902 - val_loss: 0.3478 - val_accuracy: 0.8333\n",
      "Epoch 600/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2893 - accuracy: 0.9902 - val_loss: 0.3460 - val_accuracy: 0.7778\n",
      "Epoch 601/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2951 - accuracy: 0.9804 - val_loss: 0.3426 - val_accuracy: 0.7778\n",
      "Epoch 602/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2931 - accuracy: 0.9804 - val_loss: 0.3401 - val_accuracy: 0.8333\n",
      "Epoch 603/800\n",
      "102/102 [==============================] - 0s 987us/sample - loss: 0.2828 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.8333\n",
      "Epoch 604/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2963 - accuracy: 0.9608 - val_loss: 0.3415 - val_accuracy: 0.8333\n",
      "Epoch 605/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2878 - accuracy: 0.9804 - val_loss: 0.3403 - val_accuracy: 0.8333\n",
      "Epoch 606/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2905 - accuracy: 0.9706 - val_loss: 0.3422 - val_accuracy: 0.8333\n",
      "Epoch 607/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2867 - accuracy: 0.9902 - val_loss: 0.3415 - val_accuracy: 0.8889\n",
      "Epoch 608/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2861 - accuracy: 0.9804 - val_loss: 0.3429 - val_accuracy: 0.8889\n",
      "Epoch 609/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2843 - accuracy: 0.9902 - val_loss: 0.3435 - val_accuracy: 0.8889\n",
      "Epoch 610/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2897 - accuracy: 0.9804 - val_loss: 0.3426 - val_accuracy: 0.8889\n",
      "Epoch 611/800\n",
      "102/102 [==============================] - 0s 985us/sample - loss: 0.2893 - accuracy: 0.9804 - val_loss: 0.3409 - val_accuracy: 0.8889\n",
      "Epoch 612/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2876 - accuracy: 0.9804 - val_loss: 0.3379 - val_accuracy: 0.8889\n",
      "Epoch 613/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2871 - accuracy: 0.9804 - val_loss: 0.3330 - val_accuracy: 0.8333\n",
      "Epoch 614/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2885 - accuracy: 0.9706 - val_loss: 0.3345 - val_accuracy: 0.8889\n",
      "Epoch 615/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2845 - accuracy: 0.9902 - val_loss: 0.3516 - val_accuracy: 0.8333\n",
      "Epoch 616/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2830 - accuracy: 0.9804 - val_loss: 0.3523 - val_accuracy: 0.8333\n",
      "Epoch 617/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2844 - accuracy: 0.9804 - val_loss: 0.3306 - val_accuracy: 0.8889\n",
      "Epoch 618/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2825 - accuracy: 0.9902 - val_loss: 0.3377 - val_accuracy: 0.8889\n",
      "Epoch 619/800\n",
      "102/102 [==============================] - 0s 966us/sample - loss: 0.2865 - accuracy: 0.9804 - val_loss: 0.3387 - val_accuracy: 0.8889\n",
      "Epoch 620/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2814 - accuracy: 0.9804 - val_loss: 0.3393 - val_accuracy: 0.8889\n",
      "Epoch 621/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2877 - accuracy: 0.9804 - val_loss: 0.3382 - val_accuracy: 0.8889\n",
      "Epoch 622/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2788 - accuracy: 0.9902 - val_loss: 0.3366 - val_accuracy: 0.8889\n",
      "Epoch 623/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2827 - accuracy: 0.9804 - val_loss: 0.3351 - val_accuracy: 0.8889\n",
      "Epoch 624/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2810 - accuracy: 0.9902 - val_loss: 0.3340 - val_accuracy: 0.8889\n",
      "Epoch 625/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2794 - accuracy: 0.9902 - val_loss: 0.3313 - val_accuracy: 0.8889\n",
      "Epoch 626/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2756 - accuracy: 0.9902 - val_loss: 0.3187 - val_accuracy: 0.8333\n",
      "Epoch 627/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.2785 - accuracy: 0.9902 - val_loss: 0.3147 - val_accuracy: 0.8333\n",
      "Epoch 628/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2813 - accuracy: 0.9706 - val_loss: 0.3126 - val_accuracy: 0.8333\n",
      "Epoch 629/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2821 - accuracy: 0.9706 - val_loss: 0.3174 - val_accuracy: 0.8333\n",
      "Epoch 630/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2855 - accuracy: 0.9706 - val_loss: 0.3296 - val_accuracy: 0.8889\n",
      "Epoch 631/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2765 - accuracy: 0.9902 - val_loss: 0.3330 - val_accuracy: 0.8889\n",
      "Epoch 632/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2812 - accuracy: 0.9804 - val_loss: 0.3341 - val_accuracy: 0.8889\n",
      "Epoch 633/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2763 - accuracy: 0.9902 - val_loss: 0.3336 - val_accuracy: 0.8889\n",
      "Epoch 634/800\n",
      "102/102 [==============================] - 0s 975us/sample - loss: 0.2790 - accuracy: 0.9804 - val_loss: 0.3315 - val_accuracy: 0.8889\n",
      "Epoch 635/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2763 - accuracy: 0.9804 - val_loss: 0.3282 - val_accuracy: 0.8889\n",
      "Epoch 636/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2771 - accuracy: 0.9804 - val_loss: 0.3181 - val_accuracy: 0.8333\n",
      "Epoch 637/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2759 - accuracy: 0.9804 - val_loss: 0.3119 - val_accuracy: 0.8333\n",
      "Epoch 638/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2799 - accuracy: 0.9804 - val_loss: 0.3143 - val_accuracy: 0.9444\n",
      "Epoch 639/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.2739 - accuracy: 0.9902 - val_loss: 0.3207 - val_accuracy: 0.8333\n",
      "Epoch 640/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2753 - accuracy: 0.9902 - val_loss: 0.3228 - val_accuracy: 0.8333\n",
      "Epoch 641/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2722 - accuracy: 0.9902 - val_loss: 0.3220 - val_accuracy: 0.8333\n",
      "Epoch 642/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2767 - accuracy: 0.9804 - val_loss: 0.3222 - val_accuracy: 0.8333\n",
      "Epoch 643/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2781 - accuracy: 0.9804 - val_loss: 0.3229 - val_accuracy: 0.8333\n",
      "Epoch 644/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2737 - accuracy: 0.9902 - val_loss: 0.3247 - val_accuracy: 0.8333\n",
      "Epoch 645/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2739 - accuracy: 0.9804 - val_loss: 0.3133 - val_accuracy: 0.8333\n",
      "Epoch 646/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2723 - accuracy: 0.9902 - val_loss: 0.3119 - val_accuracy: 0.8333\n",
      "Epoch 647/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2802 - accuracy: 0.9706 - val_loss: 0.3108 - val_accuracy: 0.9444\n",
      "Epoch 648/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2712 - accuracy: 0.9902 - val_loss: 0.3155 - val_accuracy: 0.8333\n",
      "Epoch 649/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2747 - accuracy: 0.9804 - val_loss: 0.3280 - val_accuracy: 0.8333\n",
      "Epoch 650/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2713 - accuracy: 0.9902 - val_loss: 0.3284 - val_accuracy: 0.8889\n",
      "Epoch 651/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2749 - accuracy: 0.9804 - val_loss: 0.3283 - val_accuracy: 0.8889\n",
      "Epoch 652/800\n",
      "102/102 [==============================] - 0s 980us/sample - loss: 0.2725 - accuracy: 0.9902 - val_loss: 0.3292 - val_accuracy: 0.8333\n",
      "Epoch 653/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2702 - accuracy: 0.9902 - val_loss: 0.3268 - val_accuracy: 0.8333\n",
      "Epoch 654/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2716 - accuracy: 0.9804 - val_loss: 0.3240 - val_accuracy: 0.7778\n",
      "Epoch 655/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2739 - accuracy: 0.9706 - val_loss: 0.3226 - val_accuracy: 0.8333\n",
      "Epoch 656/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2703 - accuracy: 0.9902 - val_loss: 0.3238 - val_accuracy: 0.8333\n",
      "Epoch 657/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2691 - accuracy: 0.9902 - val_loss: 0.3253 - val_accuracy: 0.8333\n",
      "Epoch 658/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2678 - accuracy: 0.9902 - val_loss: 0.3234 - val_accuracy: 0.8333\n",
      "Epoch 659/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2667 - accuracy: 0.9902 - val_loss: 0.3227 - val_accuracy: 0.8333\n",
      "Epoch 660/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2680 - accuracy: 0.9902 - val_loss: 0.3245 - val_accuracy: 0.8889\n",
      "Epoch 661/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2789 - accuracy: 0.9608 - val_loss: 0.3245 - val_accuracy: 0.8889\n",
      "Epoch 662/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2691 - accuracy: 0.9902 - val_loss: 0.3256 - val_accuracy: 0.8889\n",
      "Epoch 663/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2685 - accuracy: 0.9804 - val_loss: 0.3251 - val_accuracy: 0.8889\n",
      "Epoch 664/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2765 - accuracy: 0.9706 - val_loss: 0.3250 - val_accuracy: 0.8889\n",
      "Epoch 665/800\n",
      "102/102 [==============================] - 0s 986us/sample - loss: 0.2741 - accuracy: 0.9706 - val_loss: 0.3245 - val_accuracy: 0.8889\n",
      "Epoch 666/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2679 - accuracy: 0.9902 - val_loss: 0.3249 - val_accuracy: 0.8889\n",
      "Epoch 667/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2668 - accuracy: 0.9804 - val_loss: 0.3168 - val_accuracy: 0.8333\n",
      "Epoch 668/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2673 - accuracy: 0.9804 - val_loss: 0.3105 - val_accuracy: 0.8333\n",
      "Epoch 669/800\n",
      "102/102 [==============================] - 0s 983us/sample - loss: 0.2680 - accuracy: 0.9804 - val_loss: 0.3120 - val_accuracy: 0.8333\n",
      "Epoch 670/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2647 - accuracy: 0.9902 - val_loss: 0.3163 - val_accuracy: 0.8333\n",
      "Epoch 671/800\n",
      "102/102 [==============================] - 0s 998us/sample - loss: 0.2672 - accuracy: 0.9804 - val_loss: 0.3191 - val_accuracy: 0.8889\n",
      "Epoch 672/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2727 - accuracy: 0.9706 - val_loss: 0.3190 - val_accuracy: 0.8889\n",
      "Epoch 673/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2640 - accuracy: 0.9902 - val_loss: 0.3170 - val_accuracy: 0.8333\n",
      "Epoch 674/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2637 - accuracy: 0.9902 - val_loss: 0.3152 - val_accuracy: 0.8333\n",
      "Epoch 675/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2648 - accuracy: 0.9804 - val_loss: 0.3073 - val_accuracy: 0.8333\n",
      "Epoch 676/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2672 - accuracy: 0.9804 - val_loss: 0.3223 - val_accuracy: 0.8889\n",
      "Epoch 677/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2693 - accuracy: 0.9804 - val_loss: 0.3436 - val_accuracy: 0.8333\n",
      "Epoch 678/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2611 - accuracy: 0.9902 - val_loss: 0.3329 - val_accuracy: 0.8333\n",
      "Epoch 679/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2623 - accuracy: 0.9902 - val_loss: 0.3059 - val_accuracy: 0.8889\n",
      "Epoch 680/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2623 - accuracy: 0.9902 - val_loss: 0.3143 - val_accuracy: 0.8889\n",
      "Epoch 681/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2689 - accuracy: 0.9706 - val_loss: 0.3174 - val_accuracy: 0.8889\n",
      "Epoch 682/800\n",
      "102/102 [==============================] - 0s 988us/sample - loss: 0.2651 - accuracy: 0.9804 - val_loss: 0.3178 - val_accuracy: 0.8889\n",
      "Epoch 683/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2639 - accuracy: 0.9804 - val_loss: 0.3171 - val_accuracy: 0.8889\n",
      "Epoch 684/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2623 - accuracy: 0.9804 - val_loss: 0.3156 - val_accuracy: 0.8889\n",
      "Epoch 685/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2677 - accuracy: 0.9706 - val_loss: 0.3140 - val_accuracy: 0.8889\n",
      "Epoch 686/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2613 - accuracy: 0.9804 - val_loss: 0.3092 - val_accuracy: 0.8889\n",
      "Epoch 687/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2686 - accuracy: 0.9608 - val_loss: 0.3028 - val_accuracy: 0.8333\n",
      "Epoch 688/800\n",
      "102/102 [==============================] - 0s 972us/sample - loss: 0.2607 - accuracy: 0.9902 - val_loss: 0.3028 - val_accuracy: 0.8333\n",
      "Epoch 689/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2642 - accuracy: 0.9804 - val_loss: 0.3079 - val_accuracy: 0.8333\n",
      "Epoch 690/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.2599 - accuracy: 0.9902 - val_loss: 0.3119 - val_accuracy: 0.8333\n",
      "Epoch 691/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2582 - accuracy: 0.9902 - val_loss: 0.3092 - val_accuracy: 0.8889\n",
      "Epoch 692/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2566 - accuracy: 0.9902 - val_loss: 0.3044 - val_accuracy: 0.8889\n",
      "Epoch 693/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.2542 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.8333\n",
      "Epoch 694/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2597 - accuracy: 0.9804 - val_loss: 0.2978 - val_accuracy: 0.8333\n",
      "Epoch 695/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2584 - accuracy: 0.9902 - val_loss: 0.2997 - val_accuracy: 0.8889\n",
      "Epoch 696/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2604 - accuracy: 0.9804 - val_loss: 0.3056 - val_accuracy: 0.8889\n",
      "Epoch 697/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2589 - accuracy: 0.9804 - val_loss: 0.3084 - val_accuracy: 0.8889\n",
      "Epoch 698/800\n",
      "102/102 [==============================] - 0s 993us/sample - loss: 0.2576 - accuracy: 0.9902 - val_loss: 0.3048 - val_accuracy: 0.8889\n",
      "Epoch 699/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2584 - accuracy: 0.9902 - val_loss: 0.3037 - val_accuracy: 0.7778\n",
      "Epoch 700/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2574 - accuracy: 0.9902 - val_loss: 0.3063 - val_accuracy: 0.8333\n",
      "Epoch 701/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2549 - accuracy: 0.9902 - val_loss: 0.3072 - val_accuracy: 0.8333\n",
      "Epoch 702/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2591 - accuracy: 0.9804 - val_loss: 0.3074 - val_accuracy: 0.8333\n",
      "Epoch 703/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2562 - accuracy: 0.9804 - val_loss: 0.3066 - val_accuracy: 0.8333\n",
      "Epoch 704/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2566 - accuracy: 0.9902 - val_loss: 0.3040 - val_accuracy: 0.8889\n",
      "Epoch 705/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2571 - accuracy: 0.9804 - val_loss: 0.3069 - val_accuracy: 0.8889\n",
      "Epoch 706/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2584 - accuracy: 0.9706 - val_loss: 0.3061 - val_accuracy: 0.8889\n",
      "Epoch 707/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2547 - accuracy: 0.9902 - val_loss: 0.3009 - val_accuracy: 0.8333\n",
      "Epoch 708/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2558 - accuracy: 0.9804 - val_loss: 0.3012 - val_accuracy: 0.8333\n",
      "Epoch 709/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2593 - accuracy: 0.9804 - val_loss: 0.2980 - val_accuracy: 0.8333\n",
      "Epoch 710/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2551 - accuracy: 0.9902 - val_loss: 0.2980 - val_accuracy: 0.8333\n",
      "Epoch 711/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2515 - accuracy: 0.9902 - val_loss: 0.2956 - val_accuracy: 0.8333\n",
      "Epoch 712/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2625 - accuracy: 0.9706 - val_loss: 0.2964 - val_accuracy: 0.8333\n",
      "Epoch 713/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2562 - accuracy: 0.9804 - val_loss: 0.2966 - val_accuracy: 0.8333\n",
      "Epoch 714/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2536 - accuracy: 0.9804 - val_loss: 0.2986 - val_accuracy: 0.8889\n",
      "Epoch 715/800\n",
      "102/102 [==============================] - 0s 997us/sample - loss: 0.2536 - accuracy: 0.9804 - val_loss: 0.3167 - val_accuracy: 0.8889\n",
      "Epoch 716/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2647 - accuracy: 0.9706 - val_loss: 0.3205 - val_accuracy: 0.8889\n",
      "Epoch 717/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2535 - accuracy: 0.9902 - val_loss: 0.3079 - val_accuracy: 0.8889\n",
      "Epoch 718/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2560 - accuracy: 0.9804 - val_loss: 0.3092 - val_accuracy: 0.8333\n",
      "Epoch 719/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2567 - accuracy: 0.9804 - val_loss: 0.3095 - val_accuracy: 0.8333\n",
      "Epoch 720/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2686 - accuracy: 0.9608 - val_loss: 0.3083 - val_accuracy: 0.8333\n",
      "Epoch 721/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2556 - accuracy: 0.9706 - val_loss: 0.3044 - val_accuracy: 0.8889\n",
      "Epoch 722/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2520 - accuracy: 0.9706 - val_loss: 0.3186 - val_accuracy: 0.8889\n",
      "Epoch 723/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2609 - accuracy: 0.9608 - val_loss: 0.3203 - val_accuracy: 0.8333\n",
      "Epoch 724/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2563 - accuracy: 0.9706 - val_loss: 0.3058 - val_accuracy: 0.8889\n",
      "Epoch 725/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2473 - accuracy: 0.9902 - val_loss: 0.2998 - val_accuracy: 0.8889\n",
      "Epoch 726/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2541 - accuracy: 0.9706 - val_loss: 0.3036 - val_accuracy: 0.8889\n",
      "Epoch 727/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2522 - accuracy: 0.9804 - val_loss: 0.3039 - val_accuracy: 0.8889\n",
      "Epoch 728/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2486 - accuracy: 0.9902 - val_loss: 0.3014 - val_accuracy: 0.8889\n",
      "Epoch 729/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2558 - accuracy: 0.9804 - val_loss: 0.2812 - val_accuracy: 0.9444\n",
      "Epoch 730/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2495 - accuracy: 0.9902 - val_loss: 0.2801 - val_accuracy: 0.8889\n",
      "Epoch 731/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.2564 - accuracy: 0.9608 - val_loss: 0.2840 - val_accuracy: 0.8333\n",
      "Epoch 732/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2485 - accuracy: 0.9902 - val_loss: 0.2947 - val_accuracy: 0.8889\n",
      "Epoch 733/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2546 - accuracy: 0.9804 - val_loss: 0.2972 - val_accuracy: 0.8889\n",
      "Epoch 734/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2529 - accuracy: 0.9706 - val_loss: 0.2924 - val_accuracy: 0.8333\n",
      "Epoch 735/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2474 - accuracy: 0.9902 - val_loss: 0.2906 - val_accuracy: 0.8333\n",
      "Epoch 736/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2524 - accuracy: 0.9804 - val_loss: 0.2893 - val_accuracy: 0.8889\n",
      "Epoch 737/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2541 - accuracy: 0.9804 - val_loss: 0.2872 - val_accuracy: 0.8333\n",
      "Epoch 738/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.2476 - accuracy: 0.9902 - val_loss: 0.2853 - val_accuracy: 0.9444\n",
      "Epoch 739/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2471 - accuracy: 0.9902 - val_loss: 0.2921 - val_accuracy: 0.8889\n",
      "Epoch 740/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2492 - accuracy: 0.9804 - val_loss: 0.2962 - val_accuracy: 0.8889\n",
      "Epoch 741/800\n",
      "102/102 [==============================] - 0s 994us/sample - loss: 0.2459 - accuracy: 0.9902 - val_loss: 0.2905 - val_accuracy: 0.8889\n",
      "Epoch 742/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2501 - accuracy: 0.9804 - val_loss: 0.2923 - val_accuracy: 0.8889\n",
      "Epoch 743/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2410 - accuracy: 0.9902 - val_loss: 0.2930 - val_accuracy: 0.8889\n",
      "Epoch 744/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2445 - accuracy: 0.9902 - val_loss: 0.2956 - val_accuracy: 0.8889\n",
      "Epoch 745/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2490 - accuracy: 0.9804 - val_loss: 0.2939 - val_accuracy: 0.8889\n",
      "Epoch 746/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2437 - accuracy: 0.9902 - val_loss: 0.2889 - val_accuracy: 0.8889\n",
      "Epoch 747/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2495 - accuracy: 0.9804 - val_loss: 0.2878 - val_accuracy: 0.8333\n",
      "Epoch 748/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2487 - accuracy: 0.9804 - val_loss: 0.2887 - val_accuracy: 0.8333\n",
      "Epoch 749/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2467 - accuracy: 0.9804 - val_loss: 0.2867 - val_accuracy: 0.8333\n",
      "Epoch 750/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2439 - accuracy: 0.9902 - val_loss: 0.2877 - val_accuracy: 0.8889\n",
      "Epoch 751/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2485 - accuracy: 0.9706 - val_loss: 0.2894 - val_accuracy: 0.8889\n",
      "Epoch 752/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2439 - accuracy: 0.9902 - val_loss: 0.2928 - val_accuracy: 0.8889\n",
      "Epoch 753/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2429 - accuracy: 0.9902 - val_loss: 0.2963 - val_accuracy: 0.8889\n",
      "Epoch 754/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2486 - accuracy: 0.9804 - val_loss: 0.2915 - val_accuracy: 0.8889\n",
      "Epoch 755/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2452 - accuracy: 0.9804 - val_loss: 0.2957 - val_accuracy: 0.8333\n",
      "Epoch 756/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2426 - accuracy: 0.9902 - val_loss: 0.2982 - val_accuracy: 0.8889\n",
      "Epoch 757/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2473 - accuracy: 0.9804 - val_loss: 0.2983 - val_accuracy: 0.8889\n",
      "Epoch 758/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2457 - accuracy: 0.9804 - val_loss: 0.2978 - val_accuracy: 0.8889\n",
      "Epoch 759/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2427 - accuracy: 0.9902 - val_loss: 0.2970 - val_accuracy: 0.8889\n",
      "Epoch 760/800\n",
      "102/102 [==============================] - 0s 989us/sample - loss: 0.2454 - accuracy: 0.9804 - val_loss: 0.2962 - val_accuracy: 0.8889\n",
      "Epoch 761/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2460 - accuracy: 0.9804 - val_loss: 0.2858 - val_accuracy: 0.8333\n",
      "Epoch 762/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2456 - accuracy: 0.9706 - val_loss: 0.2843 - val_accuracy: 0.8333\n",
      "Epoch 763/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2424 - accuracy: 0.9902 - val_loss: 0.2870 - val_accuracy: 0.8333\n",
      "Epoch 764/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2363 - accuracy: 1.0000 - val_loss: 0.2864 - val_accuracy: 0.8889\n",
      "Epoch 765/800\n",
      "102/102 [==============================] - 0s 999us/sample - loss: 0.2363 - accuracy: 0.9902 - val_loss: 0.2877 - val_accuracy: 0.8889\n",
      "Epoch 766/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2403 - accuracy: 0.9902 - val_loss: 0.2897 - val_accuracy: 0.8889\n",
      "Epoch 767/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2389 - accuracy: 0.9902 - val_loss: 0.2905 - val_accuracy: 0.8889\n",
      "Epoch 768/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2404 - accuracy: 0.9902 - val_loss: 0.2817 - val_accuracy: 0.9444\n",
      "Epoch 769/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2425 - accuracy: 0.9804 - val_loss: 0.2844 - val_accuracy: 0.8333\n",
      "Epoch 770/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2389 - accuracy: 0.9902 - val_loss: 0.2830 - val_accuracy: 0.8333\n",
      "Epoch 771/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2439 - accuracy: 0.9706 - val_loss: 0.2789 - val_accuracy: 0.8333\n",
      "Epoch 772/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2394 - accuracy: 0.9804 - val_loss: 0.2773 - val_accuracy: 0.8889\n",
      "Epoch 773/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2368 - accuracy: 0.9902 - val_loss: 0.2859 - val_accuracy: 0.8889\n",
      "Epoch 774/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2360 - accuracy: 0.9902 - val_loss: 0.2896 - val_accuracy: 0.8889\n",
      "Epoch 775/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2394 - accuracy: 0.9902 - val_loss: 0.2899 - val_accuracy: 0.8889\n",
      "Epoch 776/800\n",
      "102/102 [==============================] - 0s 995us/sample - loss: 0.2399 - accuracy: 0.9804 - val_loss: 0.2865 - val_accuracy: 0.8333\n",
      "Epoch 777/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2398 - accuracy: 0.9804 - val_loss: 0.2890 - val_accuracy: 0.8333\n",
      "Epoch 778/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2382 - accuracy: 0.9902 - val_loss: 0.2879 - val_accuracy: 0.8333\n",
      "Epoch 779/800\n",
      "102/102 [==============================] - 0s 983us/sample - loss: 0.2409 - accuracy: 0.9804 - val_loss: 0.2849 - val_accuracy: 0.8889\n",
      "Epoch 780/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2443 - accuracy: 0.9706 - val_loss: 0.2908 - val_accuracy: 0.8889\n",
      "Epoch 781/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2336 - accuracy: 0.9902 - val_loss: 0.3163 - val_accuracy: 0.8333\n",
      "Epoch 782/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2388 - accuracy: 0.9804 - val_loss: 0.2968 - val_accuracy: 0.8889\n",
      "Epoch 783/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2416 - accuracy: 0.9706 - val_loss: 0.2876 - val_accuracy: 0.8889\n",
      "Epoch 784/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2432 - accuracy: 0.9804 - val_loss: 0.2851 - val_accuracy: 0.8889\n",
      "Epoch 785/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2362 - accuracy: 0.9902 - val_loss: 0.2923 - val_accuracy: 0.8333\n",
      "Epoch 786/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2310 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.8333\n",
      "Epoch 787/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2368 - accuracy: 0.9804 - val_loss: 0.2956 - val_accuracy: 0.8333\n",
      "Epoch 788/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2368 - accuracy: 0.9804 - val_loss: 0.2887 - val_accuracy: 0.8333\n",
      "Epoch 789/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2374 - accuracy: 0.9804 - val_loss: 0.2835 - val_accuracy: 0.8889\n",
      "Epoch 790/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2356 - accuracy: 0.9902 - val_loss: 0.2872 - val_accuracy: 0.8889\n",
      "Epoch 791/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2340 - accuracy: 0.9902 - val_loss: 0.2980 - val_accuracy: 0.8889\n",
      "Epoch 792/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2343 - accuracy: 0.9902 - val_loss: 0.2993 - val_accuracy: 0.8889\n",
      "Epoch 793/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2398 - accuracy: 0.9706 - val_loss: 0.2919 - val_accuracy: 0.8889\n",
      "Epoch 794/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2356 - accuracy: 0.9902 - val_loss: 0.2841 - val_accuracy: 0.8889\n",
      "Epoch 795/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2354 - accuracy: 0.9804 - val_loss: 0.2700 - val_accuracy: 0.9444\n",
      "Epoch 796/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2364 - accuracy: 0.9804 - val_loss: 0.2658 - val_accuracy: 0.8333\n",
      "Epoch 797/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2408 - accuracy: 0.9706 - val_loss: 0.2860 - val_accuracy: 0.8889\n",
      "Epoch 798/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2336 - accuracy: 0.9902 - val_loss: 0.2900 - val_accuracy: 0.8889\n",
      "Epoch 799/800\n",
      "102/102 [==============================] - 0s 1ms/sample - loss: 0.2365 - accuracy: 0.9804 - val_loss: 0.2901 - val_accuracy: 0.8889\n",
      "Epoch 800/800\n",
      "102/102 [==============================] - 0s 2ms/sample - loss: 0.2365 - accuracy: 0.9804 - val_loss: 0.2882 - val_accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "reg_history = train_model(reg_model, train_data, train_targets, epochs=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves\n",
    "\n",
    "Let's now plot the loss and accuracy for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXecFdXZ+L/PvXcru7DA0hcEKdKkCdhAsRfsMVFfjbHF2KImJm+MKa8lif6SvEaNvjEmliQaidFYotjFQmwUKUoXEBYQFhCWtu3u+f0xM/fOnTu37e7dXfY+389nP3tn5syZZ87MnOc8z3OKGGNQFEVRFIBAWwugKIqitB9UKSiKoigRVCkoiqIoEVQpKIqiKBFUKSiKoigRVCkoiqIoEVQpKIoCgIgMFBEjIqG2lkVpO1QpKFlHRN4Wka9EpKCtZVEUJTmqFJSsIiIDgamAAc5o5Wtri1dRMkSVgpJtLgY+BB4DvuU+ICJFIvK/IvKFiOwUkdkiUmQfmyIi74vIDhFZLyKX2PvfFpErXHlcIiKzXdtGRK4VkZXASnvfvXYe1SIyT0SmutIHReQWEflcRHbZx/uLyAMi8r8eef8tIjd6b1BEHhSR33r2PS8i37d//0hENtj5LxeR49IpOBHpKyLPiEiViKwRketdx24VkadF5B92vvNFZKzr+Ai7rHaIyGcicobrWMJyt7lQRNaJyFYR+YnrvMkiMtcux80icnc696HsZxhj9E//svYHrAKuAQ4B6oFermMPAG8D/YAgcARQAAwAdgEXAHlAd2Ccfc7bwBWuPC4BZru2DfA60A0osvddZOcRAm4CvgQK7WM/BBYDBwECjLXTTgY2AgE7XTmw1y2/65pHAesBsbe7AvuAvna+64G+9rGBwOA0yi0AzAN+DuQDBwKrgZPs47fa5XmuXUY/ANbYv/Pscr/FPvdYuzwPSlHuA+3y+xNQZJdFLTDCPu8D4Jv27xLgsLZ+v/Sv5f/aXAD967h/wBS74iq3t5cB37N/B+yKc6zPeT8Gnk2QZzpK4dgUcn3lXBdYDpyZIN1S4AT793XAzATpBFgHHGVvfxt4y/49BNgCHA/kZVB2hwLrfMrlUfv3rcCHrmMBYBOWq24qluILuI4/aZ+TrNwdpVDh2vcxcL79+13gNud56l/H/FP3kZJNvgW8ZozZam//nagLqRwoBD73Oa9/gv3pst69ISI3ichS21WyA+hiXz/Vtf6CZWVg//+bXyJj1ZgzsCwbgP8CnrCPrQJuxKqQt4jIDBHpm8Y9HAD0td0/O2y5bwF6+d2nMaYRqMSyTvoC6+19Dl9gWQbJyt3hS9fvvVhWAcDlwDBgmYjMEZHT0rgPZT9DlYKSFWwf9TeAo0XkSxH5EvgeMNb2fW8FaoDBPqevT7AfYA9Q7Nru7ZMmMvWvHT/4kS1LV2NMGbATq3Wf6lqPA2fa8o4AnkuQDqyW+LkicgBWK/+ZiDDG/N0YMwWrojfA/0uSj8N6YI0xpsz1V2qMOdWVpr/rPgNABZbLayPQ397nMADYQPJyT4oxZqUx5gKgp30PT4tIp0zzUdo3qhSUbHEWEAZGAuPsvxHAe8DFdiv2EeBuO6AaFJHD7W6rTwDHi8g3RCQkIt1FZJyd7wLgHBEpFpEhWK3XZJQCDUAVEBKRnwOdXcf/DNwhIkPFYoyIdAcwxlQCc7AshGeMMfsSXcQY84l9jT8DrxpjdgCIyEEicqx9XzVYrptw6uLjY6DaDlIX2eUzWkQmudIcIiLn2L2sbsTy/38IfISlPP9bRPJEZBpwOjAjRbknRUQuEpEedh477N3p3IuyH6FKQckW38Lyf68zxnzp/AH3Y/VuCWEFRxdjVbzbsVqfAWPMOuBUrKDwdixF4PSs+R1QB2zGcu88kUKOV4GXgRVYLpQaYt1LdwNPAa8B1cDDWEFWh78AB5PAdeThSazYwd9d+wqAu7Ba6F9itbJvARCRC0XkM7+MjDFhrIp8HFYAeSuWwuniSvY8cB5WjOSbwDnGmHpjTB1W999T7PP+D0sRL7PP8y33NO7vZOAzEdkN3IsVa6hJ4zxlP8LpLaEoig8ichSWG2mgx0ffpojIrcAQY8xFqdIqSiaopaAoCRCRPOAG4M/tSSEoSjZRpaAoPojICCy/eR/gnjYWR1FaDXUfKYqiKBHUUlAURVEi7HcThpWXl5uBAwe2tRiKoij7FfPmzdtqjOmRKt1+pxQGDhzI3Llz21oMRVGU/QoR+SKddOo+UhRFUSKoUlAURVEiqFJQFEVRIqhSUBRFUSKoUlAURVEiZE0piMgjIrJFRD5NcFxE5D4RWSUii0RkQrZkURRFUdIjm5bCY1izKibiFGCo/Xcl8IcsyqIoiqKkQdaUgjHmXaxpeRNxJvBXY/EhUCYifbIlT9bYugpe+ykseNL/eGMY5v8Nwg2tK1ca7Kqp51/zK9tajHbH0k3VfLR6G7tq6nn2k5Ypn311Yf45dz3NmVbmi217eHv5lsj2J+u+4tMNO1tCvBbn3RVVfLFtT8p0r372JVuq23727cWVO5m/7qtWudbSTdV8vCZx1VjbEOYfc9bR2Ng2UxC15eC1fsTOa19p79vkTSgiV2JZEwwYMKBVhEub+w+J/h59DoQ8a5XM/wu8+D2orYbDr21d2VJw01MLeW3JZsZUdGFIz9K2FqfdcMq97wFw4shevLZkMwf3a3753P36cv703hrKSws45qCeTcpj+n2z2V3bwJo7T0VEOPv/3gdg7V3TmyVbNrj4kY8JCKy+M7FsNfVhvvO3eQzvXcorNx7VitLFc/r9s4HWKUvn/Up0rd+9vpIH3/mcbp0KOGFkL9802aQtA83is89XNRpjHjLGTDTGTOzRI+Uo7bYjXBe/b++22P/tiMV2KzOsk0L74pRPTX3zC2jnvnoANnyVcPG2lOyutazNrbt93rN2RNhu4aZq6EbKZEfTy2R/JpyggFZu3mUfb5sPsy0thUpca8wSXV92/yVcH7O5dXctq9dsZ7JP0hcWbmRIjxJG9o2uDLl0UzXLvqzm7PEVAGyuruHBdz7nwkMHJGyp7q1r4O7XVnDS6N6s2rKbj9ds5xdnjaYoL8gf313NBZP7U1acH3fe8i93sWmnZbY/PW89px7chzEVZfzs+U9pbDRcM20IA7oX89cP1vLZhmoOKC8mIMJxw3vy/ufbOGFkL/qWRRco27a7lgdmfc43JlXwwefb2FsX5uB+XVj2ZTUnjerNr19dzrmHVDC8dykvL/6Sy6YMipHn/VVbefyjL7jx+GF8YOf/6YadzFv3FZ3yQ5w/qT9Pz6/kqqMGEwj4tSeizF27ne176jhxVHT55vc/38oTH67jxuOHMrRXKc9+UsnQnqV88Pk2duyrY+e+eqYM6cGIPtFydsrnir/M5dgRPenduZBTRvfmtSWb6d+tmDPG9mVR5Q7Wbd/Lis27GdmnMyeP7s2j/1nDSaN6ExDhj+9+zlFDe/DvhZYB/NnGnfzo6UWsqtrN2eP7cdFhB/DMvEpmr9pK58IQhw8uZ8XmXSxcv4Npw3tycL8uVH61l26uZ3j7i0v4+iEVkW1jDH96bzXnTKhg/hdfUVacz+dVu3lneRX5oQDXHzeUIT1LeOw/a8gPBTlzXF8emb2GLbtq2VsX5ppjBvPm0s00NBoEYeLArkwa2I1Zy7dgjOGzDdWMruhCY6Nh1vIt9C0r4pppQwCY98V2np63ge6d8skPBQgIbNwZdQctWL+Dyq/2ctqYvpF9877Yzoert/PhaquhtKumgWufmM+5Eys4qFcpz36yAWMMB/XuzOMffkHfsiJOHNmLf32ygWnDenD8iF7c8+YKSgpCrK7ag8GwfU8dPUsLGdCtmG176qjaVcOxw3vRaAwDuhWzYP0Oduyt5/DB3Xl3RRWHHtiN08b0ZeH6Hfzm1eUR2X73+gq27KqlZ2kBBXkB6hoa2VXTwKkH96YoL8SKzbs4a3w/Vm3ZxetLtvDphp2IwKi+XWgIN7JkUzXb99TRqSDEscN7sq8uzNwvtjOqbxeCAaF358LIta56fB59uhSSFwxQmBegMBTEuN67fy/axJtLtxA2htPH9EUEpjXRysyErE6dLSIDgReNMaN9jk0HrsNadvFQ4D5jjF/9GcPEiRNNu5r76FbX6og3LYfSaEX0nb/NZciyP/LDvKdg6k1w3M8jxwbe/BIQa0IOvmUm4UbD6l+dSiAgPDJ7Dbe/uIT/OnQAvzr7YN/Lv7VsM5c9NpfBPTrxeZXlw/3usUMYP6CMyx6by/mT+nPX18bEnffz5z/lrx/EToVy7/njuGHGAgCuO2YI1x07hOE/e8X3ugeWd+KtH0yLbM/4eB03/2sxU4aUM3vVVt9zAEb26cySTdV8+OPj6N0l+oE45eEweWA3Pl4b73d9/PJDmTK0PGH+7rzcZevs61wYYuH/nMigH8+MO29ozxJOG9OX372xImn+Dmvvmh4n95yfHM+kX77BsF4lfGNif37x0tKkeSz/xcmM+vmrNDTDf/z6947ihN+9y+EHdueD1fEW6cWHH8BPpo/goJ9az/KSIwby2PtrI8ePGNyd9z+PPc/v3tx88ONj6dOliOv+Pp8XF8V5fOPwexZ+JHrubu45bxw3/mNBwuMikKpaG9i9mLd/eExSWdxMGFDG/HXWstRr7jyVg372CnUNrd+Sb457S0TmGWMmpkqXzS6pTwIfAAeJSKWIXC4iV4nIVXaSmcBqYBXwJ+CabMnSanjcR1t21fomSxRAcszJzbuslsK67XsB2JogH4B126w0jkIACIiwpdo6pz7sfy0nbzf76qJrsO+tC1NdUx+XxmH11tggopPf5hRBw1VVu4GoKyQRdVnyaVXXNFCVoDwrv9rnWy6J8KsUnDL7vGoP69PIa8WXu5ulEAD22M/NKVsvVbtqY9xWn3gCqn7POVVjca99TccFlIpdSd4lN6neC4B5XyQPCA/tWdIi13HjfkZVu2qbrRB+d97Y1Il8aI31b/a7RXbas6Uw47DnmL+7GwWhID+ZPoLhP3uFa4PP8cO8p/gzZ/PhoGuZdlBPfv3KMqprrJfyO0cdSFlxPis37+Jfn2wArNZ0z84FvL28KpL3o5dMojAvyG3//ozORXmce0gFW6preOz9L9i6O7aSKykIYYyJVBbj+pdRnB+kOD8EGBZv2Mnm6lqG9SphxeZoRXLXOQdz878WR7bzgpJQqQD8+mtjeHHxJiq376W2oTEj3/BBvUo5oLtl1ueHAlRm4Gs/7MBu9CwtZG9dmKL8IF/u3MfYijKKC0J8umEnby2zeuiUFoTo17WIunAjq11Ks7ykIK7M3KQ67r6H5bb/18Hdomwt8kOBFm+1lhaG2FWTuOI8aVQvVmzezZqtqXsYAXTKDzKkZwkXHXYAP3x6UUaylBSEYirxsuI8duxNrGSmDi3nvZWJrVWHsf3LWLg+/llNHtQtae+g758wjLtfT8+aTMSjl07i0kfnZHzez04byeUe12u6pGsp7HdTZ7dnHn5nBSuN5eudars4nCp1X4PhjaVbeGPplphz/vju6rh8lmyqZoltkQfECtg9NXc91TX1LPvSqoSSvbTeVtAC+8V3XDcOB/XuHKMUvOclUwgA//1M9OMe3KNT0rRelm/eFVehJqNzYSiiSD9cbd17UV6QffWW4puzNr71uKu2IVJeblJV+FOGdOe5BbHhLW/ZOffgxasQggHhwPJOrNyym7EVXWhoNBTmBRO2dgMC3UsK4qyZ0oIQ9Y2NDOtVyqLKnQzsXszabXvp1imf7Xv8A8/fPXYI73++LWXL2g9HIZQWhNjl06p+9bPNkd9di/P4yqeSdmQEy5pZWLmThUkUQkEoQK1LuZUUhKjoWsQB3Ytjrte3SxHnjK9g2ZfVcW4vgF4uv72XUX07U11Tz/rt+2IUwrPXHMHZ//c+o/p25nvHD+MH/1yYsJHjtbTcjOtfxoL1OxjdrzOfboi+L+53FaBLUR5fm1DBM3aX8KOG9eDdFdFGYH4wwKh+nfnE8z6lCKe1CDrNRQuST/Tj+XRjdZKU6fPyDUdxyAFd2bmvPmHL7Q8XpjcYfOYNU+nnCg4P7F4cc7w6TVeAH09fdUTk9z+uPIw1d56acR53nhMbN3nwomh339k3HxuX/vSxzRvW0r1TfAAe4PsnHBS3b+YNU1l713Tygom/yuuPHRK375UbpvL6949m7V3Tef66Kbx0/VSeufoIa/vaIwHLB+6w+s7pzPnJ8Tz57cMi+x765iEsvu0klt1xCi9cN4W1d03n7R8ew9q7pjP/ZyfEXO+Yg6zeeX26FHLTiQfxzNVHRCqSf1x5GMk41xW8dlh820mMqejikzpK/27FcfscGd/4fuKupmM9+S78nxNjzv/0tpN45cajKC+xunlXdC1i7V3TmXnDVH5++kj+/u3DImV+4/FDue4Y67e34nzhuiMjv1+6fipnju0Xc7xfWRHjB3Rl7V3Teen6qRw+uDvv/fcxkeM9S2O7mSdymZ0wshfPXXska++azovfnRrj/196x8msvWt65Fl3KcrjphOHRY7/9bLYcOpjl03i2WuOjNl3wsheXHpk06yETFCl0IKEXErhvjdXAtF+t+Lf2zYlFV2LKM4P8v7n21hU6T9Q6YDu6bfSSwqixmFXT6+k+95a1SQZwTLpHYrzQ4hk3qTp3zW2cunjCkSX5McbtUcOSR5wTnk9n8oMoF/XIt/9AHnBxJ/MyL7xlWdFV/9ruK/fuTAv7ljnolBcukTku2Tyk71zkZX/kBS+9kHl/u9RqifpfqcSXduPgrxgzHahZ9uhi52HXzmF7HvPCwboXmK9z8FA7DPq4pHBG6+q94lfuXu4eb/cRO7BhjTiYL1KrXe6tCAUKZvCvPh3yvstpJt/S6DuoxYkz1YK/cqK4kzPTvlBHJ3Rv1sR67dHj58wshevL4max+dP6s/XJ/bn3RVVdCoIxfRL71dWxMSBXanaVcuKzbs4elhPhvby/9inDi1n6aZdBAT+n90D6YELJ/CHtz8nPyScN6k/O/bWUVIY4lczl8Wce+4hFTw9L/lo3kMHdaNX50LG9i+LUQJF+dbHffc3xlLb0MjC9TsINxr21odpCDdGXAHHHNSDA7p3oqJrEYN7lDB+QBmnjekT6c1S7mqhBQLCVUcP5sF3Pgdg+pg+HDu8JxcdNoDHP1wXSffDkw6K6WL4tQlWN9hNO2sY1quEd1ZUccSQcgQ4elgPHp69hv7dihncoxMFoSAL1u8gGBBuOXU4o/t1oT5sWO0K4FpKIeoGcLjkiIFMHVrOaWP6UFqYR4/SAmrrw5Gy8KNrcR7XHjOYU0b34Ytte6lxuReG9CzhrHF9CQYCKSvzZ689gsf+s5aCvACnj+kbUx5g9diauXgT3Trl88uzR1NeUsDSTdU8+fE6jhhczrN2LOvSIwdS+dU+qnbVxLg5HbdHeUk+1x83lPvfWhXpRDG6X2d+eNJBPL9gI3vrGnhqbuw741eRO1x/7FAuevgjAP50seXq/tXZB9PD0zI/eXRvln25y3cg16VHDmRzdQ3fOmIgAYFVW3Zz/XFDefJjqwzOPaSCfmVF/P6C8ZHK/+qjB7OntgERePzDdQkD/b/9+liK8oIMLC/m5cVfkhcM8OA7n8e4gc6b2J9/zLXG4N5+ZlwnS/5y2WTWuuIuf7t8Mk/Pq4zc43XHDOGUg60ei3//9qE8O38DXTvlRyz6v1w2mc+37Gb9V3u5rBWsBNBAc/NxBZovqPsJHzSOYsaVh3H+Qx8CcF3wWX6Q90/MlJv4xqrjmbP2K96/+Vh+/K/FvLOiirPH9+N3541jd20Do//nVSC+29mRd70VUTJ3f2Ms50yIN/P9utbde/44zhzXL26/l0837OS038+O2ZeoS2KPUsvf/d5/HxPXgnXSv3/zsTFjGLzc/dpy7ntrFdcdM4QfnBTvqnHyWfDzExh3++sRecKNhsG3zIxse9ODVQG+u7KKh95dzc2nDOeqowcnvfdMmfiLN+JiEqWFIRbfelKLXqepfF61m+P+9x36dCnkgx8fl9Y53i68DeFGhvzk5ci+Q3/1Bpura/n3dVM42Hb5OOcsuvXEmIo/WXdgN4PKOzHrB9N80zcXY0yky3GyfDft3Mfhd75FaUGIxbel9/xOvfe9SGzp9jNHsXVXLfe9tYrvHT+MG44f2nzhs0ibd0nNRZyYQqf8EEHb/AyJ1aoQDP27FZMXFHp1Loy4IRzTtpPdovTzurhbm6VJWl5eGtNU+H7mayIc/2owScSrOEnrGIhYFb06FyRNV2y7jLp1ctwC6bmknC6/wSa4sFLh9S9D6j7xrYlT9l7XYCaEPC6yTvZz6N8tquid2IqfWy8dkrmcmku6rsuIWyqJi8uL+1vplB+iyL7/ovyOU5Wq+6gFcdxHRflBXrlhKh+v3c5xG2bDIqCxnsuOHMRhg7oTDEjko3JeSBHhrnMOZvyArnH5/vniiTy3YAOCRAKJXh6//FBqG8Lsrm1gUeVOSgpCTD+4r29aL4N7lPDfJx/Er19ZHrP/kUsmctljllX2/ROGMaJPZ0b17czMxZti/P1ekrlMAK486kAAzpvkP4/VU985nO17askPBbjjzFFMGZp8apPfXzCekoIQizfs5PDB3XlzmeWeyoJO4E/fmsjLizfRtTifRmP44dOLWqXveLr07lzIT6eP4OTRvVMntrn3/HFxsY/ffn0sw3tbo7sfvmQS766oihkZ/9L1U5n3xVdxo8sfvOiQmPgSwH0XjOeLrXsY2quUpZuqEYGvT7QmM3j2miNY34ypPxLxv18fy0G9k89XVZwf4rYzRnH0sPSnzrnvgvH803aRnT62L43GUFMf5uLDBzZH3HaFKoUWxFEKxflB+pYVMbRXKbxqtyDC9Yzu14XR/Szz2+lX3rkw+gjOn+xfSQ4s78SNxw/zPebgHuWbjsvIjYhwzbQhcUrh2OFRH+71x0VN4yumHpg0v/wkwViATgUhvndC4vuZPKhb5Pc30/jYTh9rKb9jhltTADh1dLqWRSb0KyuK3L8Ta2ijySx9EZGUz8eL3/vi7ok0qLxTXBB6WK9ShvWKr3T9lNEZY/smPD5+QFffhlBz+ZpPTyo/vnXEwIzyrehaHPfuJnuX90c6js3TBnhHJruVQgRnPiTPaGdnRKi3Z8T+jNMyb0rPo5bEaal6W6wtjdNbxjSxZ5mitEfUUmgGVdV7cPeH6CQ1FFBHkdtHX7cn9n+4HpBIsLJPlyJrX9BVgYUbABO/r7EeJAihDP3FjY1WfoHkbp1ZP5jGjI/XRVreYM2rs2lnevPdz7ppGqu3+k+10FLMuPIwyx/d2AjhWgjkQdD1GofrufqoA+hRkhfXH72lKQhZzzlrlkJ9DQRCsfeXiHCD9XzbWCEr+z9qKTSVvdvp/sDwmF135j3M8sJLyH/zZ9aO1W/Dgset34v+YS2284ue8OtBbK+2ejAMCnwJd5RbC/WApSB+M9jat8PuWli3B347FH7ZG37VFzZ+kliu+n1Wj6iPHorue2w6/HaYteCPH78eDE9fxqDyTvz41BERFxfA0F6lHJWmz3VgeacYl1M2OOzA7pZ8j5xklcdvh0CtPbK4eiPcUU7Br3py4YrvJZ5N9ckL4PbuVjkti58YLyEv/QBui7o6nH72WYkpzH0Uftkr9v4ScUdPuKM7PPXNlpejPfLEN+Aee6Djxk+s57gx8QR5WaMxbF179u+s7Re/D7d1S36Ow85K69zl/hNOxnDnAPjXlU2XM0NUKTSVPVWE6nfxr/AUbq//Jj+o/w531Z/PRtMN2WYPAttuT2FxkD26d+1sMI1QW82IrnYPHGPP0bLon9b/ut1QYw+OqbanWti7HfZthwGHW9bCjth+6DHss4fgz747um/d+7B3KzQkmN5h71b49JkMbr4dsHUFhAqt+3XWqqh2TU2xelbic5fPhEZ70Mj8v6R/zTl/sp6fTaFtKYzs0znRGU3HeYf2fWU9/2SE7ee69N8tL0d7ZOWr0W9gudV1lhVpVK4tjfM9vX2X9X/uw2ASNLy8VNrd6p1GYzJqd1qNylZC3UdNxY4RvBKexGuNkwBr4E3neSuj8QMnnnDynVZFVBd1rdz3jVGsqulCqGG+J1/XEPpIPvb/gVNg3Qdx6zZkJnPy0bH7DeF6KOoGuzYmjNtkm1AwwJPfPizSS6dFcd9LU5+3kl0am/FcHOUhyV26bYFaCk1kzz5roq96l17tW1ZISVFRfCWVb49IrYuObOxWYPey8VZkMZWBR7nkFcen8ZLIReTOpyMQroN8T3m0slIAOHxwd7ommEOpWfi9B0r7ojnfk7OqWoo4X1ugSqGJXP+4Ne2tWynkBQNWcNhbSTmVuUspJGzd+rUQI8qlk/85ic7P5Nj+hDFWK82rJFtL6SVTvC2Fn8WotC8SPZd0YkxqKXQ89jqWgokqhWBAIJgfX0mFCq2HH6MUElRkvu4je19EKSSp/JIe6yCVS6Q8SmK3W+v+WkP5qPuo/ZPofUvneTkNC7UUOg7OmIR6og81FBDbUnBVUhKEgG1BuGIKCV0eLWUpOK0Vd6vF72VtR6Nx0yZRebSaUmiF66TrPmqjxd0Vot+T9xtK5/1I11JoDavUgyqFJuIohTqSWQp11jZY/zN2H3kqu0jLOJlS8FT8ja41GPzOa/Rfo6Fdk1AptFKLulUshTTdR80JdirNI6GlkIZSiFgKKargNrASVSk0kTx7+uT4mILHfRRRCnmt5D5KQ8kkS78/4CiyVO6jbLWiW91SaKK7UMkuzXEfpWsptMH3qUqhCVTtqo3MiFofZyl43EfOqORgPjS4Jv5qivsoVAhIZsHkVJXL/qgU0nUfZasV3VpKIS3LcD98fh2FRJV/WpZCmr2P1FLYP5j0yzd83UehiPvIqcw9loIbp7Xrrbj8KnEnTaggNn8/nLTOdAfhhvhjMdfrCO4jp7wb/NMlpQnTQrSGyy3cEL2/ZMrN+y7sjzGi/ZVE32E6jZFctRRE5GQRWS4iq0TkZp/jXUXkWRFZJCIfi0j80kXtlDyxLQXf3kdupeCyFNzEuY+MZ9snTTA/tVKIc0d1QPdRIndanJWtQuX8AAAgAElEQVS0v1sKTXEXqjup1XDK3jvfVEv2PupISkFEgsADwCnASOACERnpSXYLsMAYMwa4GLg3W/K0NHk+7qNQwGecgjvQ7Mbr8nBekmTuo2BebP5+5JT7yONeSXbvCWlCy7rVlUITn7eSXZrjPopYCrkVaJ4MrDLGrDbG1AEzgDM9aUYCbwIYY5YBA0UkuzOqtRBOTKExkIcz71oomKz3kcd95K3w3dZFJI2nsotYChn0PkrVi2V/bFmm2/soWxVka/U+akpvM1UKrUdL9D5KqRQ6kKUA9APWu7Yr7X1uFgLnAIjIZOAAIG51DBG5UkTmisjcqqqqLImbGY6lUFZSHFk/IDJOwYSth56J+8ivtetNE8iLDWT7kQu9jyLuo+LY7XRcKS3hc28tSyHPc3/pyLI/Kvn9ldYYvNbBlIJfBM/7Rd4FdBWRBcB3gU+AuCieMeYhY8xEY8zEHj3SXzovmzhKoWtpp4ilEOl9BNaL4e59FPBaCnXJ/zt5uPdl4j5yKr+O7D7KS9H7yHdchmcwUFOURKsohfr4uZ0SpYvZ3g+fZ3Noy8B6cwavRTqEtD/3UTZnSa0E+ru2K4CN7gTGmGrgUgCxmttr7L92TSf2cV3oeQC+f9IILv/LPMDYMQXbInj1FqhaDt0GWdte99Gnz8LWVfDF+9a2CcPLP4LNn0XTrHkHXr45un6C4z7aON/a78fmT63/u7+00uz+Mnps4ZPx8867j8/8IeypghJ7ycTaXZZqL+kNU2+KVlLrP4ZP/5W0jOII5kFhF9izNXb/rk3QfQgMOAxWvWnta6iB+r3WLKh+bF1h/XfcR8tetKbN/mJ2bLq374SyA1wfbxh2rI9Ns2VpfFkGgjDkeFj5OnQqt57huo+ixz96KHYe/P6T4cBp8J97remUy/pDpx6wYT4MPxUGHQVr3rXWbsgrsroWhwpg9xaoroTSvtB9sLVv1RvW9t5tUffR0n/Dzg3x5RAqiH1fAGb9yipnESjtDdWb4s8bcjx88R9r7Q3nXle9YSnMfV9BXiGEiqy0nftYefg9v9pqq1LrPhhqqq3n4T7ea6RVHg011n03Nlrl8eEfrCnIx10IvUfD9jUw58/W9Wt2QJ9x8NXaaD4DDoXi7vFrX7gr49n3QMVE615qqq01Dpz7m3QFfPYs9BoN2z+33q3dtsehtBeMPNNa68SRf9TZUNQV5j0GB50c+/z6jremml//MdTstPII10bXVAD46I9W2l6jrHvf9rn1npf2scrhgCOtdwtgwzzr/SsfYjUcP3/Len8mf8f6Xp3vGax0Bx4NB50S/0xbkGwqhTnAUBEZBGwAzgf+y51ARMqAvXbM4QrgXVtRtGsmBZZRIPXsLejJ1GE9IzZRMCjWi1fcHRY/be2ssKbVpv9kq0LuN8F6qb5cbP2BVUnkFcGCJ63tniOhcz/rxVvwd2tf3/FWuv6HwmfPRfcnIq84mqaomzVwbsMn1l8iPn4oeq4EYqflGHSU9UICfHA/LHkBCtJcR8A0Qp29UEwwP1rh1O6MpgmErHT5JVZlA5YlEPC8onW7omsalA+FfhNhyzLrz8sSS3GTX2rdj/t6DjU7PWVprOt//FC0xRcIEWP4rnUpn/q9sOwlOP5/4D/3WB92Yz0EC6zKomqpVXbv3Z18jQc3gZBVQfU/FLau9L8/E459PmApomUvWb+de5VgVLmAVX5z/mR1q80vsfL46I+WzM42WM+2bnfM+hFA9Pn5Xd99vGGfda63++7KVy0FBJbCOO1uWPSU9U45ZbfwSet55Zda5bv8Jeh2oFUxu3FbfQ374PGvwa07LYU3++7o/dTuil83I1Ron1djKe+lL0SPVVdC14Hw4QOwZYn9/P7XWjQrEIrek9sl/Mat0d9r3rPkaQz7r6/w/u+j+1e/bf15qam2ZHa+FbCUVGGX/VcpGGMaROQ64FUgCDxijPlMRK6yjz8IjAD+KiJhYAlwebbkaUkKbNfR7EP/jxMh4j4KCDD4GPjv1fEnHftT66+5nHGf9ZcNbrVXXDvvcSgfBve4egjHuKEaLOV3tadlnoi92+HXtsV0+LVw/K3W7z+fAJUfW78bG+CAKfDNZ+EXtovwitet1pabPx4FmxZCr4OtlvC33/S/5qw74R178ZMbFlgt/lujK8px6m9h8rfjz6vbY61u577fxgaY8C3/cv/3DdZCL076Q79jVXDOwjcNLtdWYZdo6zIZI8+Ccx+2fk+81D/NjnXR1ceOvw2m3Bh7/O6RUL0Bhp4I/zUjuv+hYyxLE+Dy1+EP9sJNgVB0G+CHq6xKdu17ViPHWcjoiO/CcT+3Wr+/nxAvl3P8rV/Cu7+OP77PXkCqsMzl9qu1rj/5SqsiBstauHIWvHA9rHzNKscDjrQqecdy9iosB2fxmyvegD8c6b9y3Um/sho/z10V/0waw67nZluZzrZbyU2+0mpAzP9r7Pk/Xhd7/8XlVkPQUVKN9dDvEMtKrd/rfw+OzOc+bL3Lmxdb79+Yb/inb0GyusiOMWYmMNOz70HX7w+AodmUIRs48YSwWC6h318wgftnraIw1P5mPGwSjpvKjbuSNOHUc7Z483NINljHiZn4nec9P9X1Y/LJ8zmeYA2ERPIlSu/0BovEOYpij7vjHaEiIA2lkOhaidL4pY90cPDcu/c8CVrP0/vMA3nR7fxOUaUQKf8E5eQcT3QP7nKKGfmf7//s3eWb1yU2XxP2X5PaO67HPb2MO393/M9NYzh5rC8mjyTvhUN+J0speO8v2bfgyBzMj1oVfu9xFtCV15qAoxQabaVwwshenDByv+hJmx7eDxQ8LedwZvPAx1Q2yZRCfuxH7vcROOenun66lWai/JPl590fro9WLI5bwsFdqeR5jiUimMZnGXN/SZSeV26vsgwEIRyOV8ju+Jjb/ZSq/J3jicrXXU7u3nXBPP97ipRvXXwlnGgG0ZiOGcmUQn5segcTTt4r0J2HtwOJ+Ny/U37e+0vWsIkohbzofabTWGgBdJqLJuCMZnYshQ5HMORjKbhaUyac2Tzw7g8klaXgxvvBuc9Pdf2USiFTSyFBRe30BouZn8qFe/xJyGNFJCSNqTdSWVSJxsckaq36tXqdtHmuJVxb1FJwVbiBRErBKV9HcbjkT7QeciQWZKf3jX243vG4ObPCsQrL/T8uD+8763P/TgcN9/scyEthKeyOpnPu0+97yAKqFJqAM3CtQTqooZWWpZDBq+Nu/cec5+nKF1cp+bmP7PNTWgruD9AnbUJLIcF9JarkAnal5fixQwWxx2PcR55jzSGQSimk6z4KRH8nUiBul5jzLBM9f+d4KkshZjoYxwpwfU9upeYoXW/LvDHs3yU1xn2Ul9p91FATe8xk4j5Kw1JwlKr3/pI1bNzuo8bWdR+pUmgCkZhCK2nuVsfPLI6JKTRmvoygU4kkM5mTuTocAk2wFDI97ndvqXzH9fYMuHExBVfF5z3WHNKNmSR1H4Vc5enT6vWzNprtPqqz3oW4KeaTuI9Mo1Vxeyth0+gfbPaO60nlPvIeb2z0cR/5WQr58crR7/4TuY/Siim4LAV1H7U/dtXUc8Vf5kaUQkNHDcn4+TvdH0Vjhu4jSK+Fn6xVG5dPBoHmTI9nYlk4++v2RCs7N+5Kxetaag5uGZO6j5JYX3GWQgIFEswn4tJqCfeRBP0tBT/rJ1K+u+MVR6Iun95pYXyVgisvr3vJ+LmP/CwFn3fCUVLeQLN3X0aWgk+eWUSVQgbMXLyJN5ZujiywE+7I7iMv3t5HmbiPIDreIFWgOZUckZZqc5VCC1sKdbv9W44xgWaPpdBSlmZz3EeBZDEFV8XstdASlb+fT91NuN5KEzNxpD3FvLsh4lVqdXviZXSmk/G7hiN3MD/xeAq3QneTqPeR95783pOkSiFJPMeLI3Mb9D5SpdAEnEBzY64qhSZZCmn0GvJe1+8aTQk0Z3rc11JIpBTsD7V+r3/rLybQ7LEUnMrCi183y2Q0xX0kAUtWtw/cK7s7D+/zS2kpJKjAGutdloK7wk0Qz3BkaGyIdx81hhO7jyQYVT5+1oRbwXgH2MX0PnL99z4vv+fk5/93zpMg0ZGuLmvc7z1wKwLtfdR+cWJaeTRQa0IU5HWQcQle/D5ob++jTGMK6cQC4oJ2Ph9dU7qkpnOtmOtm4j5yt2R9/MTJLAV3V8/m4OtmS9AK9SqLZC17d8UcZymkiikkcR9FLAWP+8hXTk/sJJWl4LTyEynFRHn55eHI5vxP53n5+f+d80T8FW2yfGMsBVUK7Y6aeuvh5GH16/7ahLgJXTsGcS32UAtYCmnEAtJ56dO2FJrjPnJac67eQum6j9xyhQqjE5+F6+N7HyWyFDIl2b0kDB7b/5O5MNwVc8RScDoMJLIUAtFz/DCNPoHmhtTKy/kdZyl4lIIzZiSlUvDpOQTWMzdh13Ors1qD4br0nlfEfeS2FFxdet1yOWWYLF/tfdS+2bnPMjPzaKCgoJBQsIMWn98H2tzeR2lZCmkohUAaAet08krHfeQebJbKfeRnKYQK7Z4zdVZF4x2n0GJKIUllkTB4bP8PJKnE3Yoj4FEGTbUUnDSZuo+c3+7rmsZ4SyHSfTVBTMWdl5+MeYWxvY8iQWeT2fNy5+1+7m65JB2lkOcfp8giHbRWyw4791kvSj4+LZuOhHcSumAesWs9ZzjNBaQZU0gjRpP2NBcpno/3Hv2u4fcxJ7pOnU9MwXEX1duBTO+I5qxaCsb/WEaWgnPPpgkxhRSB/GBe1JeftvsoFPvcE1oK6bqPfJ6pM9mfuxHkBKKbqhT8ug83yVJQpdDucJTC9FHdO7ZS8PrynQFaDlmLKaRjKaQbU0hhaieTIyNLwRVTCOTFusccd5FTqcRZClmMKUSOeUfcei2FJIFhd75xMYUEwfBU4xScNDGWQn18ej/lEmcp+MQU3KOfvee7SeQ+yiuMjSmASylk8LwSjTh335fzriSNKeRp76P2THVNPcN7l1ImezP3qe/PeN1HLdX7yDsatSVjCqm6eyZbnMXPUkiUn2Pd1O0irgePc76zhoPXUkg0mC3ThWOSWVheub2VZbKWvfvcdCy9VPm50zjv1N7tds+tPP/79o5dcJfvnqr4WUb3bbdmGI0ovQRl451WwyFUZMWHnBHqADud51ccm9aYxM8q4GMdGONyBbkGDnrzdXB6iGlMof2yc1893QqxFnVpyxWfskVxd//9wTz49Blr6untq5toKfgEKHuOiE2T6OOIySfNyskJ7nUZEN1X1DW9azmyuivx/ATpndXf9n0V35IttNebePRkOw9Pi9CRoeyA2P3OwkypKCyLlcFNpx7+cmfS+8hRWoVl6Y8kTyemUF1pvVM1O60p1b9aY91D577RNI7cbvnziqGgNLr91zOt99LNH46w1l9wyjaRayav0Aoqe9+jYJ61IM7uzdZ6DgCP2usXOGXqUNoHygbE7isfFn/d0j7W/57Do/LndSLSkcGbb0RGO4++46z/rTSDQgftaJ8dqvfVM7yL7QcdcHjbCpMNrv7AmoPf4bq5Vmvl7+dFW2SbFlmBuCZbCq52yKm/hYPPtSrLLUtg1FnW/hsXQ63PgCN3Pqmu33UQfP0x6OFSPNd8BNtWWr9Lk8xq627tXvSMtRpXxWT/tM4iSk56t1yjzobxF0V93CPPghdd6x4E8+Cy16DHMGvhnnC9tbjN4GOS35vDJS9ZFarfvRz7U2s1u6Enxe73+uq94wqu+TBaoY4627qfoSdFV9pLNWgwVe8jrxwAJ9xulU3ZAPjaw9aUISNOt45VTIazH4JwLYw8w2o1F5ZZLXnHQgrXQ5f+8I8Lre3JV8I4ez2vo39kLWxV0tta1a2m2lqwx6mcL3zKWuWtbKC1NsKCJ6z9o78GR98M6z+MfX79DrEq/GA+DDnOStu5ryXzvu0w3Ja724Fw7qNWOQyaChe/YC20VbXM+oZGngkHHAGVc6zfA4+MPv+uB1irLnYfasv4T6hakV7MrQVQpZABO/fV062n7UvtPyl54v2R0l6xFUy5/VJ6W30tFVPIK7SWsQRrKUUHb+srJp80ex+JWJWaG+/9pZJVgtbyjskIhqyV8rYsie99VNAZxl+Y5Doha6lJiFaCmdB7tPXnR0nPaMUYI6/HfRTpfWRvu623gpJoHi1pKXiPT/gWFNlWz8HnetKFYOx5sfsSLTzkMOJ0a6VCsCrYSVckTut9vp/8zfo/6ChLWfcYFnt8zNfj8xh6Qvw+ERh9TnTbWbWw7/iobEVl0efnff7OtweWheu8J62Auo8yYFdNA50LnD7sHTjQ7MXd6hPJXu+jTPLJ9PpNukaasvr1KEnn/LaIS2XS+8hNum67dPNLFIhtCZqTXyv39GmPqFLIgNqGMMXBHHxpsmUpNIV0K6cWuUaan0fMKFXXOelWoK1JxELwzEWVyjWRdoDfSZciv6wqhWb43lt5TEB7RJVCmny1p476sKEg0Lo9AdoF3g8kW7OkppVPCymXlryG208fYymk8r9nOMdRS5BJ7yM36T6/tC0Fn+6uLUWLWAo59H17UKWQJuPveB2AwkAuWgqeD6QplkKq6RHSpVUshQwVmLuidZ+T6vx24T7yxBQSEbEAUlQZ3hhFQjk8LsmWpDnfZivPM9QeyapSEJGTRWS5iKwSkZt9jncRkX+LyEIR+UxEUkSQ2p4CycGXxn2vxjSt91GmLplEtJRySXqNploKGcYU2tJ9FOk7n2bLOGNLoRlzTzWX5rTyHUuhoy6glQZZUwoiEgQeAE4BRgIXiMhIT7JrgSXGmLHANOB/RaRd17YF9rTZOWVexkxC1hCd1CwTWsrt01LKJa1rpClrZJRwaD+wFGxfv1MppxtYzbT3UarWf1aVQktYCjn0fXvIpqUwGVhljFltjKkDZgBnetIYoFREBCgBtgOeyc3bF7lpKbg+kHB9ExfZ2Q8thXTdGjHuI3egOVVMoR24j9J1l/iNM/FNl25wPouVrvY+ahbZVAr9gPWu7Up7n5v7gRHARmAxcIMxfqtmtB/yHZ2VSy+N+17DdU0LNEd6ozTTf5xu5dQcMu0pFeM+csnVrruk2pVyuoHVdJV6pj22skGzeh8lmEgwh8imUvD7+r1zQ5wELAD6AuOA+0Wkc1xGIleKyFwRmVtVVdXykmZAvuSgeRljKdQ1L9DstwpWJrRGoDnTnlLuijbGfdRCFWhL4u19lG4XTOe+UrXZ0m3Tqfuo3ZLNt7IS6O/arsCyCNxcCvzLWKwC1gDDvRkZYx4yxkw0xkzs0SPBPCGtRL4TU8ilQJTXUjDNCDT7rambCZm6dppCxpaCy0+/3wxe81oKacYUUj2/dJ9vu3cf5dD37SGbSmEOMFREBtnB4/OBFzxp1gHHAYhIL+AgYHUWZWo2QZPj7iNn9siMLYU0W5op82mFvv2Zjr52z/eTSaC5XcUU0ux9lMrSS9cSzOb3k2rgXDIc+dvi2bQTsjb3kTGmQUSuA14FgsAjxpjPROQq+/iDwB3AYyKyGMvd9CNjzNZsydQSiDOFdC61JNz32lBj/c90momWshRag6aOvt4vLAWP+yhjSyGFUk91PCJHFpVCcxoOkS6pqhSygjFmJjDTs+9B1++NwInZlKHFacxxS6F+n/W/yZbCfqAUmhrMznTwWrsap5BuTKGlLIV22qiKWAq5O643d++8iUQthRxVCitetf63VUyhNWiqpRDwLBfZLi0Fr/vI6W2TZu+jFosptNPvx7F0cthSUKWQhNeXbOabD3/Eqi27Ivuk0V7Qu722dLJBxUToXGH9rttjLQrjTP+bLkf/yDpv0NTmyXLAEdBtMAyc0rx8kjFwirUwSrprZgw7xZKpzzhruuz+h0GP4dB1YHzaQ6+Com5Q2hdGnNGiYqdFQWcYdrI1tz/AlButhWG6D0l+3rQfW8/vgCOi+yZebk1P3qU/nPd4/PEjb7TKZNjJgERb39N+DF0qoNdoOOYnLXdv0++Goc10PJx+L/QcFV0YJwcRs5+tIDZx4kQzd+7cVrnWwJtfAqBTfpA9dVYLaNnJyyh8+3a4ZVPi1bgURVHaGSIyzxgzMVU6tRTSwFEINxw3lELRqXUVRem4qFLIgFBA7AXsJad9joqidFxUKWTAV3vro+u1tsVc+IqiKFlGlUIGbN5VY00Ip64jRVE6KKoUMmBfXdi2FHKo55GiKDmFKoUMuOOs0aoUFEXp0KhSyIB+ZUXqPlIUpUOjSiEBf/9onf8BtRQURenAZHXuo/2ZW55dHPn97amDOGOsvT5Qo1oKiqJ0XNRSSIPjR/Ti4Iou1ka4Xi0FRVE6LKoU0qBTgcugcsYpKIqidEBUKaSgc2GI0f26RHeoUlAUpQOjMQXAGEO40RAMCDv21scsJH3SqN6xidV9pChKB0aVAnDvmyu5542VXHnUgTz0buxqoOFGzyyyuzdDtwNbUTpFUZTWQ91HwDPzKwF4Y8nmuGMNbqXw1RewfbVlLSiKonRAVCkAfboUAbB66564Y2H3ehN7qqz/o85qDbEURVFaHVUKQK/OhQmPhcMupeAsxdl1UJYlUhRFaRtUKQDFebFrI7zx/aM5f1J/wGMp5OL6zIqi5BRZVQoicrKILBeRVSJys8/xH4rIAvvvUxEJi0i3bMrkR14odm2EIT1LOH5EL8ATaHZiCaoUFEXpoGRNKYhIEHgAOAUYCVwgIiPdaYwxvzHGjDPGjAN+DLxjjNmeLZkS4bdM9YE9OgFw1NDy6M6IUtAuqYqidEyy2SV1MrDKGLMaQERmAGcCSxKkvwB4MovyJKQhHK8VDuxRwtyfHk/3Ti6rQN1HiqJ0cLLpPuoHrHdtV9r74hCRYuBk4JkEx68UkbkiMreqqqpFhVywfgfb99b5HisvKUDcy26q+0hRlA5ONi0Fv0WMfRw1AJwO/CeR68gY8xDwEMDEiRMT5ZExjY2Gsx74T8w+J8DsS8RSUPeRoigdk7QsBREZLCIF9u9pInK9iJSlOK0ScNewFcDGBGnPpw1cR3Xhxrh9d55zcOIT1H2kKEoHJ1330TNAWESGAA8Dg4C/pzhnDjBURAaJSD5Wxf+CN5GIdAGOBp5PW+oWwk8pxLiLvKj7SFGUDk66SqHRGNMAnA3cY4z5HtAn2Ql2+uuAV4GlwFPGmM9E5CoRucqV9GzgNWNM/HDiLFPXEKsUxlZ0SZDSJmIp6JRRiqJ0TNKt3epF5ALgW1j+f4CUjnVjzExgpmffg57tx4DH0pSjRfEqheevm5L8BHUfKYrSwUnXUrgUOBz4pTFmjYgMAh7PnlitQ72P+ygp6j5SFKWDk5alYIxZAlwPICJdgVJjzF3ZFKw18FoKKWmsBwlAIJg6raIoyn5Iur2P3haRzvYUFAuBR0Xk7uyKln1qM1UKuuqaoigdnHTdR12MMdXAOcCjxphDgOOzJ1br8O9FiXrIJmDB3y1LQVEUpYOSbg0XEpE+wDeAF7MoT6vyx3dWp07kZu82VQqKonRo0q3hbsfqWvq5MWaOiBwIrMyeWO2Yw65uawkURVGyRrqB5n8C/3Rtrwa+li2h2iWNYTCNGlNQFKVDk26guUJEnhWRLSKyWUSeEZGKbAvXmtx7/rjkCZwxCgEduKYoSsclXffRo1hTVPTFmun03/a+DsOJI3snT6AD1xRFyQHSVQo9jDGPGmMa7L/HgB5ZlKvVyQsmmfMIdOCaoig5QbpKYauIXCQiQfvvImBbNgVrbYKBVEpBp81WFKXjk65SuAyrO+qXwCbgXKypL/ZbYtZeJsXsqKCWgqIoOUFaSsEYs84Yc4Yxpocxpqcx5iysgWz7LRlPcaFKQVGUHKA5I7G+32JStAE19eHMTlD3kaIoOUBzlEIKf0v7pknzHoFaCoqidGiaoxRabK3ktiBzS0HdR4qidHySjsQSkV34V/4CFGVFolbCsRR+fMpwJg3qlvoEXXVNUZQcIGkNZ4wpbS1BWpvdtVbLf0jPEiYM6Jr6BHUfKYqSA+TslJ9f+8MHABSE0lwwR91HiqLkADmrFBwK8tIogr3bYety67f2PlIUpQOT8w7ywnQshb+dDZsWWL8LOmdXIEVRlDYkq5aCiJwsIstFZJWI3JwgzTQRWSAin4nIO9mUx8GYaOw8PUthGww6Gi57FboNyqJkiqIobUvWLAURCQIPACcAlcAcEXnBGLPElaYM+D/gZGPMOhHpmS153DS4prhIy1II10G3A2HAYVmUSlEUpe3JpqUwGVhljFltjKkDZgBnetL8F/AvY8w6AGPMlizKE8E9xUValkK4TmMJiqLkBNlUCv2A9a7tSnufm2FAVxF5W0TmicjFfhmJyJUiMldE5lZVVTVbMPdo5oJQOkqhXnsdKYqSE2RTKfhNg+EdCBcCDgGmAycBPxORYXEnGfOQMWaiMWZijx7NX8bBbSkU5qXpPlJLQVGUHCCbvY8qgf6u7Qpgo0+arcaYPcAeEXkXGAusyKJc1DZEp7jID6bQi8bYSkEtBUVROj7ZtBTmAENFZJCI5APnYy3p6eZ5YKqIhESkGDgUWJpFmYBYSyGQanGdxgbrv1oKiqLkAFmzFIwxDSJyHfAqEAQeMcZ8JiJX2ccfNMYsFZFXgEVAI/BnY8yn2ZLJwYkpPPTNQ1In1uktFEXJIbI6eM0YMxOY6dn3oGf7N8BvsimHF0cp5KcVZFaloChK7pCT01w4MYW05j0Kq/tIUZTcISeVQp1aCoqiKL7ktFJIb4yCKgVFUXKHnFQKtRkpBWfKbHUfKYrS8clJpdAk91FAlYKiKB2fnFMKxhjufHkZkG6gWd1HiqLkDjm3nsLW3XVs3V0LuCyFjZ/AW78EE44/oWan9V/dR4qi5AA5pxQa3WspOEph5euw6nXoNxHEM8JZAnDgNOh9cKvJqCiK0lbknFJwT3ERsRTCdVbl/+0320gqRVGU9kHOxRRq6qMuopAz76bbfmMAABM1SURBVJFOeKcoigLkoFJwr6UgjqtI10tQFEUBclIp+ASTw3UQyDlPmqIoShw5pxRq6hvjd6r7SFEUBchBpeBvKaj7SFEUBXJQKSS2FHQcgqIoSs4pBcdSuPMc17gDdR8piqIAuagUbEth2kE9ojvDDWopKIqikINKwRmnEDPvkVoKiqIoQA4qBd9ps1UpKIqiAKoULML16j5SFEUhy0pBRE4WkeUiskpEbvY5Pk1EdorIAvvv59mUByz3USgghIJqKSiKonjJ2jBeEQkCDwAnAJXAHBF5wRizxJP0PWPMadmSw0ttQ2P8ims6TkFRFAXIrqUwGVhljFltjKkDZgBnZvF6aVFTH6Ywz7O4TrgOgjrNhaIoSjaVQj9gvWu70t7n5XARWSgiL4vIKL+MRORKEZkrInOrqqqaJZS/pVCny20qiqKQXaUgPvuMZ3s+cIAxZizwe+A5v4yMMQ8ZYyYaYyb26NHDL0na1DY0UuC1FExYJ8RTFEUhu0qhEujv2q4ANroTGGOqjTG77d8zgTwRKc+iTNTUh+MthcZGCKSxXrOiKEoHJ5tKYQ4wVEQGiUg+cD7wgjuBiPQWe1EDEZlsy7MtizIlthQk53rnKoqixJE1n4kxpkFErgNeBYLAI8aYz0TkKvv4g8C5wNUi0gDsA843xnhdTC1KbX2YwjhLIayWgqIoClleo9l2Cc307HvQ9ft+4P5syuClpqGRLkWeoLIJg6hSUBRFyTmfSa1vTEEtBUVRFMhFpdDQGD9OwTSqpaAoikIuKgW1FBRFURKSe0rBb/Ca9j5SFEUBclAp+E5zoZaCoigKkINKIbGloEpBURQlp5RCQ7iRhkYTaykYYwWa1VJQFEXJLaXgu8COsfappaAoipLlwWvtiY9Wb+OOl6ylHGKUQqO1ZjOBnNKPiqIovuRMTbhtTx2fbqgG8LiPbKWgloKiKEruKIVQIDqTd0Gen6WgSkFRFCV3lELQpRRCaikoiqL4kTNKIeiKGUwc2DV6QC0FRVGUCDmjFNzuo56lhdEDkd5HOVMUiqIoCcmZmjAY8FsdlKiloEpBURQld5RCXjCBUjDqPlIURXHImXEKwUTjEHTwmqK0GfX19VRWVlJTU9PWonQYCgsLqaioIC8vL3ViH3JGKYRSuY/UUlCUVqeyspLS0lIGDhyIvVy70gyMMWzbto3KykoGDRrUpDxyxn2UMKagXVIVpc2oqamhe/fuqhBaCBGhe/fuzbK8ckYpJIwpNNruI7UUFKVNUIXQsjS3PHNGKSSOKWjvI0VRFIes1oQicrKILBeRVSJyc5J0k0QkLCLnZksWjSkoiuJl27ZtjBs3jnHjxtG7d2/69esX2a6rq0srj0svvZTly5cnTfPAAw/wxBNPtITIWSdrgWYRCQIPACcAlcAcEXnBGLPEJ93/A17NliygMQVFUeLp3r07CxYsAODWW2+lpKSEH/zgBzFpjDEYYwgk8DY8+uijKa9z7bXXNl/YViKbvY8mA6uMMasBRGQGcCawxJPuu8AzwKQsyqKWgqK0c27792cs2VjdonmO7NuZ/zl9VMbnrVq1irPOOospU6bw0Ucf8eKLL3Lbbbcxf/589u3bx3nnncfPf/5zAKZMmcL999/P6NGjKS8v56qrruLll1+muLiY559/np49e/LTn/6U8vJybrzxRqZMmcKUKVN466232LlzJ48++ihHHHEEe/bs4eKLL2bVqlWMHDmSlStX8uc//5lx48a1aJmkIpvuo37Aetd2pb0vgoj0A84GHkyWkYhcKSJzRWRuVVVVk4QJBVPFFFQpKIoSZcmSJVx++eV88skn9OvXj7vuuou5c+eycOFCXn/9dZYs8bZvYefOnRx99NEsXLiQww8/nEceecQ3b2MMH3/8Mb/5zW+4/fbbAfj9739P7969WbhwITfffDOffPJJVu8vEdm0FPya5sazfQ/wI2NMOFnE3BjzEPAQwMSJE715pEXiaS6095GitAea0qLPJoMHD2bSpKgD48knn+Thhx+moaGBjRs3smTJEkaOHBlzTlFREaeccgoAhxxyCO+9955v3uecc04kzdq1awGYPXs2P/rRjwAYO3Yso0a1TXlkUylUAv1d2xXARk+aicAMWyGUA6eKSIMx5rmWFiah+0h7HymK4kOnTp0iv1euXMm9997Lxx9/TFlZGRdddJHvWID8/PzI72AwSENDg2/eBQUFcWmMaVJ7t8XJZk04BxgqIoNEJB84H3jBncAYM8gYM9AYMxB4GrgmGwoB0pgQTy0FRVESUF1dTWlpKZ07d2bTpk28+mrL94uZMmUKTz31FACLFy/2dU+1BlmzFIwxDSJyHVavoiDwiDHmMxG5yj6eNI7Q0iS0FMJ2t7NgQesJoyjKfsWECRMYOXIko0eP5sADD+TII49s8Wt897vf5eKLL2bMmDFMmDCB0aNH06VLlxa/TiqkvZgs6TJx4kQzd+7cjM8zxjDoxzMBWHvX9OiBFa/B378OV7wJFRNbSkxFUdJg6dKljBgxoq3FaBc0NDTQ0NBAYWEhK1eu5MQTT2TlypWEQpm33f3KVUTmGWNSVnI5MyFewkB2xFJo2oyCiqIoLcHu3bs57rjjaGhowBjDH//4xyYphOaSM0ohIRGlkJ88naIoShYpKytj3rx5bS1G7sx95HDFFM90suF6678qBUVRlNyyFGJiCQ6NjlJQ95GiKErOWQpxqPtIURQlgioFdR8piqJEUKWgvY8UJWeZNm1a3EC0e+65h2uuuSbhOSUlJQBs3LiRc8/1n+1/2rRppOo6f88997B3797I9qmnnsqOHTvSFT1rqFJQ95Gi5CwXXHABM2bMiNk3Y8YMLrjggpTn9u3bl6effrrJ1/YqhZkzZ1JWVtbk/FqKnAo0++K4jwJqKShKm/LyzfDl4pbNs/fBcMpdCQ+fe+65/PSnP6W2tpaCggLWrl3Lxo0bGTduHMcddxxfffUV9fX1/OIXv+DMM8+MOXft2rWcdtppfPrpp+zbt49LL72UJUuWMGLECPbt2xdJd/XVVzNnzhz27dvHueeey2233cZ9993Hxo0bOeaYYygvL2fWrFkMHDiQuXPnUl5ezt133x2ZYfWKK67gxhtvZO3atZxyyilMmTKF999/n379+vH8889TVFTUokWmlkK4zpo2O9FynYqidFi6d+/O5MmTeeWVVwDLSjjvvPMoKiri2WefZf78+cyaNYubbrop6YR1f/jDHyguLmbRokX85Cc/iRlv8Mtf/pK5c+eyaNEi3nnnHRYtWsT1119P3759mTVrFrNmzYrJa968eTz66KN89NFHfPjhh/zpT3+KTKO9cuVKrr32Wj777DPKysp45plnWrxM1FII16nrSFHaA0la9NnEcSGdeeaZzJgxg0ceeQRjDLfccgvvvvsugUCADRs2sHnzZnr37u2bx7vvvsv1118PwJgxYxgzZkzk2FNPPcVDDz1EQ0MDmzZtYsmSJTHHvcyePZuzzz47MkvrOeecw3vvvccZZ5zBoEGDIovuuKfdbkm0eRyuV6WgKDnMWWedxZtvvhlZVW3ChAk88cQTVFVVMW/ePBYsWECvXr18p8p24zeVzpo1a/jtb3/Lm2++yaJFi5g+fXrKfJJZJM6U25B8au7moEohXKc9jxQlhykpKWHatGlcdtllkQDzzp076dmzJ3l5ecyaNYsvvvgiaR5HHXUUTzzxBACffvopixYtAqwptzt16kSXLl3YvHkzL7/8cuSc0tJSdu3a5ZvXc889x969e9mzZw/PPvssU6dObanbTUnuuI9WvQGv/iR+/65NkFfc+vIoitJuuOCCCzjnnHMiPZEuvPBCTj/9dCZOnMi4ceMYPnx40vOvvvpqLr30UsaMGcO4ceOYPHkyYK2gNn78eEaNGhU35faVV17JKaecQp8+fWLiChMmTOCSSy6J5HHFFVcwfvz4rLiK/MiZqbNZ/zF8cL//sQFHwGFXNU8wRVEyRqfOzg46dXY69J8M/f/a1lIoiqK0azSmoCiKokRQpaAoSpuyv7mw2zvNLU9VCoqitBmFhYVs27ZNFUMLYYxh27ZtFBYWNjmP3IkpKIrS7qioqKCyspKqqqq2FqXDUFhYSEVFRZPPV6WgKEqbkZeXx6BBg1InVFqNrLqPRORkEVkuIqtE5Gaf42eKyCIRWSAic0VkSjblURRFUZKTNUtBRILAA8AJQCUwR0ReMMYscSV7E3jBGGNEZAzwFJB8lIiiKIqSNbJpKUwGVhljVhtj6oAZQMzcs8aY3SYaYeoEaLRJURSlDclmTKEfsN61XQkc6k0kImcDdwI9gel+GYnIlcCV9uZuEVneRJnKga1NPDfbtFfZVK7MULkyQ+XKjObIdUA6ibKpFOKnDPSxBIwxzwLPishRwB3A8T5pHgIearZAInPTGebdFrRX2VSuzFC5MkPlyozWkCub7qNKoL9ruwLYmCixMeZdYLCIlGdRJkVRFCUJ2VQKc4ChIjJIRPKB84EX3AlEZIjYk5CLyAQgH9iWRZkURVGUJGTNfWSMaRCR64BXgSDwiDHmMxG5yj7+IPA14GIRqQf2AeeZ7A5tbLYLKou0V9lUrsxQuTJD5cqMrMu1302drSiKomQPnftIURRFiaBKQVEURYmQM0oh1ZQbWb72/2/vXEOsKMM4/vuzma23vJVsWq2SCBamEuIlIjQqJfzSB5UEC/siQVpQuQiB0BcjIqQIuhhdTCjTCj+UYhfogpKXtTXdxFzMUlc/mBQhYk8f3uecndZjrtGZmdrnB8O85zmz5/2dc+bsM/POzDNrJHVKasvEhkraIumAz4dknmtxz3ZJd9XR61pJn0raJ2mvpKVlcJN0haTtklrda2UZvDJ9NUjaJWlTWbwkdUj6tlIypkRegyWtl7Tf17NpRXtJGuefU2U6LWlZ0V7ezyO+zrdJWue/hXy9zOx/P5EOdB8ExpDOcGoFxufY/23AZKAtE3saWO7t5cAqb493v77AaPduqJNXEzDZ2wOB773/Qt1I17gM8HYfYBswtWivjN+jwNvAphJ9lx3A8G6xMni9Djzo7cuBwWXwyvg1AMdIF3YVvd6PBA4Bjf74HeD+vL3q9mGXaQKmAR9nHrcALTk7NPPXpNAONHm7CWiv5UY6e2taTo4fkGpVlcYN6AfsJF0NX7gX6XqbrcBMupJCGbw6OD8pFOoFDPJ/ciqTVzeXO4Evy+BFVxWIoaQzQze5X65evWX4qFbJjZEFuVQYYWZHAXx+tccLcZXUDEwibZUX7uZDNLuBTmCLmZXCC3gOeBz4IxMrg5cBmyXtUCoLUwavMcAJ4DUfbntFUv8SeGWZD6zzdqFeZvYT8AxwGDgK/GJmm/P26i1JoUclN0pC7q6SBgDvAcvM7PTfLVojVhc3MztnZhNJW+ZTJN1UtJeke4BOM9vR0z+pEavXdznDzCYDs4GHlMrGXIi8vC4jDZu+aGaTgN9Iwx9Fe6XO0kW1c4F3L7ZojVg91q8hpKKho4FrgP6SFubt1VuSwiWV3MiJ45KaAHze6fFcXSX1ISWEtWa2oUxuAGZ2CvgMuLsEXjOAuZI6SFV/Z0p6qwRemNnPPu8ENpKqFBftdQQ44nt5AOtJSaJorwqzgZ1mdtwfF+11B3DIzE6Y2VlgAzA9b6/ekhQuWnKjAD4EFnl7EWk8vxKfL6mvpNHAWGB7PQQkCXgV2Gdmz5bFTdJVkgZ7u5H0Y9lftJeZtZjZKDNrJq1Dn5jZwqK9JPWXNLDSJo1DtxXtZWbHgB8ljfPQLOC7or0yLKBr6KjSf5Feh4Gpkvr5b3MWsC93r3oexCnTBMwhnV1zEFiRc9/rSGOEZ0nZfTEwjHTA8oDPh2aWX+Ge7cDsOnrdStrd3APs9mlO0W7ABGCXe7UBT3q88M8s09/tdB1oLvrzGkM6C6UV2FtZv4v28n4mAt/4d/k+MKQkXv1IddauzMTK4LWStAHUBrxJOrMoV68ocxEEQRBU6S3DR0EQBEEPiKQQBEEQVImkEARBEFSJpBAEQRBUiaQQBEEQVImkEATdkHSuWxXNf62qrqRmZarlBkHZqNvtOIPgP8zvlkpsBEGvI/YUgqCH+D0LVind62G7pBs8fr2krZL2+Pw6j4+QtFHpvhCtkqb7SzVIetnr5m/2q7aDoBREUgiC82nsNnw0L/PcaTObAjxPqpiKt98wswnAWmC1x1cDn5vZzaSaP3s9PhZ4wcxuBE4B99b5/QRBj4krmoOgG5J+NbMBNeIdwEwz+8ELCR4zs2GSTpLq3Z/1+FEzGy7pBDDKzM5kXqOZVAp8rD9+AuhjZk/V/50FwcWJPYUguDTsAu0LLVOLM5n2OeLYXlAiIikEwaUxLzP/2ttfkaqmAtwHfOHtrcASqN40aFBekkHwT4ktlCA4n0a/61uFj8ysclpqX0nbSBtUCzz2MLBG0mOkO4094PGlwEuSFpP2CJaQquUGQWmJYwpB0EP8mMItZnayaJcgqBcxfBQEQRBUiT2FIAiCoErsKQRBEARVIikEQRAEVSIpBEEQBFUiKQRBEARVIikEQRAEVf4E3uyRGl/01FUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Run this cell to plot the new accuracy vs epoch graph\n",
    "\n",
    "try:\n",
    "    plt.plot(reg_history.history['accuracy'])\n",
    "    plt.plot(reg_history.history['val_accuracy'])\n",
    "except KeyError:\n",
    "    plt.plot(reg_history.history['acc'])\n",
    "    plt.plot(reg_history.history['val_acc'])\n",
    "plt.title('Accuracy vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Run this cell to plot the new loss vs epoch graph\n",
    "\n",
    "plt.plot(reg_history.history['loss'])\n",
    "plt.plot(reg_history.history['val_loss'])\n",
    "plt.title('Loss vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the regularisation has helped to reduce the overfitting of the network.\n",
    "You will now incorporate callbacks into a new training run that implements early stopping and learning rate reduction on plateaux.\n",
    "\n",
    "Fill in the function below so that:\n",
    "\n",
    "* It creates an `EarlyStopping` callback object and a `ReduceLROnPlateau` callback object\n",
    "* The early stopping callback is used and monitors validation loss with the mode set to `\"min\"` and patience of 30.\n",
    "* The learning rate reduction on plateaux is used with a learning rate factor of 0.2 and a patience of 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def get_callbacks():\n",
    "    \"\"\"\n",
    "    This function should create and return a tuple (early_stopping, learning_rate_reduction) callbacks.\n",
    "    The callbacks should be instantiated according to the above requirements.\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=30, mode='min')\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=20, factor=0.2)\n",
    "    return (early_stopping, learning_rate_reduction)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to instantiate and train the regularised model with the callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_model = get_regularised_model(train_data[0].shape, 0.3, 0.0001)\n",
    "compile_model(call_model)\n",
    "early_stopping, learning_rate_reduction = get_callbacks()\n",
    "call_history = call_model.fit(train_data, train_targets, epochs=800, validation_split=0.15,\n",
    "                         callbacks=[early_stopping, learning_rate_reduction], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate_reduction.patience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's replot the accuracy and loss graphs for our new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    plt.plot(call_history.history['accuracy'])\n",
    "    plt.plot(call_history.history['val_accuracy'])\n",
    "except KeyError:\n",
    "    plt.plot(call_history.history['acc'])\n",
    "    plt.plot(call_history.history['val_acc'])\n",
    "plt.title('Accuracy vs. epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(call_history.history['loss'])\n",
    "plt.plot(call_history.history['val_loss'])\n",
    "plt.title('Loss vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.081\n",
      "Test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "\n",
    "test_loss, test_acc = call_model.evaluate(test_data, test_targets, verbose=0)\n",
    "print(\"Test loss: {:.3f}\\nTest accuracy: {:.2f}%\".format(test_loss, 100 * test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations for completing this programming assignment! In the next week of the course we will learn how to save and load pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "tensor-flow-2-1",
   "graded_item_id": "mtZ4n",
   "launcher_item_id": "WphgK"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
